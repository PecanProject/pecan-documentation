<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 More on the PEcAn Web Interface | The Predictive Ecosystem Analyzer</title>
  <meta name="description" content="7 More on the PEcAn Web Interface | The Predictive Ecosystem Analyzer" />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="7 More on the PEcAn Web Interface | The Predictive Ecosystem Analyzer" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 More on the PEcAn Web Interface | The Predictive Ecosystem Analyzer" />
  
  
  

<meta name="author" content="By: PEcAn Team" />


<meta name="date" content="2020-01-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="basic-web-workflow.html"/>
<link rel="next" href="developer-guide.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.11/datatables.js"></script>
<link href="libs/dt-core-1.10.19/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.19/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.19/js/jquery.dataTables.min.js"></script>
<link href="libs/dt-ext-fixedcolumns-1.10.19/css/fixedColumns.dataTables.min.css" rel="stylesheet" />
<script src="libs/dt-ext-fixedcolumns-1.10.19/js/dataTables.fixedColumns.min.js"></script>
<script src="libs/jszip-1.10.19/jszip.min.js"></script>
<script src="libs/pdfmake-1.10.19/pdfmake.min.js"></script>
<script src="libs/pdfmake-1.10.19/vfs_fonts.js"></script>
<link href="libs/dt-ext-buttons-1.10.19/css/buttons.dataTables.min.css" rel="stylesheet" />
<script src="libs/dt-ext-buttons-1.10.19/js/dataTables.buttons.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.19/js/buttons.flash.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.19/js/buttons.html5.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.19/js/buttons.colVis.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.19/js/buttons.print.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="project-overview.html"><a href="project-overview.html"><i class="fa fa-check"></i><b>1</b> Project Overview</a></li>
<li class="chapter" data-level="2" data-path="contributor-covenant-code-of-conduct.html"><a href="contributor-covenant-code-of-conduct.html"><i class="fa fa-check"></i><b>2</b> Contributor Covenant Code of Conduct</a></li>
<li class="chapter" data-level="3" data-path="about-the-pecan-book.html"><a href="about-the-pecan-book.html"><i class="fa fa-check"></i><b>3</b> About the PEcAn Book</a><ul>
<li class="chapter" data-level="3.1" data-path="about-the-pecan-book.html"><a href="about-the-pecan-book.html#general-feedbackcommentssuggestions"><i class="fa fa-check"></i><b>3.1</b> General Feedback/Comments/Suggestions</a></li>
<li class="chapter" data-level="3.2" data-path="about-the-pecan-book.html"><a href="about-the-pecan-book.html#bookediting"><i class="fa fa-check"></i><b>3.2</b> Editing this book</a></li>
<li class="chapter" data-level="3.3" data-path="about-the-pecan-book.html"><a href="about-the-pecan-book.html#how-to-create-your-own-version-of-documentation"><i class="fa fa-check"></i><b>3.3</b> How to create your own version of Documentation</a></li>
</ul></li>
<li class="part"><span><b>II Tutorials, Demos and How To’s</b></span></li>
<li class="chapter" data-level="4" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html"><i class="fa fa-check"></i><b>4</b> Install PEcAn</a><ul>
<li class="chapter" data-level="4.1" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#install-vm"><i class="fa fa-check"></i><b>4.1</b> Virtual Machine (VM)</a></li>
<li class="chapter" data-level="4.2" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#install-docker"><i class="fa fa-check"></i><b>4.2</b> Docker</a></li>
<li class="chapter" data-level="4.3" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#install-native"><i class="fa fa-check"></i><b>4.3</b> (Advanced) Native install</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="user-section.html"><a href="user-section.html"><i class="fa fa-check"></i><b>5</b> Tutorials</a><ul>
<li class="chapter" data-level="5.1" data-path="user-section.html"><a href="user-section.html#pecan-in-a-nutshell"><i class="fa fa-check"></i><b>5.1</b> How PEcAn Works in a nutshell</a></li>
<li class="chapter" data-level="5.2" data-path="user-section.html"><a href="user-section.html#demo-table"><i class="fa fa-check"></i><b>5.2</b> PEcAn Demos</a></li>
<li class="chapter" data-level="5.3" data-path="user-section.html"><a href="user-section.html#demo-01-basic-run-pecan"><i class="fa fa-check"></i><b>5.3</b> Demo 01: Basic Run PEcAn</a></li>
<li class="chapter" data-level="5.4" data-path="user-section.html"><a href="user-section.html#demo-02-sensitivity-and-uncertainty-analysis"><i class="fa fa-check"></i><b>5.4</b> Demo 02: Sensitivity and Uncertainty Analysis</a></li>
<li class="chapter" data-level="5.5" data-path="user-section.html"><a href="user-section.html#othervignettes"><i class="fa fa-check"></i><b>5.5</b> Other Vignettes</a><ul>
<li class="chapter" data-level="5.5.1" data-path="user-section.html"><a href="user-section.html#simple-model-data-comparisons"><i class="fa fa-check"></i><b>5.5.1</b> Simple Model-Data Comparisons</a></li>
<li class="chapter" data-level="5.5.2" data-path="user-section.html"><a href="user-section.html#data-assimilation-concepts"><i class="fa fa-check"></i><b>5.5.2</b> Data Assimilation Concepts</a></li>
<li class="chapter" data-level="5.5.3" data-path="user-section.html"><a href="user-section.html#parameter-data-assimilation"><i class="fa fa-check"></i><b>5.5.3</b> Parameter Data Assimilation</a></li>
<li class="chapter" data-level="5.5.4" data-path="user-section.html"><a href="user-section.html#state-variable-data-assimilation"><i class="fa fa-check"></i><b>5.5.4</b> State-Variable Data Assimilation</a></li>
<li class="chapter" data-level="5.5.5" data-path="user-section.html"><a href="user-section.html#pecan-testing-the-sensitivity-analysis-against-observations"><i class="fa fa-check"></i><b>5.5.5</b> PEcAn: Testing the Sensitivity Analysis Against Observations&quot;</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="user-section.html"><a href="user-section.html#advanced-user"><i class="fa fa-check"></i><b>5.6</b> Advanced User Guide</a><ul>
<li class="chapter" data-level="5.6.1" data-path="user-section.html"><a href="user-section.html#web-curl-submission"><i class="fa fa-check"></i><b>5.6.1</b> Submitting Workflow from Command Line</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html"><i class="fa fa-check"></i><b>6</b> Basic Web workflow</a><ul>
<li class="chapter" data-level="6.1" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#web-site-model"><i class="fa fa-check"></i><b>6.1</b> Site and model selection</a><ul>
<li class="chapter" data-level="6.1.1" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#selecting-a-model"><i class="fa fa-check"></i><b>6.1.1</b> Selecting a model</a></li>
<li class="chapter" data-level="6.1.2" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#selecting-a-site"><i class="fa fa-check"></i><b>6.1.2</b> Selecting a site</a></li>
<li class="chapter" data-level="6.1.3" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#site-groups"><i class="fa fa-check"></i><b>6.1.3</b> Site Groups</a></li>
<li class="chapter" data-level="6.1.4" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#using-existing-sites"><i class="fa fa-check"></i><b>6.1.4</b> Using existing sites</a></li>
<li class="chapter" data-level="6.1.5" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#adding-a-new-site"><i class="fa fa-check"></i><b>6.1.5</b> Adding a new site</a></li>
<li class="chapter" data-level="6.1.6" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#troubleshooting"><i class="fa fa-check"></i><b>6.1.6</b> Troubleshooting</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#web-model-config"><i class="fa fa-check"></i><b>6.2</b> Model configuration</a><ul>
<li class="chapter" data-level="6.2.1" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#choosing-meteorology"><i class="fa fa-check"></i><b>6.2.1</b> Choosing meteorology</a></li>
<li class="chapter" data-level="6.2.2" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#met-workflow"><i class="fa fa-check"></i><b>6.2.2</b> Met workflow</a></li>
<li class="chapter" data-level="6.2.3" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#troubleshooting-meteorological-conversions"><i class="fa fa-check"></i><b>6.2.3</b> Troubleshooting meteorological conversions</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#selecting-plant-functional-types-pfts-and-other-parameter-groupings."><i class="fa fa-check"></i><b>6.3</b> Selecting Plant Functional Types (PFTs) and other parameter groupings.</a><ul>
<li class="chapter" data-level="6.3.1" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#using-existing-pfts"><i class="fa fa-check"></i><b>6.3.1</b> Using existing PFTs</a></li>
<li class="chapter" data-level="6.3.2" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#creating-new-pfts"><i class="fa fa-check"></i><b>6.3.2</b> Creating new PFTs</a></li>
<li class="chapter" data-level="6.3.3" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#choosing-initial-vegetation"><i class="fa fa-check"></i><b>6.3.3</b> Choosing initial vegetation</a></li>
<li class="chapter" data-level="6.3.4" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#us-fia"><i class="fa fa-check"></i><b>6.3.4</b> US FIA</a></li>
<li class="chapter" data-level="6.3.5" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#spin-up"><i class="fa fa-check"></i><b>6.3.5</b> Spin up</a></li>
<li class="chapter" data-level="6.3.6" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#selecting-a-soils-product"><i class="fa fa-check"></i><b>6.3.6</b> Selecting a soils product</a></li>
<li class="chapter" data-level="6.3.7" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#soil-texture-depth-and-physical-parameters"><i class="fa fa-check"></i><b>6.3.7</b> Soil texture, depth, and physical parameters</a></li>
<li class="chapter" data-level="6.3.8" data-path="basic-web-workflow.html"><a href="basic-web-workflow.html#other-model-inputs"><i class="fa fa-check"></i><b>6.3.8</b> Other model inputs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="intermediate-user.html"><a href="intermediate-user.html"><i class="fa fa-check"></i><b>7</b> More on the PEcAn Web Interface</a><ul>
<li class="chapter" data-level="7.1" data-path="intermediate-user.html"><a href="intermediate-user.html#additional-web-configuration"><i class="fa fa-check"></i><b>7.1</b> Additional web configuration</a><ul>
<li class="chapter" data-level="7.1.1" data-path="intermediate-user.html"><a href="intermediate-user.html#intermediate-web-setup"><i class="fa fa-check"></i><b>7.1.1</b> Web interface setup</a></li>
<li class="chapter" data-level="7.1.2" data-path="intermediate-user.html"><a href="intermediate-user.html#browndog"><i class="fa fa-check"></i><b>7.1.2</b> Brown Dog</a></li>
<li class="chapter" data-level="7.1.3" data-path="intermediate-user.html"><a href="intermediate-user.html#intermediate-advanced-setup"><i class="fa fa-check"></i><b>7.1.3</b> Advanced Setup</a></li>
<li class="chapter" data-level="7.1.4" data-path="intermediate-user.html"><a href="intermediate-user.html#intermediate-model-config"><i class="fa fa-check"></i><b>7.1.4</b> Editing model configurations</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="intermediate-user.html"><a href="intermediate-user.html#settings-configured-analyses"><i class="fa fa-check"></i><b>7.2</b> Settings-configured analyses</a><ul>
<li class="chapter" data-level="7.2.1" data-path="intermediate-user.html"><a href="intermediate-user.html#pda"><i class="fa fa-check"></i><b>7.2.1</b> Parameter data assimilation (PDA)</a></li>
<li class="chapter" data-level="7.2.2" data-path="intermediate-user.html"><a href="intermediate-user.html#sda"><i class="fa fa-check"></i><b>7.2.2</b> State data assimilation (SDA)</a></li>
<li class="chapter" data-level="7.2.3" data-path="intermediate-user.html"><a href="intermediate-user.html#running-sda-on-remote"><i class="fa fa-check"></i><b>7.2.3</b> Running SDA on remote</a></li>
<li class="chapter" data-level="7.2.4" data-path="intermediate-user.html"><a href="intermediate-user.html#restart-functionality-in-sda"><i class="fa fa-check"></i><b>7.2.4</b> Restart functionality in SDA</a></li>
<li class="chapter" data-level="7.2.5" data-path="intermediate-user.html"><a href="intermediate-user.html#state-data-assimilation-methods"><i class="fa fa-check"></i><b>7.2.5</b> State Data Assimilation Methods</a></li>
<li class="chapter" data-level="7.2.6" data-path="intermediate-user.html"><a href="intermediate-user.html#multisettings"><i class="fa fa-check"></i><b>7.2.6</b> MultiSettings</a></li>
<li class="chapter" data-level="7.2.7" data-path="intermediate-user.html"><a href="intermediate-user.html#benchmarking"><i class="fa fa-check"></i><b>7.2.7</b> Benchmarking</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="developer-guide.html"><a href="developer-guide.html"><i class="fa fa-check"></i><b>8</b> Developer guide</a><ul>
<li class="chapter" data-level="8.1" data-path="developer-guide.html"><a href="developer-guide.html#updatebety"><i class="fa fa-check"></i><b>8.1</b> Updating PEcAn Code and Bety Database</a><ul>
<li class="chapter" data-level="8.1.1" data-path="developer-guide.html"><a href="developer-guide.html#pecan-make"><i class="fa fa-check"></i><b>8.1.1</b> Updating PEcAn</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="developer-guide.html"><a href="developer-guide.html#pecan-git"><i class="fa fa-check"></i><b>8.2</b> Git and GitHub Workflow</a><ul>
<li class="chapter" data-level="8.2.1" data-path="developer-guide.html"><a href="developer-guide.html#using-git"><i class="fa fa-check"></i><b>8.2.1</b> Using Git</a></li>
<li class="chapter" data-level="8.2.2" data-path="developer-guide.html"><a href="developer-guide.html#github-use-with-pecan"><i class="fa fa-check"></i><b>8.2.2</b> GitHub use with PEcAn</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="developer-guide.html"><a href="developer-guide.html#coding-practices"><i class="fa fa-check"></i><b>8.3</b> Coding Practices</a><ul>
<li class="chapter" data-level="8.3.1" data-path="developer-guide.html"><a href="developer-guide.html#developer-codestyle"><i class="fa fa-check"></i><b>8.3.1</b> Coding Style</a></li>
<li class="chapter" data-level="8.3.2" data-path="developer-guide.html"><a href="developer-guide.html#developer-logging"><i class="fa fa-check"></i><b>8.3.2</b> Logging</a></li>
<li class="chapter" data-level="8.3.3" data-path="developer-guide.html"><a href="developer-guide.html#developer-packagedata"><i class="fa fa-check"></i><b>8.3.3</b> Package Data</a></li>
<li class="chapter" data-level="8.3.4" data-path="developer-guide.html"><a href="developer-guide.html#developer-roxygen"><i class="fa fa-check"></i><b>8.3.4</b> Documenting functions using <code>roxygen2</code></a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="developer-guide.html"><a href="developer-guide.html#developer-testing"><i class="fa fa-check"></i><b>8.4</b> Testing</a><ul>
<li class="chapter" data-level="8.4.1" data-path="developer-guide.html"><a href="developer-guide.html#developer-testing-unit"><i class="fa fa-check"></i><b>8.4.1</b> Unit testing</a></li>
<li class="chapter" data-level="8.4.2" data-path="developer-guide.html"><a href="developer-guide.html#developer-testing-integration"><i class="fa fa-check"></i><b>8.4.2</b> Integration testing</a></li>
<li class="chapter" data-level="8.4.3" data-path="developer-guide.html"><a href="developer-guide.html#continuous-integration"><i class="fa fa-check"></i><b>8.4.3</b> Continuous Integration</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="developer-guide.html"><a href="developer-guide.html#download-and-compile-pecan"><i class="fa fa-check"></i><b>8.5</b> Download and Compile PEcAn</a><ul>
<li class="chapter" data-level="8.5.1" data-path="developer-guide.html"><a href="developer-guide.html#download-compile-and-install-pecan-from-github"><i class="fa fa-check"></i><b>8.5.1</b> Download, compile and install PEcAn from GitHub</a></li>
<li class="chapter" data-level="8.5.2" data-path="developer-guide.html"><a href="developer-guide.html#pecan-testrun"><i class="fa fa-check"></i><b>8.5.2</b> PEcAn Testrun</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="developer-guide.html"><a href="developer-guide.html#directory-structure"><i class="fa fa-check"></i><b>8.6</b> Directory structure</a><ul>
<li class="chapter" data-level="8.6.1" data-path="developer-guide.html"><a href="developer-guide.html#overview-of-pecan-repository-as-of-pecan-1.5.3"><i class="fa fa-check"></i><b>8.6.1</b> Overview of PEcAn repository as of PEcAn 1.5.3</a></li>
<li class="chapter" data-level="8.6.2" data-path="developer-guide.html"><a href="developer-guide.html#generic-r-package-structure"><i class="fa fa-check"></i><b>8.6.2</b> Generic R package structure:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Topical Pages</b></span></li>
<li class="chapter" data-level="9" data-path="working-with-vm.html"><a href="working-with-vm.html"><i class="fa fa-check"></i><b>9</b> VM configuration and maintenance</a><ul>
<li class="chapter" data-level="9.1" data-path="working-with-vm.html"><a href="working-with-vm.html#maintain-vm"><i class="fa fa-check"></i><b>9.1</b> Updating the VM</a></li>
<li class="chapter" data-level="9.2" data-path="working-with-vm.html"><a href="working-with-vm.html#ssh-vm"><i class="fa fa-check"></i><b>9.2</b> Connecting to the VM via SSH</a></li>
<li class="chapter" data-level="9.3" data-path="working-with-vm.html"><a href="working-with-vm.html#ssh-vm-bety"><i class="fa fa-check"></i><b>9.3</b> Connecting to bety on the VM via SSh</a><ul>
<li class="chapter" data-level="9.3.1" data-path="working-with-vm.html"><a href="working-with-vm.html#awsvm"><i class="fa fa-check"></i><b>9.3.1</b> Using Amazon Web Services for a VM (AWS)</a></li>
<li class="chapter" data-level="9.3.2" data-path="working-with-vm.html"><a href="working-with-vm.html#createvm"><i class="fa fa-check"></i><b>9.3.2</b> Creating a Virtual Machine</a></li>
<li class="chapter" data-level="9.3.3" data-path="working-with-vm.html"><a href="working-with-vm.html#vm-dektop-conversion"><i class="fa fa-check"></i><b>9.3.3</b> VM Desktop Conversion</a></li>
<li class="chapter" data-level="9.3.4" data-path="working-with-vm.html"><a href="working-with-vm.html#install-rstudio"><i class="fa fa-check"></i><b>9.3.4</b> Install RStudio Desktop</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pecan-standards.html"><a href="pecan-standards.html"><i class="fa fa-check"></i><b>10</b> PEcAn standard formats</a><ul>
<li class="chapter" data-level="10.1" data-path="pecan-standards.html"><a href="pecan-standards.html#defining-new-input-formats"><i class="fa fa-check"></i><b>10.1</b> Defining new input formats</a></li>
<li class="chapter" data-level="10.2" data-path="pecan-standards.html"><a href="pecan-standards.html#time-standard"><i class="fa fa-check"></i><b>10.2</b> Time Standard</a><ul>
<li class="chapter" data-level="10.2.1" data-path="pecan-standards.html"><a href="pecan-standards.html#input-standards"><i class="fa fa-check"></i><b>10.2.1</b> Input Standards</a></li>
<li class="chapter" data-level="10.2.2" data-path="pecan-standards.html"><a href="pecan-standards.html#soils-and-vegetation-inputs"><i class="fa fa-check"></i><b>10.2.2</b> Soils and Vegetation Inputs</a></li>
<li class="chapter" data-level="10.2.3" data-path="pecan-standards.html"><a href="pecan-standards.html#output-standards"><i class="fa fa-check"></i><b>10.2.3</b> Output Standards</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="pecanXML.html"><a href="pecanXML.html"><i class="fa fa-check"></i><b>11</b> The PEcAn XML</a><ul>
<li class="chapter" data-level="11.0.1" data-path="pecanXML.html"><a href="pecanXML.html#xml-core-config"><i class="fa fa-check"></i><b>11.0.1</b> Core configuration</a></li>
<li class="chapter" data-level="11.0.2" data-path="pecanXML.html"><a href="pecanXML.html#xml-outdir"><i class="fa fa-check"></i><b>11.0.2</b> <code>outdir</code>: Output directory</a></li>
<li class="chapter" data-level="11.0.3" data-path="pecanXML.html"><a href="pecanXML.html#xml-database"><i class="fa fa-check"></i><b>11.0.3</b> <code>database</code>: PEcAn database settings</a></li>
<li class="chapter" data-level="11.0.4" data-path="pecanXML.html"><a href="pecanXML.html#xml-pft"><i class="fa fa-check"></i><b>11.0.4</b> <code>pft</code>: Plant functional type selection</a></li>
<li class="chapter" data-level="11.0.5" data-path="pecanXML.html"><a href="pecanXML.html#xml-meta-analysis"><i class="fa fa-check"></i><b>11.0.5</b> <code>meta.analysis</code>: Trait Meta Analysis</a></li>
<li class="chapter" data-level="11.0.6" data-path="pecanXML.html"><a href="pecanXML.html#xml-model"><i class="fa fa-check"></i><b>11.0.6</b> <code>model</code>: Model configuration</a></li>
<li class="chapter" data-level="11.0.7" data-path="pecanXML.html"><a href="pecanXML.html#xml-run"><i class="fa fa-check"></i><b>11.0.7</b> <code>run</code>: Run Setup</a></li>
<li class="chapter" data-level="11.0.8" data-path="pecanXML.html"><a href="pecanXML.html#xml-host"><i class="fa fa-check"></i><b>11.0.8</b> <code>host</code>: Host information for remote execution</a></li>
<li class="chapter" data-level="11.0.9" data-path="pecanXML.html"><a href="pecanXML.html#xml-advanced"><i class="fa fa-check"></i><b>11.0.9</b> Advanced features</a></li>
<li class="chapter" data-level="11.0.10" data-path="pecanXML.html"><a href="pecanXML.html#xml-ensemble"><i class="fa fa-check"></i><b>11.0.10</b> <code>ensemble</code>: Ensemble Runs</a></li>
<li class="chapter" data-level="11.0.11" data-path="pecanXML.html"><a href="pecanXML.html#xml-sensitivity-analysis"><i class="fa fa-check"></i><b>11.0.11</b> <code>sensitivity.analysis</code>: Sensitivity analysis</a></li>
<li class="chapter" data-level="11.0.12" data-path="pecanXML.html"><a href="pecanXML.html#xml-parameter-data-assimilation"><i class="fa fa-check"></i><b>11.0.12</b> Parameter Data Assimilation</a></li>
<li class="chapter" data-level="11.0.13" data-path="pecanXML.html"><a href="pecanXML.html#xml-multi-settings"><i class="fa fa-check"></i><b>11.0.13</b> Multi-Settings</a></li>
<li class="chapter" data-level="11.0.14" data-path="pecanXML.html"><a href="pecanXML.html#xml-state-data-assimilation"><i class="fa fa-check"></i><b>11.0.14</b> (experimental) State Data Assimilation</a></li>
<li class="chapter" data-level="11.0.15" data-path="pecanXML.html"><a href="pecanXML.html#xml-browndog"><i class="fa fa-check"></i><b>11.0.15</b> (experimental) Brown Dog</a></li>
<li class="chapter" data-level="11.0.16" data-path="pecanXML.html"><a href="pecanXML.html#xml-benchmarking"><i class="fa fa-check"></i><b>11.0.16</b> (experimental) Benchmarking</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="workflow.html"><a href="workflow.html"><i class="fa fa-check"></i><b>12</b> PEcAn workflow (web/workflow.R)</a><ul>
<li class="chapter" data-level="12.0.1" data-path="workflow.html"><a href="workflow.html#workflow-readsettings"><i class="fa fa-check"></i><b>12.0.1</b> Read Settings</a></li>
<li class="chapter" data-level="12.0.2" data-path="workflow.html"><a href="workflow.html#workflow-input"><i class="fa fa-check"></i><b>12.0.2</b> Input Conversions</a></li>
<li class="chapter" data-level="12.0.3" data-path="workflow.html"><a href="workflow.html#workflow-input-data"><i class="fa fa-check"></i><b>12.0.3</b> Input Data</a></li>
<li class="chapter" data-level="12.0.4" data-path="workflow.html"><a href="workflow.html#workflow-input-initial"><i class="fa fa-check"></i><b>12.0.4</b> Initial Conditions</a></li>
<li class="chapter" data-level="12.0.5" data-path="workflow.html"><a href="workflow.html#workflow-met"><i class="fa fa-check"></i><b>12.0.5</b> Meteorological Data</a></li>
<li class="chapter" data-level="12.0.6" data-path="workflow.html"><a href="workflow.html#workflow-met-standard"><i class="fa fa-check"></i><b>12.0.6</b> Converting raw data to PEcAn standard</a></li>
<li class="chapter" data-level="12.0.7" data-path="workflow.html"><a href="workflow.html#workflow-met-downscale"><i class="fa fa-check"></i><b>12.0.7</b> Downscaling and gapfilling (optional)</a></li>
<li class="chapter" data-level="12.0.8" data-path="workflow.html"><a href="workflow.html#workflow-met-model"><i class="fa fa-check"></i><b>12.0.8</b> Converting from PEcAn standard to model-specific format</a></li>
<li class="chapter" data-level="12.0.9" data-path="workflow.html"><a href="workflow.html#workflow-traits"><i class="fa fa-check"></i><b>12.0.9</b> Traits</a></li>
<li class="chapter" data-level="12.0.10" data-path="workflow.html"><a href="workflow.html#workflow-metaanalysis"><i class="fa fa-check"></i><b>12.0.10</b> Meta Analysis</a></li>
<li class="chapter" data-level="12.0.11" data-path="workflow.html"><a href="workflow.html#workflow-modelconfig"><i class="fa fa-check"></i><b>12.0.11</b> Model Configuration</a></li>
<li class="chapter" data-level="12.0.12" data-path="workflow.html"><a href="workflow.html#workflow-modelrun"><i class="fa fa-check"></i><b>12.0.12</b> Run Execution</a></li>
<li class="chapter" data-level="12.0.13" data-path="workflow.html"><a href="workflow.html#workflow-postrun"><i class="fa fa-check"></i><b>12.0.13</b> Post Run Analysis</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="pecan-models.html"><a href="pecan-models.html"><i class="fa fa-check"></i><b>13</b> PEcAn Models</a><ul>
<li class="chapter" data-level="13.0.1" data-path="pecan-models.html"><a href="pecan-models.html#models-biocro"><i class="fa fa-check"></i><b>13.0.1</b> BioCro</a></li>
<li class="chapter" data-level="13.0.2" data-path="pecan-models.html"><a href="pecan-models.html#introduction-1"><i class="fa fa-check"></i><b>13.0.2</b> Introduction</a></li>
<li class="chapter" data-level="13.0.3" data-path="pecan-models.html"><a href="pecan-models.html#pecan-configuration-file-additions"><i class="fa fa-check"></i><b>13.0.3</b> PEcAn configuration file additions</a></li>
<li class="chapter" data-level="13.0.4" data-path="pecan-models.html"><a href="pecan-models.html#model-specific-input-files"><i class="fa fa-check"></i><b>13.0.4</b> Model specific input files</a></li>
<li class="chapter" data-level="13.0.5" data-path="pecan-models.html"><a href="pecan-models.html#model-configuration-files"><i class="fa fa-check"></i><b>13.0.5</b> Model configuration files</a></li>
<li class="chapter" data-level="13.0.6" data-path="pecan-models.html"><a href="pecan-models.html#installation-notes"><i class="fa fa-check"></i><b>13.0.6</b> Installation notes</a></li>
<li class="chapter" data-level="13.0.7" data-path="pecan-models.html"><a href="pecan-models.html#models-clm"><i class="fa fa-check"></i><b>13.0.7</b> CLM</a></li>
<li class="chapter" data-level="13.0.8" data-path="pecan-models.html"><a href="pecan-models.html#models-dalec"><i class="fa fa-check"></i><b>13.0.8</b> DALEC</a></li>
<li class="chapter" data-level="13.0.9" data-path="pecan-models.html"><a href="pecan-models.html#models-ed"><i class="fa fa-check"></i><b>13.0.9</b> ED2</a></li>
<li class="chapter" data-level="13.0.10" data-path="pecan-models.html"><a href="pecan-models.html#models-gday"><i class="fa fa-check"></i><b>13.0.10</b> GDAY</a></li>
<li class="chapter" data-level="13.0.11" data-path="pecan-models.html"><a href="pecan-models.html#models-linkages"><i class="fa fa-check"></i><b>13.0.11</b> LINKAGES</a></li>
<li class="chapter" data-level="13.0.12" data-path="pecan-models.html"><a href="pecan-models.html#models-lpjguess"><i class="fa fa-check"></i><b>13.0.12</b> LPJ-GUESS</a></li>
<li class="chapter" data-level="13.0.13" data-path="pecan-models.html"><a href="pecan-models.html#models-maespa"><i class="fa fa-check"></i><b>13.0.13</b> MAESPA</a></li>
<li class="chapter" data-level="13.0.14" data-path="pecan-models.html"><a href="pecan-models.html#models-preles"><i class="fa fa-check"></i><b>13.0.14</b> PRELES</a></li>
<li class="chapter" data-level="13.0.15" data-path="pecan-models.html"><a href="pecan-models.html#models-sipnet"><i class="fa fa-check"></i><b>13.0.15</b> SiPNET</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html"><i class="fa fa-check"></i><b>14</b> Available Meteorological Drivers</a><ul>
<li class="chapter" data-level="14.0.1" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#ameriflux"><i class="fa fa-check"></i><b>14.0.1</b> Ameriflux</a></li>
<li class="chapter" data-level="14.0.2" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#amerifluxlbl"><i class="fa fa-check"></i><b>14.0.2</b> AmerifluxLBL</a></li>
<li class="chapter" data-level="14.0.3" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#fluxnet2015"><i class="fa fa-check"></i><b>14.0.3</b> Fluxnet2015</a></li>
<li class="chapter" data-level="14.0.4" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#narr"><i class="fa fa-check"></i><b>14.0.4</b> NARR</a></li>
<li class="chapter" data-level="14.0.5" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#cruncep"><i class="fa fa-check"></i><b>14.0.5</b> CRUNCEP</a></li>
<li class="chapter" data-level="14.0.6" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#cmip5"><i class="fa fa-check"></i><b>14.0.6</b> CMIP5</a></li>
<li class="chapter" data-level="14.0.7" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#nldas"><i class="fa fa-check"></i><b>14.0.7</b> NLDAS</a></li>
<li class="chapter" data-level="14.0.8" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#gldas"><i class="fa fa-check"></i><b>14.0.8</b> GLDAS</a></li>
<li class="chapter" data-level="14.0.9" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#paleon"><i class="fa fa-check"></i><b>14.0.9</b> PalEON</a></li>
<li class="chapter" data-level="14.0.10" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#fluxnetlathuile"><i class="fa fa-check"></i><b>14.0.10</b> FluxnetLaThuile</a></li>
<li class="chapter" data-level="14.0.11" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#geostreams"><i class="fa fa-check"></i><b>14.0.11</b> Geostreams</a></li>
<li class="chapter" data-level="14.0.12" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#era5"><i class="fa fa-check"></i><b>14.0.12</b> ERA5</a></li>
<li class="chapter" data-level="14.0.13" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#download-gfdl"><i class="fa fa-check"></i><b>14.0.13</b> Download GFDL</a></li>
<li class="chapter" data-level="14.0.14" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#cm3"><i class="fa fa-check"></i><b>14.0.14</b> CM3</a></li>
<li class="chapter" data-level="14.0.15" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#esm2m-esm2g"><i class="fa fa-check"></i><b>14.0.15</b> ESM2M &amp; ESM2G</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="database-synchronization.html"><a href="database-synchronization.html"><i class="fa fa-check"></i><b>15</b> Database synchronization</a><ul>
<li class="chapter" data-level="15.0.1" data-path="database-synchronization.html"><a href="database-synchronization.html#how-does-it-work"><i class="fa fa-check"></i><b>15.0.1</b> How does it work?</a></li>
<li class="chapter" data-level="15.0.2" data-path="database-synchronization.html"><a href="database-synchronization.html#set-up"><i class="fa fa-check"></i><b>15.0.2</b> Set up</a></li>
<li class="chapter" data-level="15.0.3" data-path="database-synchronization.html"><a href="database-synchronization.html#fetch-latest-data"><i class="fa fa-check"></i><b>15.0.3</b> Fetch latest data</a></li>
<li class="chapter" data-level="15.0.4" data-path="database-synchronization.html"><a href="database-synchronization.html#sharing-data"><i class="fa fa-check"></i><b>15.0.4</b> Sharing data</a></li>
<li class="chapter" data-level="15.0.5" data-path="database-synchronization.html"><a href="database-synchronization.html#automation"><i class="fa fa-check"></i><b>15.0.5</b> Automation</a></li>
<li class="chapter" data-level="15.0.6" data-path="database-synchronization.html"><a href="database-synchronization.html#database-maintentance"><i class="fa fa-check"></i><b>15.0.6</b> Database maintentance</a></li>
<li class="chapter" data-level="15.0.7" data-path="database-synchronization.html"><a href="database-synchronization.html#troubleshooting-1"><i class="fa fa-check"></i><b>15.0.7</b> Troubleshooting</a></li>
<li class="chapter" data-level="15.0.8" data-path="database-synchronization.html"><a href="database-synchronization.html#network-status-map"><i class="fa fa-check"></i><b>15.0.8</b> Network Status Map</a></li>
<li class="chapter" data-level="15.0.9" data-path="database-synchronization.html"><a href="database-synchronization.html#tasks"><i class="fa fa-check"></i><b>15.0.9</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="standalone-tools-modules.html"><a href="standalone-tools-modules.html"><i class="fa fa-check"></i><b>16</b> Standalone tools (modules)</a><ul>
<li class="chapter" data-level="16.0.1" data-path="standalone-tools-modules.html"><a href="standalone-tools-modules.html#LoadData"><i class="fa fa-check"></i><b>16.0.1</b> Loading Data in PEcAn</a></li>
<li class="chapter" data-level="16.0.2" data-path="standalone-tools-modules.html"><a href="standalone-tools-modules.html#function-load_data"><i class="fa fa-check"></i><b>16.0.2</b> Function <code>load_data</code></a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="shiny.html"><a href="shiny.html"><i class="fa fa-check"></i><b>17</b> Shiny</a><ul>
<li class="chapter" data-level="17.1" data-path="shiny.html"><a href="shiny.html#testing-the-shiny-server"><i class="fa fa-check"></i><b>17.1</b> Testing the Shiny Server</a></li>
<li class="chapter" data-level="17.2" data-path="shiny.html"><a href="shiny.html#debugging-shiny-apps"><i class="fa fa-check"></i><b>17.2</b> Debugging Shiny Apps</a></li>
<li class="chapter" data-level="17.3" data-path="shiny.html"><a href="shiny.html#checking-log-files"><i class="fa fa-check"></i><b>17.3</b> Checking Log Files</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html"><i class="fa fa-check"></i><b>18</b> Adding to PEcAn</a><ul>
<li class="chapter" data-level="18.1" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#adding-model"><i class="fa fa-check"></i><b>18.1</b> Adding An Ecosystem Model</a></li>
<li class="chapter" data-level="18.2" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#example-met-conversion-wrapper-function"><i class="fa fa-check"></i><b>18.2</b> Example met conversion wrapper function</a></li>
<li class="chapter" data-level="18.3" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#NewInput"><i class="fa fa-check"></i><b>18.3</b> Adding input data</a><ul>
<li class="chapter" data-level="18.3.1" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#meterological-data"><i class="fa fa-check"></i><b>18.3.1</b> Meterological Data</a></li>
<li class="chapter" data-level="18.3.2" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#vegetation-data-1"><i class="fa fa-check"></i><b>18.3.2</b> Vegetation Data</a></li>
<li class="chapter" data-level="18.3.3" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#soil-data-1"><i class="fa fa-check"></i><b>18.3.3</b> Soil Data</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#adding-data-web"><i class="fa fa-check"></i><b>18.4</b> Pecan Data Ingest via Web Interface</a></li>
<li class="chapter" data-level="18.5" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#NewFormat"><i class="fa fa-check"></i><b>18.5</b> Creating a new format</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html"><i class="fa fa-check"></i><b>19</b> Troubleshooting and Debugging PEcAn</a><ul>
<li class="chapter" data-level="19.0.1" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html#cookies-and-pecan-web-pages"><i class="fa fa-check"></i><b>19.0.1</b> Cookies and pecan web pages</a></li>
<li class="chapter" data-level="19.0.2" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html#warning-mkdir-function.mkdir-no-such-file-or-directory"><i class="fa fa-check"></i><b>19.0.2</b> <code>Warning: mkdir() [function.mkdir]: No such file or directory</code></a></li>
<li class="chapter" data-level="19.0.3" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html#after-creating-a-new-pft-the-tag-for-pft-not-passed-to-config.xml-in-ed"><i class="fa fa-check"></i><b>19.0.3</b> After creating a new PFT the <num> tag for PFT not passed to config.xml in ED</a></li>
<li class="chapter" data-level="19.1" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html#debugging"><i class="fa fa-check"></i><b>19.1</b> Debugging</a><ul>
<li class="chapter" data-level="19.1.1" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html#using-testsworkflow.r"><i class="fa fa-check"></i><b>19.1.1</b> Using <code>tests/workflow.R</code></a></li>
<li class="chapter" data-level="19.1.2" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html#useful-scripts"><i class="fa fa-check"></i><b>19.1.2</b> Useful scripts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="database.html"><a href="database.html"><i class="fa fa-check"></i><b>20</b> BETY Database Administration</a><ul>
<li class="chapter" data-level="20.0.1" data-path="database.html"><a href="database.html#database-setup"><i class="fa fa-check"></i><b>20.0.1</b> Best practices</a></li>
<li class="chapter" data-level="20.0.2" data-path="database.html"><a href="database.html#backup-of-bety-database"><i class="fa fa-check"></i><b>20.0.2</b> Backup of BETY database</a></li>
<li class="chapter" data-level="20.0.3" data-path="database.html"><a href="database.html#restore-of-bety-database"><i class="fa fa-check"></i><b>20.0.3</b> Restore of BETY database</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="workflow-modules.html"><a href="workflow-modules.html"><i class="fa fa-check"></i><b>21</b> Workflow modules</a><ul>
<li class="chapter" data-level="21.0.1" data-path="workflow-modules.html"><a href="workflow-modules.html#overview-1"><i class="fa fa-check"></i><b>21.0.1</b> Overview</a></li>
<li class="chapter" data-level="21.0.2" data-path="workflow-modules.html"><a href="workflow-modules.html#load-settings"><i class="fa fa-check"></i><b>21.0.2</b> Load Settings:</a></li>
<li class="chapter" data-level="21.0.3" data-path="workflow-modules.html"><a href="workflow-modules.html#query-database"><i class="fa fa-check"></i><b>21.0.3</b> Query Database:</a></li>
<li class="chapter" data-level="21.0.4" data-path="workflow-modules.html"><a href="workflow-modules.html#meta-analysis"><i class="fa fa-check"></i><b>21.0.4</b> Meta Analysis:</a></li>
<li class="chapter" data-level="21.0.5" data-path="workflow-modules.html"><a href="workflow-modules.html#write-configuration-files"><i class="fa fa-check"></i><b>21.0.5</b> Write Configuration Files</a></li>
<li class="chapter" data-level="21.0.6" data-path="workflow-modules.html"><a href="workflow-modules.html#start-runs"><i class="fa fa-check"></i><b>21.0.6</b> Start Runs:</a></li>
<li class="chapter" data-level="21.0.7" data-path="workflow-modules.html"><a href="workflow-modules.html#get-model-output"><i class="fa fa-check"></i><b>21.0.7</b> Get Model Output</a></li>
<li class="chapter" data-level="21.0.8" data-path="workflow-modules.html"><a href="workflow-modules.html#ensemble-analysis"><i class="fa fa-check"></i><b>21.0.8</b> Ensemble Analysis</a></li>
<li class="chapter" data-level="21.0.9" data-path="workflow-modules.html"><a href="workflow-modules.html#sensitivity-analysis-variance-decomposition"><i class="fa fa-check"></i><b>21.0.9</b> Sensitivity Analysis, Variance Decomposition</a></li>
<li class="chapter" data-level="21.0.10" data-path="workflow-modules.html"><a href="workflow-modules.html#glossary"><i class="fa fa-check"></i><b>21.0.10</b> Glossary</a></li>
<li class="chapter" data-level="21.1" data-path="workflow-modules.html"><a href="workflow-modules.html#pecanvm"><i class="fa fa-check"></i><b>21.1</b> PEcAn Virtual Machine</a><ul>
<li class="chapter" data-level="21.1.1" data-path="workflow-modules.html"><a href="workflow-modules.html#aws-setup"><i class="fa fa-check"></i><b>21.1.1</b> AWS Setup</a></li>
<li class="chapter" data-level="21.1.2" data-path="workflow-modules.html"><a href="workflow-modules.html#porting-vm-to-aws"><i class="fa fa-check"></i><b>21.1.2</b> Porting VM to AWS</a></li>
<li class="chapter" data-level="21.1.3" data-path="workflow-modules.html"><a href="workflow-modules.html#set-up-multiple-instances-optional"><i class="fa fa-check"></i><b>21.1.3</b> Set up multiple instances (optional)</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="workflow-modules.html"><a href="workflow-modules.html#shiny-setup"><i class="fa fa-check"></i><b>21.2</b> Shiny Setup</a><ul>
<li class="chapter" data-level="21.2.1" data-path="workflow-modules.html"><a href="workflow-modules.html#install-the-shiny-r-package-and-shiny-server"><i class="fa fa-check"></i><b>21.2.1</b> Install the Shiny R package and Shiny server</a></li>
<li class="chapter" data-level="21.2.2" data-path="workflow-modules.html"><a href="workflow-modules.html#modify-the-shiny-configuration-file"><i class="fa fa-check"></i><b>21.2.2</b> Modify the shiny configuration file</a></li>
<li class="chapter" data-level="21.2.3" data-path="workflow-modules.html"><a href="workflow-modules.html#set-the-apache-proxy"><i class="fa fa-check"></i><b>21.2.3</b> Set the Apache proxy</a></li>
<li class="chapter" data-level="21.2.4" data-path="workflow-modules.html"><a href="workflow-modules.html#enable-and-start-the-shiny-server-and-restart-apache"><i class="fa fa-check"></i><b>21.2.4</b> Enable and start the shiny server, and restart apache</a></li>
<li class="chapter" data-level="21.2.5" data-path="workflow-modules.html"><a href="workflow-modules.html#troubleshooting-2"><i class="fa fa-check"></i><b>21.2.5</b> Troubleshooting</a></li>
<li class="chapter" data-level="21.2.6" data-path="workflow-modules.html"><a href="workflow-modules.html#further-reading"><i class="fa fa-check"></i><b>21.2.6</b> Further reading</a></li>
<li class="chapter" data-level="21.2.7" data-path="workflow-modules.html"><a href="workflow-modules.html#thredds-setup"><i class="fa fa-check"></i><b>21.2.7</b> Thredds Setup</a></li>
<li class="chapter" data-level="21.2.8" data-path="workflow-modules.html"><a href="workflow-modules.html#install-the-tomcat-8-and-thredds-webapp"><i class="fa fa-check"></i><b>21.2.8</b> Install the Tomcat 8 and Thredds webapp</a></li>
<li class="chapter" data-level="21.2.9" data-path="workflow-modules.html"><a href="workflow-modules.html#update-the-catalog"><i class="fa fa-check"></i><b>21.2.9</b> Update the catalog</a></li>
<li class="chapter" data-level="21.2.10" data-path="workflow-modules.html"><a href="workflow-modules.html#troubleshooting-3"><i class="fa fa-check"></i><b>21.2.10</b> Troubleshooting</a></li>
<li class="chapter" data-level="21.2.11" data-path="workflow-modules.html"><a href="workflow-modules.html#further-reading-1"><i class="fa fa-check"></i><b>21.2.11</b> Further reading</a></li>
<li class="chapter" data-level="21.2.12" data-path="workflow-modules.html"><a href="workflow-modules.html#osinstall"><i class="fa fa-check"></i><b>21.2.12</b> OS Specific Installations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="docker-index.html"><a href="docker-index.html"><i class="fa fa-check"></i><b>22</b> Docker</a><ul>
<li class="chapter" data-level="22.1" data-path="docker-index.html"><a href="docker-index.html#docker-intro"><i class="fa fa-check"></i><b>22.1</b> Introduction to Docker?</a><ul>
<li class="chapter" data-level="22.1.1" data-path="docker-index.html"><a href="docker-index.html#what-is-docker"><i class="fa fa-check"></i><b>22.1.1</b> What is Docker?</a></li>
<li class="chapter" data-level="22.1.2" data-path="docker-index.html"><a href="docker-index.html#working-with-docker"><i class="fa fa-check"></i><b>22.1.2</b> Working with Docker</a></li>
<li class="chapter" data-level="22.1.3" data-path="docker-index.html"><a href="docker-index.html#docker-compose"><i class="fa fa-check"></i><b>22.1.3</b> <code>docker-compose</code></a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="docker-index.html"><a href="docker-index.html#docker-quickstart"><i class="fa fa-check"></i><b>22.2</b> The PEcAn docker install process in detail</a><ul>
<li class="chapter" data-level="22.2.1" data-path="docker-index.html"><a href="docker-index.html#pecan-setup-compose-configure"><i class="fa fa-check"></i><b>22.2.1</b> Configure docker-compose</a></li>
<li class="chapter" data-level="22.2.2" data-path="docker-index.html"><a href="docker-index.html#pecan-docker-quickstart-init"><i class="fa fa-check"></i><b>22.2.2</b> Initialize PEcAn (first time only)</a></li>
<li class="chapter" data-level="22.2.3" data-path="docker-index.html"><a href="docker-index.html#docker-quickstart-troubleshooting"><i class="fa fa-check"></i><b>22.2.3</b> Troubleshooting</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="docker-index.html"><a href="docker-index.html#pecan-docker"><i class="fa fa-check"></i><b>22.3</b> PEcAn Docker Architecture</a><ul>
<li class="chapter" data-level="22.3.1" data-path="docker-index.html"><a href="docker-index.html#pecan-docker-overview"><i class="fa fa-check"></i><b>22.3.1</b> Overview</a></li>
<li class="chapter" data-level="22.3.2" data-path="docker-index.html"><a href="docker-index.html#pecan-docker-compose"><i class="fa fa-check"></i><b>22.3.2</b> PEcAn’s <code>docker-compose</code></a></li>
<li class="chapter" data-level="22.3.3" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-structure"><i class="fa fa-check"></i><b>22.3.3</b> Top-level structure</a></li>
<li class="chapter" data-level="22.3.4" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-traefik"><i class="fa fa-check"></i><b>22.3.4</b> <code>traefik</code></a></li>
<li class="chapter" data-level="22.3.5" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-portainer"><i class="fa fa-check"></i><b>22.3.5</b> <code>portainer</code></a></li>
<li class="chapter" data-level="22.3.6" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-minio"><i class="fa fa-check"></i><b>22.3.6</b> <code>minio</code></a></li>
<li class="chapter" data-level="22.3.7" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-thredds"><i class="fa fa-check"></i><b>22.3.7</b> <code>thredds</code></a></li>
<li class="chapter" data-level="22.3.8" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-postgres"><i class="fa fa-check"></i><b>22.3.8</b> <code>postgres</code></a></li>
<li class="chapter" data-level="22.3.9" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-rabbitmq"><i class="fa fa-check"></i><b>22.3.9</b> <code>rabbitmq</code></a></li>
<li class="chapter" data-level="22.3.10" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-bety"><i class="fa fa-check"></i><b>22.3.10</b> <code>bety</code></a></li>
<li class="chapter" data-level="22.3.11" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-docs"><i class="fa fa-check"></i><b>22.3.11</b> <code>docs</code></a></li>
<li class="chapter" data-level="22.3.12" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-web"><i class="fa fa-check"></i><b>22.3.12</b> <code>web</code></a></li>
<li class="chapter" data-level="22.3.13" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-executor"><i class="fa fa-check"></i><b>22.3.13</b> <code>executor</code></a></li>
<li class="chapter" data-level="22.3.14" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-monitor"><i class="fa fa-check"></i><b>22.3.14</b> <code>monitor</code></a></li>
<li class="chapter" data-level="22.3.15" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-models"><i class="fa fa-check"></i><b>22.3.15</b> Model-specific containers</a></li>
</ul></li>
<li class="chapter" data-level="22.4" data-path="docker-index.html"><a href="docker-index.html#model-docker"><i class="fa fa-check"></i><b>22.4</b> Models using Docker</a><ul>
<li class="chapter" data-level="22.4.1" data-path="docker-index.html"><a href="docker-index.html#model-docker-json-file"><i class="fa fa-check"></i><b>22.4.1</b> Model information</a></li>
<li class="chapter" data-level="22.4.2" data-path="docker-index.html"><a href="docker-index.html#model-docker-Dockerfile"><i class="fa fa-check"></i><b>22.4.2</b> Model build</a></li>
<li class="chapter" data-level="22.4.3" data-path="docker-index.html"><a href="docker-index.html#common-docker-problems"><i class="fa fa-check"></i><b>22.4.3</b> Common problems</a></li>
<li class="chapter" data-level="22.4.4" data-path="docker-index.html"><a href="docker-index.html#debugging-missing-libraries"><i class="fa fa-check"></i><b>22.4.4</b> Debugging missing libraries</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path="docker-index.html"><a href="docker-index.html#docker-build-images"><i class="fa fa-check"></i><b>22.5</b> Building and modifying images</a><ul>
<li class="chapter" data-level="22.5.1" data-path="docker-index.html"><a href="docker-index.html#docker-local-devel"><i class="fa fa-check"></i><b>22.5.1</b> Local development and testing with Docker</a></li>
</ul></li>
<li class="chapter" data-level="22.6" data-path="docker-index.html"><a href="docker-index.html#docker-troubleshooting"><i class="fa fa-check"></i><b>22.6</b> Troubleshooting Docker</a><ul>
<li class="chapter" data-level="22.6.1" data-path="docker-index.html"><a href="docker-index.html#package-not-available-while-building-images"><i class="fa fa-check"></i><b>22.6.1</b> “Package not available” while building images</a></li>
</ul></li>
<li class="chapter" data-level="22.7" data-path="docker-index.html"><a href="docker-index.html#docker-migrate"><i class="fa fa-check"></i><b>22.7</b> Migrating PEcAn from VM to Docker</a><ul>
<li class="chapter" data-level="22.7.1" data-path="docker-index.html"><a href="docker-index.html#running-bety-as-a-docker-container"><i class="fa fa-check"></i><b>22.7.1</b> Running BETY as a docker container</a></li>
</ul></li>
<li class="chapter" data-level="22.8" data-path="docker-index.html"><a href="docker-index.html#pecan-api"><i class="fa fa-check"></i><b>22.8</b> The PEcAn Docker API</a></li>
<li class="chapter" data-level="22.9" data-path="docker-index.html"><a href="docker-index.html#rabbitmq"><i class="fa fa-check"></i><b>22.9</b> RabbitMQ</a><ul>
<li class="chapter" data-level="22.9.1" data-path="docker-index.html"><a href="docker-index.html#rabbitmq-basics-sender"><i class="fa fa-check"></i><b>22.9.1</b> Producer – <code>sender.py</code></a></li>
<li class="chapter" data-level="22.9.2" data-path="docker-index.html"><a href="docker-index.html#rabbitmq-basics-receiver"><i class="fa fa-check"></i><b>22.9.2</b> Consumer – <code>receiver.py</code></a></li>
<li class="chapter" data-level="22.9.3" data-path="docker-index.html"><a href="docker-index.html#rabbitmq-web"><i class="fa fa-check"></i><b>22.9.3</b> RabbitMQ and the PEcAn web interface</a></li>
<li class="chapter" data-level="22.9.4" data-path="docker-index.html"><a href="docker-index.html#rabbitmq-xml"><i class="fa fa-check"></i><b>22.9.4</b> RabbitMQ in the PEcAn XML</a></li>
<li class="chapter" data-level="22.9.5" data-path="docker-index.html"><a href="docker-index.html#rabbitmq-dockerfile"><i class="fa fa-check"></i><b>22.9.5</b> RabbitMQ configuration in Dockerfiles</a></li>
<li class="chapter" data-level="22.9.6" data-path="docker-index.html"><a href="docker-index.html#rabbitmq-case-study"><i class="fa fa-check"></i><b>22.9.6</b> Case study: PEcAn web interface</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="pecan-remote.html"><a href="pecan-remote.html"><i class="fa fa-check"></i><b>23</b> Remote execution with PEcAn</a><ul>
<li class="chapter" data-level="23.1" data-path="pecan-remote.html"><a href="pecan-remote.html#basics-of-ssh"><i class="fa fa-check"></i><b>23.1</b> Basics of SSH</a></li>
<li class="chapter" data-level="23.2" data-path="pecan-remote.html"><a href="pecan-remote.html#ssh-authentication-password-vs.ssh-key"><i class="fa fa-check"></i><b>23.2</b> SSH authentication – password vs. SSH key</a></li>
<li class="chapter" data-level="23.3" data-path="pecan-remote.html"><a href="pecan-remote.html#ssh-tunneling"><i class="fa fa-check"></i><b>23.3</b> SSH tunneling</a></li>
<li class="chapter" data-level="23.4" data-path="pecan-remote.html"><a href="pecan-remote.html#ssh-tunnels-and-pecan"><i class="fa fa-check"></i><b>23.4</b> SSH tunnels and PEcAn</a></li>
<li class="chapter" data-level="23.5" data-path="pecan-remote.html"><a href="pecan-remote.html#basic-remote-execute-functions"><i class="fa fa-check"></i><b>23.5</b> Basic remote execute functions</a></li>
<li class="chapter" data-level="23.6" data-path="pecan-remote.html"><a href="pecan-remote.html#remote-model-execution-with-pecan"><i class="fa fa-check"></i><b>23.6</b> Remote model execution with PEcAn</a></li>
<li class="chapter" data-level="23.7" data-path="pecan-remote.html"><a href="pecan-remote.html#xml-configuration"><i class="fa fa-check"></i><b>23.7</b> XML configuration</a></li>
<li class="chapter" data-level="23.8" data-path="pecan-remote.html"><a href="pecan-remote.html#configuration-for-pecan-web-interface"><i class="fa fa-check"></i><b>23.8</b> Configuration for PEcAn web interface</a></li>
<li class="chapter" data-level="23.9" data-path="pecan-remote.html"><a href="pecan-remote.html#running-pecan-code-for-remotely"><i class="fa fa-check"></i><b>23.9</b> Running PEcAn code for remotely</a></li>
<li class="chapter" data-level="23.10" data-path="pecan-remote.html"><a href="pecan-remote.html#special-case-geo.bu.edu"><i class="fa fa-check"></i><b>23.10</b> Special case: <code>geo.bu.edu</code></a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="data-assimilation-with-dart.html"><a href="data-assimilation-with-dart.html"><i class="fa fa-check"></i><b>24</b> Data assimilation with DART</a></li>
<li class="part"><span><b>IV Appendix</b></span></li>
<li class="chapter" data-level="25" data-path="miscellaneous.html"><a href="miscellaneous.html"><i class="fa fa-check"></i><b>25</b> Miscellaneous</a><ul>
<li class="chapter" data-level="25.1" data-path="miscellaneous.html"><a href="miscellaneous.html#todo"><i class="fa fa-check"></i><b>25.1</b> TODO</a></li>
<li class="chapter" data-level="25.2" data-path="miscellaneous.html"><a href="miscellaneous.html#using-the-pecan-download.file-function"><i class="fa fa-check"></i><b>25.2</b> Using the PEcAn download.file() function</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="faq.html"><a href="faq.html"><i class="fa fa-check"></i><b>26</b> FAQ</a></li>
<li class="chapter" data-level="27" data-path="pecan-project-used-in-courses.html"><a href="pecan-project-used-in-courses.html"><i class="fa fa-check"></i><b>27</b> PEcAn Project Used in Courses</a><ul>
<li class="chapter" data-level="27.0.1" data-path="pecan-project-used-in-courses.html"><a href="pecan-project-used-in-courses.html#university-classes"><i class="fa fa-check"></i><b>27.0.1</b> University classes</a></li>
<li class="chapter" data-level="27.0.2" data-path="pecan-project-used-in-courses.html"><a href="pecan-project-used-in-courses.html#summer-courses-workshops"><i class="fa fa-check"></i><b>27.0.2</b> Summer Courses / Workshops</a></li>
<li class="chapter" data-level="27.0.3" data-path="pecan-project-used-in-courses.html"><a href="pecan-project-used-in-courses.html#selected-publications"><i class="fa fa-check"></i><b>27.0.3</b> Selected Publications</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="package-dependencies.html"><a href="package-dependencies.html"><i class="fa fa-check"></i><b>28</b> Package Dependencies</a><ul>
<li class="chapter" data-level="28.1" data-path="package-dependencies.html"><a href="package-dependencies.html#executive-summary-what-to-usually-do"><i class="fa fa-check"></i><b>28.1</b> Executive Summary: What to usually do</a></li>
<li class="chapter" data-level="28.2" data-path="package-dependencies.html"><a href="package-dependencies.html#big-picture-whats-possible-to-do"><i class="fa fa-check"></i><b>28.2</b> Big Picture: What’s possible to do</a></li>
<li class="chapter" data-level="28.3" data-path="package-dependencies.html"><a href="package-dependencies.html#declaring-dependencies-depends-suggests-imports"><i class="fa fa-check"></i><b>28.3</b> Declaring Dependencies: Depends, Suggests, Imports</a></li>
<li class="chapter" data-level="28.4" data-path="package-dependencies.html"><a href="package-dependencies.html#importing-functions-use-roxygen"><i class="fa fa-check"></i><b>28.4</b> Importing Functions: Use Roxygen</a></li>
<li class="chapter" data-level="28.5" data-path="package-dependencies.html"><a href="package-dependencies.html#loading-code-dont-but-use-requirenamespace-when-you-do"><i class="fa fa-check"></i><b>28.5</b> Loading Code: Don’t… But Use <code>requireNamespace</code> When You Do</a></li>
<li class="chapter" data-level="28.6" data-path="package-dependencies.html"><a href="package-dependencies.html#installing-dependencies-let-the-machines-do-it"><i class="fa fa-check"></i><b>28.6</b> Installing dependencies: Let the machines do it</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="appendix-testthat.html"><a href="appendix-testthat.html"><i class="fa fa-check"></i><b>29</b> Testing with the <code>testthat</code> package</a><ul>
<li class="chapter" data-level="29.1" data-path="appendix-testthat.html"><a href="appendix-testthat.html#list-of-expectations"><i class="fa fa-check"></i><b>29.1</b> List of Expectations</a></li>
<li class="chapter" data-level="29.2" data-path="appendix-testthat.html"><a href="appendix-testthat.html#basic-use-of-the-testthat-package"><i class="fa fa-check"></i><b>29.2</b> Basic use of the <code>testthat</code> package</a></li>
<li class="chapter" data-level="29.3" data-path="appendix-testthat.html"><a href="appendix-testthat.html#data-for-tests"><i class="fa fa-check"></i><b>29.3</b> Data for tests</a></li>
<li class="chapter" data-level="29.4" data-path="appendix-testthat.html"><a href="appendix-testthat.html#settings-1"><i class="fa fa-check"></i><b>29.4</b> Settings</a></li>
<li class="chapter" data-level="29.5" data-path="appendix-testthat.html"><a href="appendix-testthat.html#helper-functions-for-unit-tests"><i class="fa fa-check"></i><b>29.5</b> Helper functions for unit tests</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="developer-devtools.html"><a href="developer-devtools.html"><i class="fa fa-check"></i><b>30</b> <code>devtools</code> package</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Predictive Ecosystem Analyzer</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intermediate-user" class="section level1">
<h1><span class="header-section-number">7</span> More on the PEcAn Web Interface</h1>
<p>This section will provide information to those wanting to take advantage of PEcAn’s customizations from the web interface.</p>
<ul>
<li><a href="intermediate-user.html#additional-web-configuration">Additional web configuration</a> - Advanced options available from the web interface
<ul>
<li><a href="intermediate-user.html#browndog">Brown Dog</a></li>
<li><a href="intermediate-user.html#intermediate-advanced-setup">Sensitivity and ensemble analyses</a>[TODO: Under construction…]</li>
<li>[Editing model configurations][TODO: Under construction…]</li>
</ul></li>
<li><a href="intermediate-user.html#settings-configured-analyses">Settings-configured analyses</a> - Analyses only available by manually editing <code>pecan.xml</code>
<ul>
<li><a href="intermediate-user.html#pda">Parameter data assimilation (PDA)</a></li>
<li><a href="intermediate-user.html#sda">State data assimilation (SDA)</a></li>
</ul></li>
<li><a href="pecan-remote.html#pecan-remote">Remote execution with PEcAn</a> - Running analyses and generally working with external machines (HPC) in the context of PEcAn.</li>
</ul>

<div id="additional-web-configuration" class="section level2">
<h2><span class="header-section-number">7.1</span> Additional web configuration</h2>
<p>Additional settings for web configuration:</p>
<ul>
<li><span id="intermediate-web-setup">Web interface setup</span></li>
<li><span id="browndog">Brown Dog</span></li>
<li><span id="intermediate-advanced-setup">Advanced setup</span>
<ul>
<li>[Sensitivity analysis] (TODO)</li>
<li>[Uncertainty analysis] (TODO)</li>
</ul></li>
<li><span id="intermediate-model-config">Editing model configuration files</span></li>
</ul>
<div id="intermediate-web-setup" class="section level3">
<h3><span class="header-section-number">7.1.1</span> Web interface setup</h3>
<p>There are few options which you can change via web interface.</p>
<p>To visit the configuration page either you can just click on the setups link on the introduction page alternatively can type <code>&lt;host&gt;/setups/</code>.</p>
<p>The list of configuration available</p>
<ol style="list-style-type: decimal">
<li><p><strong>Database configuration</strong> : BETYdb(Biofuel Ecophysiological Traits and Yields database) configuration details, can be edited according to need.</p></li>
<li><p><strong>Browndog configuration</strong> : Browndog configuration details, Used to connect browndog. Its included by default in VM.</p></li>
<li><p><strong>FIA Database</strong> : FIA(Forest Inventory and Analysis) Database configuration details, Can be used to add additional data to models.</p></li>
<li><p><strong>Google MapKey</strong> : Google Map key, used to access the google map by PEcAn.</p></li>
<li><p><strong>Change Password</strong> : A small infomation to change the VM user password. (if using Docker image it won’t work)</p></li>
<li><p><strong>Automatic Sync</strong> : If ON then it will sync the database between local machine and the remote servers. <strong>Still unders testing part might be buggy</strong>.</p></li>
</ol>
<p>Still work on the adding other editing feature going on, this page will be updated as new configuration will be available.</p>
</div>
<div id="browndog" class="section level3">
<h3><span class="header-section-number">7.1.2</span> Brown Dog</h3>
<p>The Browndog service provides PEcAn with access to large and diverse sets of data at the click of a button in the format that PEcAn needs. By clicking the checkbox you will be using the Browndog Service to process data.</p>
<p>For more information regarding meteorological data check out <a href="available-meteorological-drivers.html#available-meteorological-drivers">Available Meteorological Drivers</a></p>
<p>More information can be found at the <a href="http://browndog.ncsa.illinois.edu/">Browndog website</a>.</p>
</div>
<div id="intermediate-advanced-setup" class="section level3">
<h3><span class="header-section-number">7.1.3</span> Advanced Setup</h3>
<p>(TODO: Under construction…)</p>
</div>
<div id="intermediate-model-config" class="section level3">
<h3><span class="header-section-number">7.1.4</span> Editing model configurations</h3>
<p>(TODO: Under construction…)</p>

</div>
</div>
<div id="settings-configured-analyses" class="section level2">
<h2><span class="header-section-number">7.2</span> Settings-configured analyses</h2>
<p>These analyses can be run through the web interface, but lack graphical interfaces and currently can only be configured throughthe XML settings. To run these analyses use the <strong>Edit pecan.xml</strong> checkbox on the Input configuration page. Eventually, these modules will be integrated into the web user interface.</p>
<ul>
<li><a href="intermediate-user.html#pda">Parameter Data Assimilation (PDA)</a></li>
<li><a href="intermediate-user.html#sda">State Data Assimilation (SDA)</a></li>
<li><a href="intermediate-user.html#multisettings">MultiSettings</a></li>
<li><a href="intermediate-user.html#benchmarking">Benchmarking</a></li>
</ul>
<p>(TODO: Add links)</p>
<div id="pda" class="section level3">
<h3><span class="header-section-number">7.2.1</span> Parameter data assimilation (PDA)</h3>
<p>All functions pertaining to Parameter Data Assimilation are housed within: <strong>pecan/modules/assim.batch</strong>.</p>
<p>For a detailed usage of the module, please see the vignette under <strong>pecan/modules/assim.batch/vignettes</strong>.</p>
<div id="pda.mcmc.r" class="section level4">
<h4><span class="header-section-number">7.2.1.1</span> <strong>pda.mcmc.R</strong></h4>
<p>This is the main PDA code. It performs Bayesian MCMC on model parameters by proposing parameter values, running the model, calculating a likelihood (between model output and supplied observations), and accepting or rejecting the proposed parameters (Metropolis algorithm). Additional notes:</p>
<ul>
<li><p>The first argument is <em>settings</em>, followed by others that all default to <em>NULL.settings</em> is a list used throughout Pecan, which contains all the user options for whatever analyses are being done. The easiest thing to do is just pass that whole object all around the Pecan code and let different functions access whichever settings they need. That’s what a lot of the rest of the Pecan code does. But the flexibility to override most of the relevant settings in <em>settings</em> is there by providing them directly as arguments to the function.</p></li>
<li><p>The <em>if(FALSE)…</em> : If you’re trying to step through the function you probably will have the <em>settings</em> object around, but those other variables will be undefined. If you set them all to NULL then they’ll be ignored without causing errors. It is there for debugging purposes.</p></li>
<li><p>The next step calls pda.settings(), which is in the file pda.utils.R (see below). It checks whether any settings are being overridden by arguments, and in most cases supplies default values if it can’t find either.</p></li>
<li>In the MCMC setup section
<ul>
<li>The code is set up to allow you to start a new MCMC chain, or to continue a previous chain as specified in settings.</li>
<li>The code writes a simple text file of parameter samples at every iteration, which lets you get some results and even re-start an MCMC that fails for some reason.</li>
<li>The code has adaptive jump distributions. So you can see some initialization of the jump distributions and associated variables here.</li>
<li>Finally, note that after all this setup a new XML settings file is saved. The idea is that the original pecan.xml you create is preserved for provenance, and then periodically throughout the workflow the settings (likely containing new information) are re-saved with descriptive filenames.</li>
</ul></li>
<li>MCMC loop
<ul>
<li>Periodically adjust jump distribution to make acceptance rate closer to target</li>
<li>Propose new parameters one at a time. For each:
<ul>
<li>First, note that Pecan may be handling many more parameters than are actually being targeted by PDA. Pecan puts priors on any variables it has information for (in the BETY database), and then these get passed around throughout the analysis and every step (meta-, sensitivity, ensemble analyses, etc.). But for PDA, you specify a separate list of probably far fewer parameters to constrain with data. These are the ones that get looped over and varied here. The distinction between all parameters and only those dealt with in PDA is dealt with in the setup code above.</li>
<li>First a new value is proposed for the parameter of interest.</li>
<li>Then, a new model run is set up, identical to the previous except with the new proposed value for the one parameter being updated on this run.</li>
<li>The model run is started, and outputs collected after waiting for it to finish.</li>
<li>A new likelihood is calculated based on the model outputs and the observed dataset provided.</li>
<li>Standard Metropolis acceptance criteria is used to decide whether to keep the proposed parameter.</li>
<li>Periodically (at interval specified in settings), a diagnostic figure is saved to disk so you can check on progress.</li>
</ul></li>
<li>This works only for NEE currently</li>
</ul></li>
</ul>
</div>
<div id="pda.mcmc.bs.r" class="section level4">
<h4><span class="header-section-number">7.2.1.2</span> <strong>pda.mcmc.bs.R</strong></h4>
<p>This file is basically identical to pda.mcm.R, but rather than propose parameters one at a time, it proposes new values for all parameters at once (“bs” stands for “block sampling”). You choose which option to use by specifying settings<span class="math inline">\(assim.batch\)</span>method:
* “bruteforce” means sample parameters one at a time
* “bruteforce.bs” means use this version, sampling all parameters at once
* “emulator” means use the emulated-likelihood version</p>
</div>
<div id="pda.emulator" class="section level4">
<h4><span class="header-section-number">7.2.1.3</span> <strong>pda.emulator</strong></h4>
<p>This version of the PDA code again looks quite similar to the basic “bruteforce” one, but its mechanics are very different. The basic idea is, rather than running thousands of model iterations to explore parameter space via MCMC, run a relatively smaller number of runs that have been carefully chosen to give good coverage of parameter space. Then, basically interpolate the likelihood calculated for each of those runs (actually, fit a Gaussian process to it), to get a surface that “emulates” the true likelihood. Now, perform regular MCMC (just like the “bruteforce” approach), except instead of actually running the model on every iteration to get a likelihood, just get an approximation from the likelihood emulator. Since the latter step takes virtually no time, you can run as long of an MCMC as you need at little computational cost, once you have done the initial model runs to create the likelihood emulator.</p>
</div>
<div id="pda.mcmc.recover.r" class="section level4">
<h4><span class="header-section-number">7.2.1.4</span> <strong>pda.mcmc.recover.R</strong></h4>
<p>This function is for recovering a failed PDA MCMC run.</p>
</div>
<div id="pda.utils.r" class="section level4">
<h4><span class="header-section-number">7.2.1.5</span> <strong>pda.utils.R</strong></h4>
<p>This file contains most of the individual functions used by the main PDA functions (pda.mcmc.*.R).</p>
<ul>
<li><em>assim.batch</em> is the main function Pecan calls to do PDA. It checks which method is requested (bruteforce, bruteforce.bs, or emulator) and call the appropriate function described above.</li>
<li><em>pda.setting</em> handles settings. If a setting isn’t found, the code can usually supply a reasonable default.</li>
<li><em>pda.load.priors</em> is fairly self explanatory, except that it handles a lot of cases and gives different options priority over others. Basically, the priors to use for PDA parameters can come from either a Pecan prior.distns or post.distns object (the latter would be, e.g., the posteriors of a meta-analysis or previous PDA), or specified either by file path or BETY ID. If not told otherwise, the code tries to just find the most recent posterior in BETY, and use that as prior for PDA.</li>
<li><em>pda.create.ensemble</em> gets an ensemble ID for the PDA. All model runs associated with an individual PDA (any of the three methods) are considered part of a single ensemble. This function does is register a new ensemble in BETY, and return the ID that BETY gives it.</li>
<li><em>pda.define.prior.fn</em> creates R functions for all of the priors the PDA will use.</li>
<li><em>pda.init.params</em> sets up the parameter matrix for the run, which has one row per iteration, and one column per parameter. Columns include all Pecan parameters, not just the (probably small) subset that are being updated by PDA. This is for compatibility with other Pecan components. If starting a fresh run, the returned matrix is just a big empty matrix to fill in as the PDA runs. If continuing an existing MCMC, then it will be the previous params matrix, with a bunch of blank rows added on for filling in during this round of PDA.</li>
<li><em>pda.init.run</em> This is basically a big wrapper for Pecan’s write.config function (actually functions [plural], since every model in Pecan has its own version). For the bruteforce and bruteforce.bs methods this will be run once per iteration, whereas the emulator method knows about all its runs ahead of time and this will be a big batch of all runs at once.</li>
<li><em>pda.adjust.jumps</em> tweaks the jump distributions for the standard MCMC method, and <em>pda.adjust.jumps.bs</em> does the same for the block-sampled version.</li>
<li><em>pda.calc.llik</em> calculates the log-likelihood of the model given all datasets provided to compare it to.</li>
<li><em>pda.generate.knots</em> is for the emulator version of PDA. It uses a Latin hypercube design to sample a specified number of locations in parameter space. These locations are where the model will actually be run, and then the GP interpolates the likelihood surface in between.</li>
<li><em>pda.plot.params</em> provides basic MCMC diagnostics (trace and density) for parameters being sampled.</li>
<li><em>pda.postprocess</em> prepares the posteriors of the PDA, stores them to files and the database, and performs some other cleanup functions.</li>
<li><em>pda.load.data.r</em> This is the function that loads in data that will be used to constrain the PDA. It’s supposed to be eventually more integrated with Pecan, which will know how to load all kinds of data from all kinds of sources. For now, it can do NEE from Ameriflux.</li>
<li><em>pda.define.llik.r</em> A simple helper function that defines likelihood functions for different datasets. Probably in the future this should be queried from the database or something. For now, it is extremely limited. The original test case of NEE assimilation uses a heteroskedastic Laplacian distribution.</li>
<li><em>pda.get.model.output.R</em> Another function that will eventually grow to handle many more cases, or perhaps be replaced by a better system altogether. For now though, it again just handles Ameriflux NEE.</li>
</ul>
</div>
<div id="get.da.data..r-plot.da.r" class="section level4">
<h4><span class="header-section-number">7.2.1.6</span> <strong>get.da.data.*.R, plot.da.R</strong></h4>
<p>Old codes written by Carl Davidson. Defunct now, but may contain good ideas so currently left in.</p>
</div>
</div>
<div id="sda" class="section level3">
<h3><span class="header-section-number">7.2.2</span> State data assimilation (SDA)</h3>
<p><code>sda.enkf.R</code> is housed within: <code>/pecan/modules/assim.sequential/R</code></p>
<p>The tree ring tutorial is housed within: <code>/pecan/documentation/tutorials/StateAssimilation</code></p>
<p>More descriptive SDA methods can be found at: <code>/pecan/book_source/adve_user_guide_web/SDA_Methods.Rmd</code></p>
<div id="sda.enkf.r-description" class="section level4">
<h4><span class="header-section-number">7.2.2.1</span> <strong>sda.enkf.R Description</strong></h4>
<p>This is the main ensemble Kalman filter and generalized filter code. Originally, this was just ensemble Kalman filter code. Mike Dietze and Ann Raiho added a generalized ensemble filter to avoid filter divergence. The output of this function will be all the of run outputs, a PDF of diagnostics, and an Rdata object that includes three lists:</p>
<ul>
<li>FORECAST will be the ensemble forecasts for each year</li>
<li>ANALYSIS will be the updated ensemble sample given the NPP observations</li>
<li>enkf.params contains the prior and posterior mean vector and covariance matrix for each time step.</li>
</ul>
</div>
<div id="sda.enkf.r-arguments" class="section level4">
<h4><span class="header-section-number">7.2.2.2</span> <strong>sda.enkf.R Arguments</strong></h4>
<ul>
<li><p>settings - (required) <a href="intermediate-user.html#state-data-assimilation-tags-example">State Data Assimilation Tags Example</a> settings object</p></li>
<li><p>obs.mean - (required) a list of observation means named with dates in YYYY/MM/DD format</p></li>
<li><p>obs.cov - (required) a list of observation covariances names with dates in YYYY/MM/DD format</p></li>
<li><p>IC - (optional) initial condition matrix (dimensions: ensemble memeber # by state variables). Default is NULL.</p></li>
<li><p>Q - (optional) process covariance matrix (dimensions: state variable by state variables). Defualt is NULL.</p></li>
</ul>
</div>
<div id="state-data-assimilation-workflow" class="section level4">
<h4><span class="header-section-number">7.2.2.3</span> State Data Assimilation Workflow</h4>
<p>Before running sda.enkf, these tasks must be completed (in no particular order),</p>
<ul>
<li><p>Read in a <a href="intermediate-user.html#state-data-assimilation-tags-example">State Data Assimilation Tags Example</a> settings file with tags listed below. i.e. read.settings(‘pecan.SDA.xml’)</p></li>
<li><p>Load data means (obs.mean) and covariances (obs.cov) as lists with PEcAn naming and unit conventions. Each observation must have a date in YYYY/MM/DD format (optional time) associated with it. If there are missing data, the date must still be represented in the list with an NA as the list object.</p></li>
<li><p>Create initial conditions matrix (IC) that is state variables columns by ensemble members rows in dimension. <a href="intermediate-user.html#sample.ic.model.r">sample.IC.MODEL</a> can be used to create the IC matrix, but it is not required. This IC matrix is fed into write.configs for the initial model runs.</p></li>
</ul>
<p>The main parts of the SDA function are:</p>
<p>Setting up for initial runs:</p>
<ul>
<li><p>Set parameters</p></li>
<li><p>Load initial run inputs via <a href="intermediate-user.html#split.inputs.model.r">split.inputs.MODEL</a></p></li>
<li><p>Open database connection</p></li>
<li><p>Get new workflow ids</p></li>
<li><p>Create ensemble ids</p></li>
</ul>
<p>Performing the initial set of runs</p>
<p>Set up for data assimilation</p>
<p>Loop over time</p>
<ul>
<li><p><a href="intermediate-user.html#read.restart.model.r">read.restart.MODEL</a> - read model restart files corresponding to start.time and stop.time that you want to assimilate data into</p></li>
<li><p>Analysis - There are four choices based on if process variance is TRUE or FALSE and if there is data or not. <a href="intermediate-user.html#analysis-options">See explaination below.</a></p></li>
<li><p><a href="intermediate-user.html#write.restart.model.r">write.restart.MODEL</a> - This function has two jobs. First, to insert adjusted state back into model restart file. Second, to update start.time, stop.time, and job.sh.</p></li>
<li><p>run model</p></li>
</ul>
<p>Save outputs</p>
<p>Create diagnostics</p>
</div>
<div id="state-data-assimilation-tags-example" class="section level4">
<h4><span class="header-section-number">7.2.2.4</span> State Data Assimilation Tags Example</h4>
<pre><code>&lt;state.data.assimilation&gt;
  &lt;adjustment&gt;TRUE&lt;/adjustment&gt;
  &lt;process.variance&gt;FALSE&lt;/process.variance&gt;
  &lt;sample.parameters&gt;FALSE&lt;/sample.parameters&gt;
  &lt;q.type&gt;Single&lt;/q.type&gt;
   &lt;state.variables&gt;
    &lt;variable&gt;
      &lt;variable.name&gt;AGB.pft&lt;/variable.name&gt;
      &lt;unit&gt;MgC/ha/yr&lt;/unit&gt;
      &lt;min_value&gt;0&lt;/min_value&gt;
      &lt;max_value&gt;100000000&lt;/max_value&gt;
    &lt;/variable&gt;
    &lt;variable&gt;
      &lt;variable.name&gt;TotSoilCarb&lt;/variable.name&gt;
      &lt;unit&gt;KgC/m^2&lt;/unit&gt;
      &lt;min_value&gt;0&lt;/min_value&gt;
      &lt;max_value&gt;100000000&lt;/max_value&gt;
    &lt;/variable&gt;
  &lt;/state.variables&gt;
  &lt;spin.up&gt;
    &lt;start.date&gt;1950/01/01&lt;/start.date&gt;
    &lt;end.date&gt;1960/12/31&lt;/end.date&gt;
  &lt;/spin.up&gt;
  &lt;forecast.time.step&gt;1&lt;/forecast.time.step&gt;
  &lt;start.date&gt;1961/01/01&lt;/start.date&gt;
  &lt;end.date&gt;2010/12/31&lt;/end.date&gt;
 &lt;/state.data.assimilation&gt;</code></pre>
</div>
<div id="state-data-assimilation-tags-descriptions" class="section level4">
<h4><span class="header-section-number">7.2.2.5</span> State Data Assimilation Tags Descriptions</h4>
<ul>
<li><strong>adjustment</strong> : [optional] TRUE/FLASE flag for if ensembles needs to be adjusted based on weights estimated given their likelihood during analysis step. The defualt is TRUE for this flag.</li>
<li><strong>process.variance</strong> : [optional] TRUE/FLASE flag for if process variance should be estimated (TRUE) or not (FALSE). If TRUE, a generalized ensemble filter will be used. If FALSE, an ensemble Kalman filter will be used. Default is FALSE. If you use the TRUE argument you can set three more optional tags to control the MCMCs built for the generalized esnsemble filter.</li>
<li><strong>nitrGEF</strong> : [optional] numeric defining the length of the MCMC chains.</li>
<li><strong>nthin</strong> : [optional] numeric defining thining length for the MCMC chains.</li>
<li><strong>nburnin</strong> : [optional] numeric defining the number of burnins during the MCMCs.</li>
<li><strong>q.type</strong> : [optional] If the <code>process.variance</code> is set to TRUE then this can take values of Single, Site or PFT.</li>
<li><p><strong>censored.data</strong> : [optional] logical set TRUE for censored state variables.</p></li>
<li><strong>sample.parameters</strong> : [optional] TRUE/FLASE flag for if parameters should be sampled for each ensemble member or not. This allows for more spread in the initial conditions of the forecast.</li>
<li><strong>state.variable</strong> : [required] State variable that is to be assimilated (in PEcAn standard format).</li>
<li><strong>spin.up</strong> : [required] start.date and end.date for initial model runs.</li>
<li><strong><em>NOTE:</em></strong> start.date and end.date are distinct from values set in the run tag because initial runs can be done over a subset of the full run.</li>
<li><strong>forecast.time.step</strong> : [optional] In the future, this will be used to allow the forecast time step to vary from the data time step.</li>
<li><strong>start.date</strong> : [optional] start date of the state data assimilation (in YYYY/MM/DD format)</li>
<li><strong>end.date</strong> : [optional] end date of the state data assimilation (in YYYY/MM/DD format)</li>
<li><p><strong><em>NOTE:</em></strong> start.date and end.date are distinct from values set in the run tag because this analysis can be done over a subset of the run.</p></li>
</ul>
</div>
<div id="model-specific-functions-for-sda-workflow" class="section level4">
<h4><span class="header-section-number">7.2.2.6</span> Model Specific Functions for SDA Workflow</h4>
</div>
<div id="read.restart.model.r" class="section level4">
<h4><span class="header-section-number">7.2.2.7</span> read.restart.MODEL.R</h4>
<p>The purpose of read.restart is to read model restart files and return a matrix that is site rows by state variable columns. The state variables must be in PEcAn names and units. The arguments are:</p>
<ul>
<li><p>outdir - output directory</p></li>
<li><p>runid - ensemble member run ID</p></li>
<li><p>stop.time - used to determine which restart file to read (in POSIX format)</p></li>
<li><p>settings - <a href="intermediate-user.html#state-data-assimilation-tags-example">pecan.SDA.xml</a> settings object</p></li>
<li><p>var.names - vector with state variable names with PEcAn standard naming. Example: c(‘AGB.pft’, ‘TotSoilCarb’)</p></li>
<li><p>params - parameters used by ensemble member (same format as write.configs)</p></li>
</ul>
</div>
<div id="write.restart.model.r" class="section level4">
<h4><span class="header-section-number">7.2.2.8</span> write.restart.MODEL.R</h4>
<p>This model specific function takes in new state and new parameter matrices from sda.enkf.R after the analysis step and translates new variables back to the model variables. Then, updates start.time, stop.time, and job.sh so that start.model.runs() does the correct runs with the new states. In write.restart.LINKAGES and write.restart.SIPNET, job.sh is updated by using write.configs.MODEL.</p>
<ul>
<li><p>outdir - output directory</p></li>
<li><p>runid - run ID for ensemble member</p></li>
<li><p>start.time - beginning of model run (in POSIX format)</p></li>
<li><p>stop.time - end of model run (in POSIX format)</p></li>
<li><p>settings - <a href="intermediate-user.html#state-data-assimilation-tags-example">pecan.SDA.xml</a> settings object</p></li>
<li><p>new.state - matrix from analysis of updated state variables with PEcAn names (dimensions: site rows by state variables columns)</p></li>
<li><p>new.params - In the future, this will allow us to update parameters based on states (same format as write.configs)</p></li>
<li><p>inputs - model specific inputs from <a href="intermediate-user.html#split.inputs.model.r">split.inputs.MODEL</a> used to run the model from start.time to stop.time</p></li>
<li><p>RENAME - [optional] Flag used in write.restart.LINKAGES.R for development.</p></li>
</ul>
</div>
<div id="split.inputs.model.r" class="section level4">
<h4><span class="header-section-number">7.2.2.9</span> split.inputs.MODEL.R</h4>
<p>This model specific function gives the correct met and/or other model inputs to settings<span class="math inline">\(run\)</span>inputs. This function returns settings<span class="math inline">\(run\)</span>inputs to an inputs argument in sda.enkf.R. But, the inputs will not need to change for all models and should return settings<span class="math inline">\(run\)</span>inputs unchanged if that is the case.</p>
<ul>
<li><p>settings - <a href="intermediate-user.html#state-data-assimilation-tags-example">pecan.SDA.xml</a> settings object</p></li>
<li><p>start.time - start time for model run (in POSIX format)</p></li>
<li><p>stop.time - stop time for model run (in POSIX format)</p></li>
</ul>
</div>
<div id="sample.ic.model.r" class="section level4">
<h4><span class="header-section-number">7.2.2.10</span> sample.IC.MODEL.R</h4>
<p>This model specific function is optional. But, it can be used to create initial condition matrix (IC) with # state variables columns by # ensemble rows. This IC matrix is used for the initial runs in sda.enkf.R in the write.configs.MODEL function.</p>
<ul>
<li><p>ne - number of ensemble members</p></li>
<li><p>state - matrix of state variables to get initial conditions from</p></li>
<li><p>year - used to determine which year to sample initial conditions from</p></li>
</ul>
</div>
<div id="analysis-options" class="section level4">
<h4><span class="header-section-number">7.2.2.11</span> Analysis Options</h4>
<p>There are four options depending on whether process variance is TRUE/FALSE and whether or not there is data or not.</p>
<ul>
<li><p>If there is no data and process variance = FALSE, there is no analysis step.</p></li>
<li><p>If there is no data and process variance = TRUE, process variance is added to the forecast.</p></li>
<li><p>If there is data and process variance = TRUE, <a href="intermediate-user.html#the-generalized-ensemble-filter">the generalized ensemble filter</a> is implemented with MCMC.</p></li>
<li><p>If there is data and process variance = FALSE, the Kalman filter is used and solved analytically.</p></li>
</ul>
</div>
<div id="the-generalized-ensemble-filter" class="section level4">
<h4><span class="header-section-number">7.2.2.12</span> The Generalized Ensemble Filter</h4>
<p>An ensemble filter is a sequential data assimilation algorithm with two procedures at every time step: a forecast followed by an analysis. The forecast ensembles arise from a model while the analysis makes an adjustment of the forecasts ensembles from the model towards the data. An ensemble Kalman filter is typically suggested for this type of analysis because of its computationally efficient analytical solution and its ability to update states based on an estimate of covariance structure. But, in some cases, the ensemble Kalman filter fails because of filter divergence. Filter divergence occurs when forecast variability is too small, which causes the analysis to favor the forecast and diverge from the data. Models often produce low forecast variability because there is little internal stochasticity. Our ensemble filter overcomes this problem in a Bayesian framework by including an estimation of model process variance. This methodology also maintains the benefits of the ensemble Kalman filter by updating the state vector based on the estimated covariance structure.</p>
<p>This process begins after the model is spun up to equilibrium.</p>
<p>The likelihood function uses the data vector <span class="math inline">\(\left(\boldsymbol{y_{t}}\right)\)</span> conditional on the estimated state vector <span class="math inline">\(\left(\boldsymbol{x_{t}}\right)\)</span> such that</p>
<p><span class="math inline">\(\boldsymbol{y}_{t}\sim\mathrm{multivariate\:normal}(\boldsymbol{x}_{t},\boldsymbol{R}_{t})\)</span></p>
<p>where <span class="math inline">\(\boldsymbol{R}_{t}=\boldsymbol{\sigma}_{t}^{2}\boldsymbol{I}\)</span> and <span class="math inline">\(\boldsymbol{\sigma}_{t}^{2}\)</span> is a vector of data variances. To obtain an estimate of the state vector <span class="math inline">\(\left(\boldsymbol{x}_{t}\right)\)</span>, we use a process model that incorporates a process covariance matrix <span class="math inline">\(\left(\boldsymbol{Q}_{t}\right)\)</span>. This process covariance matrix differentiates our methods from past ensemble filters. Our process model contains the following equations</p>
<p><span class="math inline">\(\boldsymbol{x}_{t} \sim \mathrm{multivariate\: normal}(\boldsymbol{x}_{model_{t}},\boldsymbol{Q}_{t})\)</span></p>
<p><span class="math inline">\(\boldsymbol{x}_{model_{t}} \sim \mathrm{multivariate\: normal}(\boldsymbol{\mu}_{forecast_{t}},\boldsymbol{P}_{forecast_{t}})\)</span></p>
<p>where <span class="math inline">\(\boldsymbol{\mu}_{forecast_{t}}\)</span> is a vector of means from the ensemble forecasts and <span class="math inline">\(\boldsymbol{P}_{forecast_{t}}\)</span> is a covariance matrix calculated from the ensemble forecasts. The prior for our process covariance matrix is <span class="math inline">\(\boldsymbol{Q}_{t}\sim\mathrm{Wishart}(\boldsymbol{V}_{t},n_{t})\)</span> where <span class="math inline">\(\boldsymbol{V}_{t}\)</span> is a scale matrix and <span class="math inline">\(n_{t}\)</span> is the degrees of freedom. The prior shape parameters are updated at each time step through moment matching such that</p>
<p><span class="math inline">\(\boldsymbol{V}_{t+1} = n_{t}\bar{\boldsymbol{Q}}_{t}\)</span></p>
<p><span class="math inline">\(n_{t+1} = \frac{\sum_{i=1}^{I}\sum_{j=1}^{J}\frac{v_{ijt}^{2}+v_{iit}v_{jjt}}{Var(\boldsymbol{\bar{Q}}_{t})}}{I\times J}\)</span></p>
<p>where we calculate the mean of the process covariance matrix <span class="math inline">\(\left(\bar{\boldsymbol{Q}_{t}}\right)\)</span> from the posterior samples at time t. Degrees of freedom for the Wishart are typically calculated element by element where <span class="math inline">\(v_{ij}\)</span> are the elements of <span class="math inline">\(\boldsymbol{V}_{t}\)</span>. <span class="math inline">\(I\)</span> and <span class="math inline">\(J\)</span> index rows and columns of <span class="math inline">\(\boldsymbol{V}\)</span>. Here, we calculate a mean number of degrees of freedom for <span class="math inline">\(t+1\)</span> by summing over all the elements of the scale matrix <span class="math inline">\(\left(\boldsymbol{V}\right)\)</span> and dividing by the count of those elements <span class="math inline">\(\left(I\times J\right)\)</span>. We fit this model sequentially through time in the R computing environment using R package ‘rjags.’</p>
<p>Users have control over how they think is the best way to estimate <span class="math inline">\(Q\)</span>. Our code will look for the tag <code>q.type</code> in the XML settings under <code>state.data.assimilation</code> which can take 3 values of Single, PFT or Site. If <code>q.type</code> is set to single then one value of process variance will be estimated across all different sites or PFTs. On the other hand, when q.type` is set to Site or PFT then a process variance will be estimated for each site or PFT at a cost of more time and computation power.</p>
</div>
<div id="multi-site-state-data-assimilation." class="section level4">
<h4><span class="header-section-number">7.2.2.13</span> Multi-site State data assimilation.</h4>
<p><code>sda.enkf.multisite</code> function allows for assimilation of observed data at multiple sites at the same time. In order to run a multi-site SDA, one needs to send a multisettings pecan xml file to this function. This multisettings xml file needs to contain information required for running at least two sites under <code>run</code> tag. The code will automatically run the ensembles for all the sites and reformats the outputs matching the required formats for analysis step.</p>
<p>The observed mean and cov needs to be formatted as list of different dates with observations. For each element of this list also there needs to be a list with mean and cov matrices of different sites named by their siteid. In case that zero variance was estimated for a variable inside the obs.cov, the SDA code will automatically replace that with half of the minimum variance from other non-zero variables in that time step.</p>
<p>This would look like something like this:</p>
<pre><code>&gt; obs.mean

$`2010/12/31`
$`2010/12/31`$`1000000650`
   AbvGrndWood     GWBI
    111.502    1.0746

$`2010/12/31`$`1000000651`
   AbvGrndWood     GWBI
    114.302    1.574695</code></pre>
<pre><code>&gt; obs.cov

$`2010/12/31`
$`2010/12/31`$`1000000650`
           [,1]        [,2]
[1,] 19.7821691 0.213584319
[2,]  0.5135843 0.005162113

$`2010/12/31`$`1000000651`
           [,1]        [,2]
[1,] 15.2821691 0.513584319
[2,]  0.1213583 0.001162113</code></pre>
<p>An example of multi-settings pecan xml file also may look like below:</p>
<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;pecan.multi&gt;
 &lt;state.data.assimilation&gt;
   &lt;process.variance&gt;FALSE&lt;/process.variance&gt;
   &lt;adjustment&gt;TRUE&lt;/adjustment&gt;
   &lt;data&gt;
    &lt;format_id&gt;1000000040&lt;/format_id&gt;
    &lt;input.id&gt;1000013298&lt;/input.id&gt;
  &lt;/data&gt;
   &lt;state.variables&gt;
   &lt;variable&gt;
      &lt;variable.name&gt;GWBI&lt;/variable.name&gt;
   &lt;unit&gt;KgC/m^2&lt;/unit&gt;
       &lt;min_value&gt;0&lt;/min_value&gt;
       &lt;max_value&gt;9999&lt;/max_value&gt;
   &lt;/variable&gt;
   &lt;variable&gt;
   &lt;variable.name&gt;AbvGrndWood&lt;/variable.name&gt;
   &lt;unit&gt;KgC/m^2&lt;/unit&gt;
   &lt;min_value&gt;0&lt;/min_value&gt;
   &lt;max_value&gt;9999&lt;/max_value&gt;
   &lt;/variable&gt;
   &lt;/state.variables&gt;
  &lt;start.date&gt;1960/01/01&lt;/start.date&gt;
  &lt;end.date&gt;2000/12/31&lt;/end.date&gt;
  &lt;/state.data.assimilation&gt;
 &lt;info&gt;
    &lt;notes&gt;&lt;/notes&gt;
    &lt;userid&gt;-1&lt;/userid&gt;
    &lt;username&gt;&lt;/username&gt;
    &lt;date&gt;2017/12/06 21:19:33 +0000&lt;/date&gt;
  &lt;/info&gt;
 &lt;outdir&gt;/fs/data3/hamzed/output/MultiSite_Sandbox/paleon_sda_SIPNET-8768&lt;/outdir&gt;
 &lt;database&gt;
    &lt;bety&gt;
      &lt;user&gt;bety&lt;/user&gt;
      &lt;password&gt;bety&lt;/password&gt;
      &lt;host&gt;128.197.168.114&lt;/host&gt;
      &lt;dbname&gt;bety&lt;/dbname&gt;
      &lt;driver&gt;PostgreSQL&lt;/driver&gt;
      &lt;write&gt;false&lt;/write&gt;
    &lt;/bety&gt;
    &lt;dbfiles&gt;/fs/data1/pecan.data/dbfiles/&lt;/dbfiles&gt;
  &lt;/database&gt;
 &lt;pfts&gt;
  &lt;pft&gt;
   &lt;name&gt;temperate.deciduous_SDA&lt;/name&gt;
   &lt;constants&gt;
    &lt;num&gt;2&lt;/num&gt;
   &lt;/constants&gt;
   &lt;outdir&gt;/fs/data2/output//PEcAn_1000008768/pft/temperate.deciduous_SDA&lt;/outdir&gt;
   &lt;posteriorid&gt;1000008552&lt;/posteriorid&gt;
  &lt;/pft&gt;
 &lt;/pfts&gt;
 &lt;meta.analysis&gt;
    &lt;iter&gt;3000&lt;/iter&gt;
    &lt;random.effects&gt;
      &lt;on&gt;FALSE&lt;/on&gt;
      &lt;use_ghs&gt;TRUE&lt;/use_ghs&gt;
    &lt;/random.effects&gt;
  &lt;/meta.analysis&gt;
 &lt;ensemble&gt;
  &lt;size&gt;20&lt;/size&gt;
  &lt;ensemble.id&gt;1000016146&lt;/ensemble.id&gt;
  &lt;start.year&gt;1995&lt;/start.year&gt;
  &lt;end.year&gt;1999&lt;/end.year&gt;
  &lt;samplingspace&gt;
  &lt;parameters&gt;
    &lt;method&gt;uniform&lt;/method&gt;
  &lt;/parameters&gt;
  &lt;met&gt;
    &lt;method&gt;sampling&lt;/method&gt;
  &lt;/met&gt;
  &lt;soil&gt;    
  &lt;parent&gt;parameters&lt;/parent&gt;
  &lt;/soil&gt;
  &lt;vegetation&gt;
  &lt;parent&gt;soil&lt;/parent&gt;
  &lt;/vegetation&gt;
  &lt;/samplingspace&gt;
 &lt;/ensemble&gt;
 &lt;model&gt;
  &lt;id&gt;1000000022&lt;/id&gt;
  &lt;default.param&gt;/fs/data3/hamzed/output/paleon_sda_SIPNET-8768/Bartlett.param&lt;/default.param&gt;
  &lt;type&gt;SIPNET&lt;/type&gt;
  &lt;revision&gt;r136&lt;/revision&gt;
  &lt;delete.raw&gt;FALSE&lt;/delete.raw&gt;
  &lt;binary&gt;/fs/data5/pecan.models/SIPNET/trunk/sipnet_ssr&lt;/binary&gt;
 &lt;/model&gt;
 &lt;workflow&gt;
    &lt;id&gt;1000008768&lt;/id&gt;
  &lt;/workflow&gt;
 &lt;run&gt;
  &lt;settings.1000000650&gt;
  &lt;site&gt;
   &lt;id&gt;1000000650&lt;/id&gt;
   &lt;met.start&gt;1960/01/01&lt;/met.start&gt;
   &lt;met.end&gt;1965/12/31&lt;/met.end&gt;
   &lt;name&gt;Harvard Forest - Lyford Plots (PalEON PHA)&lt;/name&gt;
   &lt;lat&gt;42.53&lt;/lat&gt;
   &lt;lon&gt;-72.18&lt;/lon&gt;
  &lt;/site&gt;
  &lt;inputs&gt;
   &lt;met&gt;
    &lt;source&gt;CRUNCEP&lt;/source&gt;
    &lt;output&gt;SIPNET&lt;/output&gt;
    &lt;path&gt;
    &lt;path1&gt;/fs/data1/pecan.data/dbfiles/CRUNCEP_SIPNET_site_0-758/CRUNCEP.1960-01-01.2010-12-31.clim&lt;/path1&gt;
    &lt;/path&gt;
   &lt;/met&gt;
  &lt;/inputs&gt;
  &lt;start.date&gt;1960/01/01&lt;/start.date&gt;
  &lt;end.date&gt;1980/12/31&lt;/end.date&gt;
  &lt;/settings.1000000650&gt;
  &lt;settings.1000000651&gt;
  &lt;site&gt;
   &lt;id&gt;1000000651&lt;/id&gt;
   &lt;met.start&gt;1960/01/01&lt;/met.start&gt;
   &lt;met.end&gt;1965/12/31&lt;/met.end&gt;
   &lt;name&gt;Harvard Forest - Lyford Plots (PalEON PHA)&lt;/name&gt;
   &lt;lat&gt;42.53&lt;/lat&gt;
   &lt;lon&gt;-72.18&lt;/lon&gt;
  &lt;/site&gt;
  &lt;inputs&gt;
   &lt;met&gt;
    &lt;source&gt;CRUNCEP&lt;/source&gt;
    &lt;output&gt;SIPNET&lt;/output&gt;
    &lt;path&gt;
    &lt;path1&gt;/fs/data1/pecan.data/dbfiles/CRUNCEP_SIPNET_site_0-758/CRUNCEP.1960-01-01.2010-12-31.clim&lt;/path1&gt;
    &lt;/path&gt;
   &lt;/met&gt;
  &lt;/inputs&gt;
  &lt;start.date&gt;1960/01/01&lt;/start.date&gt;
  &lt;end.date&gt;1980/12/31&lt;/end.date&gt;
  &lt;/settings.1000000651&gt;
 &lt;/run&gt;
 &lt;host&gt;
  &lt;name&gt;localhost&lt;/name&gt;
  &lt;rundir&gt;/fs/data3/hamzed/output/MultiSite_Sandbox/paleon_sda_SIPNET-8768/run&lt;/rundir&gt;
  &lt;outdir&gt;/fs/data3/hamzed/output/MultiSite_Sandbox/paleon_sda_SIPNET-8768/out&lt;/outdir&gt;
 &lt;/host&gt;
 &lt;settings.info&gt;
  &lt;deprecated.settings.fixed&gt;TRUE&lt;/deprecated.settings.fixed&gt;
  &lt;settings.updated&gt;TRUE&lt;/settings.updated&gt;
  &lt;checked&gt;TRUE&lt;/checked&gt;
 &lt;/settings.info&gt;
 &lt;rundir&gt;/fs/data3/hamzed/output/MultiSite_Sandbox/paleon_sda_SIPNET-8768/run&lt;/rundir&gt;
 &lt;modeloutdir&gt;/fs/data3/hamzed/output/MultiSite_Sandbox/paleon_sda_SIPNET-8768/out&lt;/modeloutdir&gt;
 &lt;multisettings&gt;run&lt;/multisettings&gt;
&lt;/pecan.multi&gt;</code></pre>
</div>
</div>
<div id="running-sda-on-remote" class="section level3">
<h3><span class="header-section-number">7.2.3</span> Running SDA on remote</h3>
<p>In general, the idea is that sending, running and monitoring an SDA job should all be done using two functions (<code>SDA_remote_launcher</code> and <code>Remote_Sync_launcher</code>). <code>SDA_remote_launcher</code> checks the XML settings defining the run, sets up the SDA on the remote machine, and then sends a qusb command for running the job. <code>Remote_Sync_launcher</code>, on the other hand, sits on the local machine and monitors the progress of the job(s) and brings back the outputs as long as the job is running.</p>
<p><code>SDA_remote_launcher</code> sets up the job by copying a template SDA workflow R script and a bash file template that are ready for submission to the remote machine. This function checks the paths to all inputs including met, soil, <code>site_pft</code> and etc., testing whether they exists on the remote machine or not. If they do not exist, the function copies the missing paths over and replaces the settings accordingly. After submitting the bash script, the function returns the PID of the job writing the log file, allowing the <code>Remote_Sync_launcher</code> to monitor the progress of the run, checks to see if the job is still alive, and determines if <code>sda.output.rdata</code> has been updated since the last check or not.</p>
<p><code>Additionally, the Remote_Sync_launcher</code> function follows the progress of the remote job by executing a nohup command on a template R script and keeps the R console open for further use. This R script, as mentioned above, constantly pings the given PID every 5 minutes and copies over the SDA output.</p>
<p>Several points on how to prepare your xml settings for the remote SDA run:
1 - In the main pecan workflow.R, if you were able to generate <code>pecan.TRAIT.xml</code>, your settings are ready to be used for an SDA run. All you need to add is your state data assimilation tags.
2 - Inside the xml setting an <code>&lt;outdir&gt;</code> flag needs to be included and point to a local directory where <code>SDA_remote_launcher</code> will look for either a <code>sample.Rdata</code> file or a <code>pft</code> folder.
3 - You need to set your <code>&lt;host&gt;</code> tag according to the desired remote machine. You can learn more about this on the <code>Remote execution with PEcAn</code> section of the documentation. Please make sure that the <code>&lt;folder&gt;</code> tag inside <code>&lt;host&gt;</code> is pointing to a directory where you would like to store and run your SDA job(s).
4 - Finally, make sure the <binary> tag inside the <model> tag is set to the correct path on the remote machine.</p>
</div>
<div id="restart-functionality-in-sda" class="section level3">
<h3><span class="header-section-number">7.2.4</span> Restart functionality in SDA</h3>
<p>If you prefer to run your SDA analysis in multiple stages, where each phase picks up where the previous one left off, you can use the <code>restart</code> argument in the <code>sda.enkf.multisite</code> function. You need to make sure that the output from previous step exists in the <code>SDA</code> folder (in the <code>outfolder</code>), and the <code>&lt;start.date&gt;</code> is the same as <code>&lt;end.date&gt;</code> from the previous step. When you run the SDA with the restart parameter, it will load the output from the previous step and use configs already written in the run folder to set itself up for the next step. Using the restart argument could be as easy as :</p>
<pre><code>sda.enkf.multisite(settings,
                   obs.mean =obs.mean ,
                   obs.cov = obs.cov,
                   control = SDA.arguments(debug = FALSE, TimeseriesPlot = FALSE),
                   restart = FALSE
        )
</code></pre>
<p>Where the new <code>settings</code>, <code>obs.mean</code> and <code>obs.cov</code> contain the relevant information for the next phase.</p>
</div>
<div id="state-data-assimilation-methods" class="section level3">
<h3><span class="header-section-number">7.2.5</span> State Data Assimilation Methods</h3>
<p><em>By Ann Raiho</em></p>
<p>Our goal is build a fully generalizable state data assimilation (SDA) workflow that will assimilate multiple types of data and data products into ecosystem models within PEcAn temporally and spatially. But, during development, specifically with PalEON goals in mind, we have been focusing on assimilating tree ring estimated NPP and AGB and pollen derived fractional composition into two ecosystem models, SIPNET and LINKAGES, at Harvard Forest. This methodology will soon be expanded to include the PalEON sites listed on the <a href="https://paleon.geography.wisc.edu/doku.php/working_groups;state_data_assimilation">state data assimilation wiki page</a>.</p>
<div id="data-products" class="section level4">
<h4><span class="header-section-number">7.2.5.1</span> Data Products</h4>
<p>During workflow development, we have been working with tree ring estimated NPP and AGB and pollen derived fractional composition data products. Both of these data products have been estimated with a full accounting of uncertainty, which provides us with state variable observation mean vector and covariance matrix at each time step. These data products are discussed in more detail below. Even though we have been working with specific data products during development, our workflow is generalizable to alternative data products as long as we can calculate a state variable observation mean vector and covariance for a time point.</p>
</div>
<div id="tree-rings" class="section level4">
<h4><span class="header-section-number">7.2.5.2</span> Tree Rings</h4>
<p>We have been primarily been working with the tree ring data product created by Andria Dawson and Chris Paciorek and the PEcAn tree ring allometry module. They have developed a Bayesian model that estimates annual aboveground biomass increment (Mg/ha/yr) and aboveground biomass (Mg/ha) for each tree in a dataset. We obtain this data and aggregate to the level appropriate for the ecosystem model. In SIPNET, we are assimilating annual gross woody increment (Mg/ha/yr) and above ground woody biomass (Mg/ha). In LINKAGES, we are assimilating annual species biomass. More information on deriving these tree ring data products can be found in Dawson et al 201?.</p>
<p>We have been working mostly with tree data collected at Harvard Forest. Tree rings and census data were collected at Lyford Plot between 1960 and 2010 in three separate plots. Other tree ring data will be added to this analysis in the future from past PEON courses (UNDERC), Kelly Heilman (Billy’s Lake and Bigwoods), and Alex Dye (Huron Mt. Club).</p>
</div>
<div id="pollen" class="section level4">
<h4><span class="header-section-number">7.2.5.3</span> Pollen</h4>
<p>STEPPS is a Bayesian model developed by Paciorek and McLachlan 2009 and Dawson et al 2016 to estimate spatially gridded fractional composition from fossil pollen. We have been working with STEPPS1 output, specifically with the grid cell that contains Harvard Forest. The temporal resolution of this data product is centennial. Our workflow currently operates at annual time steps, but does not require data at every time step. So, it is possible to assimilate fractional composition every one hundred years or to assimilate fractional composition data every year by accounting for variance inflation.</p>
<p>In the future, pollen derived biomass (ReFAB) will also be available for data assimilation. Although, we have not discussed how STEPPS and ReFAB data assimilation will work.</p>
</div>
<div id="variance-inflation" class="section level4">
<h4><span class="header-section-number">7.2.5.4</span> Variance Inflation</h4>
<p>*Side Note: Probably want to call this something else now.</p>
<p>Since the fractional composition data product has a centennial resolution, in order to use fractional composition information every year we need to change the weight the data has on the analysis. The basic idea is to downweight the likelihood relative to the prior to account for (a) the fact that we assimilate an observation multiple times and (b) the fact that the number of STEPPS observations is ‘inflated’ because of the autocorrelation. To do this, we take the likelihood and raise it to the power of (1/w) where ‘w’ is an inflation factor.</p>
<p>w = D * (N / ESS)</p>
<p>where D is the length of the time step. In our case D = 100. N is the number of time steps. In our case N = 11. and ESS is the effective sample size. The ESS is calculated with the following function where ntimes is the same as N above and sims is a matrix with the dimensions number of MCMC samples by number of state variables.</p>
<pre><code>ESS_calc &lt;- function(ntimes, sims){
        # center based on mean at each time to remove baseline temporal correlation 
        # (we want to estimate effective sample size effect from correlation of the errors)
        row.means.sims &lt;- sims - rowMeans(sims)  
        
        # compute all pairwise covariances at different times
        covars &lt;- NULL
        for(lag in 1:(ntimes-1)){
          covars &lt;- c(covars, rowMeans(row.means.sims[(lag+1):ntimes, , drop = FALSE] * row.means.sims[1:(ntimes-lag), , drop = FALSE])) 
        }
        vars &lt;- apply(row.means.sims, 1, var) # pointwise post variances at each time, might not be homoscedastic
        
        # nominal sample size scaled by ratio of variance of an average
        # under independence to variance of average of correlated values
        neff &lt;- ntimes * sum(vars) / (sum(vars) + 2 * sum(covars))
        return(neff)
      }</code></pre>
<p>The ESS for the STEPPS1 data product is 3.6, so w in our assimilation of fractional composition at Harvard Forest will be w = 305.6.</p>
</div>
<div id="current-models" class="section level4">
<h4><span class="header-section-number">7.2.5.5</span> Current Models</h4>
<p>SIPNET and LINKAGES are the two ecosystem models that have been used during state data assimilation development within PEcAn. SIPNET is a simple ecosystem model that was built for… LINKAGES is a forest gap model created to simulate the process of succession that occurs when a gap is opened in the forest canopy. LINKAGES has 72 species level plant functional types and the ability to simulate some below ground processes (C and N cycles).</p>
</div>
<div id="model-calibration" class="section level4">
<h4><span class="header-section-number">7.2.5.6</span> Model Calibration</h4>
<p>Without model calibration both SIPNET and LINKAGES make incorrect predictions about Harvard Forest. To confront this problem, SIPNET and LINKAGES will both be calibrated using data collected at the Harvard Forest flux tower. Istem has completed calibration for SIPNET using a <a href="https://github.com/PecanProject/pecan/blob/develop/modules/assim.batch/R/pda.emulator.R">parameter data assimilation emulator</a> contained within the PEcAn workflow. LINKAGES will also be calibrated using this method. This method is also generalizable to other sites assuming there is data independent of data assimilation data available to calibrate against.</p>
</div>
<div id="initial-conditions" class="section level4">
<h4><span class="header-section-number">7.2.5.7</span> Initial Conditions</h4>
<p>The initial conditions for SIPNET are sampled across state space based on data distributions at the time when the data assimilation will begin. We do not sample LINAKGES for initial conditions and instead perform model spin up for 100 years prior to beginning data assimilation. In the future, we would like to estimate initial conditions based on data. We achieve adequate spread in the initial conditions by allowing the parameters to vary across ensemble members.</p>
</div>
<div id="drivers" class="section level4">
<h4><span class="header-section-number">7.2.5.8</span> Drivers</h4>
<p>We are currently using Global Climate Model (GCM) drivers from the PaLEON model intercomparison. Christy Rollinson and John Tipton are creating MET downscaled GCM drivers for the Paleon data assimilation sites. We will use these drivers when they are available because they are a closer representation of reality.</p>
</div>
<div id="sequential-state-data-assimilation" class="section level4">
<h4><span class="header-section-number">7.2.5.9</span> Sequential State Data Assimilation</h4>
<p>We are using sequential state data assimilation methods to assimilate paleon data products into ecosystem models because less computation power is required for sequential state data assimilation than for particle filter methods.</p>
</div>
<div id="general-description" class="section level4">
<h4><span class="header-section-number">7.2.5.10</span> General Description</h4>
<p>The general sequential data assimilation framework consists of three steps at each time step:
1. Read the state variable output for time t from the model forecast ensembles and save the forecast mean (muf) and covariance (Pf).
2. If there are data mean (y) and covariance (R) at this time step, perform data assimilation analysis (either EnKF or generalized ensemble filter) to calculate the new mean (mua) and covariance (Pa) of the state variables.
3. Use mua and Pa to restart and run the ecosystem model ensembles with new state variables for time t+1.</p>
</div>
<div id="enkf" class="section level4">
<h4><span class="header-section-number">7.2.5.11</span> EnKF</h4>
<p>There are two ways to implement sequential state data assimilation at this time. The first is the Ensemble Kalman Filter (EnKF). EnKF has an analytical solution, so the kalman gain, analysis mean vector, and analysis covariance matrix can be calculated directly:</p>
<pre><code>       
        K &lt;- Pf %*% t(H) %*% solve((R + H %*% Pf %*% t(H))) ## Kalman Gain
        
        mu.a &lt;- mu.f + K %*% (Y - H %*% mu.f) # Analysis mean vector
        
        Pa   &lt;- (diag(ncol(X)) - K %*% H) %*% Pf # Analysis covariance matrix
        </code></pre>
<p>The EnKF is typically used for sequential state data assimilation, but we found that EnKF lead to filter divergence when combined with our uncertain data products. Filter divergence led us to create a generalized ensemble filter that estimates process variance.</p>
</div>
<div id="generalized-ensemble-filter" class="section level4">
<h4><span class="header-section-number">7.2.5.12</span> Generalized Ensemble Filter</h4>
<p>The generalized ensemble filter follows generally the three steps of sequential state data assimilation. But, in the generalized ensemble filter we add a latent state vector that accounts for added process variance. Furthermore, instead of solving the analysis analytically like the EnKF, we have to estimate the mean analysis vector and covariance matrix with MCMC.</p>
</div>
<div id="mapping-ensemble-output-to-tobit-space" class="section level4">
<h4><span class="header-section-number">7.2.5.13</span> Mapping Ensemble Output to Tobit Space</h4>
<p>There are some instances when we have right or left censored variables from the model forecast. For example, a model estimating species level biomass may have several ensemble members that produce zero biomass for a given species. We are considering this case a left censored state variable that needs to be mapped to normal space using a tobit model. We do this by creating two matrices with dimensions number of ensembles by state variable. The first matrix is a matrix of indicator variables (y.ind), and the second is a matrix of censored variables (y.censored). When the indicator variable is 0 the state variable (j) for ensemble member (i) is sampled. This allows us to impute a normal distribution for each state variable that contains ‘missing’ forecasts or forecasts of zero.</p>
<pre><code>tobit2space.model &lt;- nimbleCode({
    for(i in 1:N){
      y.censored[i,1:J] ~ dmnorm(muf[1:J], cov = pf[1:J,1:J])
      for(j in 1:J){
        y.ind[i,j] ~ dconstraint(y.censored[i,j] &gt; 0)
      }
    }
    
    muf[1:J] ~ dmnorm(mean = mu_0[1:J], cov = pf[1:J,1:J])
    
    Sigma[1:J,1:J] &lt;- lambda_0[1:J,1:J]/nu_0
    pf[1:J,1:J] ~ dinvwish(S = Sigma[1:J,1:J], df = J)
    
  })</code></pre>
</div>
<div id="generalized-ensemble-filter-model-description" class="section level4">
<h4><span class="header-section-number">7.2.5.14</span> Generalized Ensemble Filter Model Description</h4>
<p>Below is the BUGS code for the full analysis model. The forecast mean an covariance are calculated from the tobit2space model above. We use a tobit likelihood in this model because there are instances when the data may be left or right censored. Process variance is included by adding a latent model state (X) with a process precision matrix (q). We update our prior on q at each time step using our estimate of q from the previous time step.</p>
<pre><code>  tobit.model &lt;- nimbleCode({ 
    
    q[1:N,1:N]  ~ dwish(R = aq[1:N,1:N], df = bq) ## aq and bq are estimated over time
    Q[1:N,1:N] &lt;- inverse(q[1:N,1:N])
    X.mod[1:N] ~ dmnorm(muf[1:N], prec = pf[1:N,1:N]) ## Model Forecast ##muf and pf are assigned from ensembles
    
    ## add process error
    X[1:N]  ~ dmnorm(X.mod[1:N], prec = q[1:N,1:N])
    
    #agb linear
    #y_star[1:YN,1:YN] &lt;- X[1:YN,1:YN] #[choose]
    
    #f.comp non linear
    #y_star[1:YN] &lt;- X[1:YN] / sum(X[1:YN])
    
    ## Analysis
    y.censored[1:YN] ~ dmnorm(X[1:YN], prec = r[1:YN,1:YN]) #is it an okay assumpution to just have X and Y in the same order?
    
    #don&#39;t flag y.censored as data, y.censored in inits
    #remove y.censored samplers and only assign univariate samplers on NAs
    
    for(i in 1:YN){
      y.ind[i] ~ dconstraint(y.censored[i] &gt; 0)
    }
    
  })</code></pre>
</div>
<div id="ensemble-adjustment" class="section level4">
<h4><span class="header-section-number">7.2.5.15</span> Ensemble Adjustment</h4>
<p>Each ensemble member has a different set of species parameters. We adjust the updated state variables by using an ensemble adjustment. The ensemble adjustment weights the ensemble members based on their likelihood during the analysis step.</p>
<pre><code>      S_f  &lt;- svd(Pf)
      L_f  &lt;- S_f$d
      V_f  &lt;- S_f$v
      
      ## normalize
      Z &lt;- X*0
      for(i in seq_len(nrow(X))){
          Z[i,] &lt;- 1/sqrt(L_f) * t(V_f)%*%(X[i,]-mu.f)
      }
      Z[is.na(Z)]&lt;-0
      
      ## analysis
      S_a  &lt;- svd(Pa)
      L_a  &lt;- S_a$d
      V_a  &lt;- S_a$v
      
      ## analysis ensemble
      X_a &lt;- X*0
      for(i in seq_len(nrow(X))){
        X_a[i,] &lt;- V_a %*%diag(sqrt(L_a))%*%Z[i,] + mu.a
      }</code></pre>
</div>
<div id="diagnostics" class="section level4">
<h4><span class="header-section-number">7.2.5.16</span> Diagnostics</h4>
<p>There are three diagnostics we have currently implemented: time series, bias time series, and process variance. The time series diagnostics show the data, forecast, and analysis time series for each state variable. These are useful for visually assessing variance and magnitude of change of state variables through time. These time series are also updated throughout the analysis and are also created as a pdf at the end of the SDA workflow. There are two types of bias time series the first assess the bias in the update (the forecast minus the analysis) and the second assess the bias in the error (the forecast minus the data). These bias time series are useful for identifying which state variables have intrinsic bias within the model. For example, if red oak biomass in LINKAGES increases at every time step (the update and the error are always positive), this would suggest that LINKAGES has a positive growth or recruitment bias for red oak. Finally, when using the generalized ensemble filter to estimate process variance, there are two additional plots to assess estimation of process variance. The first is a correlation plot of the process covariance matrix. This tells us what correlations are incorrectly represented by the model. For example, if red oak biomass and white pine biomass are highly negatively correlated in the process covariance matrix, this means that the model either 1) has no relationship between red oak and white pine and they should affect each other negatively or 2) there is a positive relationship between red oak and white pine and there shouldn’t be any relationship. We can determine which of these is true by comparing the process covariance matrix to the model covariance matrix. The second process variance diagnostic plot shows how the degrees of freedom associated with estimating the process covariance matrix have changed through time. This plot should show increasing degrees of freedom through time.</p>
</div>
</div>
<div id="multisettings" class="section level3">
<h3><span class="header-section-number">7.2.6</span> MultiSettings</h3>
<p>(TODO: Under construction…)</p>
</div>
<div id="benchmarking" class="section level3">
<h3><span class="header-section-number">7.2.7</span> Benchmarking</h3>
<p>Benchmarking is the process of comparing model outputs against either experimental data or against other model outputs as a way to validate model performance.
We have a suit of statistical comparisons that provide benchmarking scores as well as visual comparisons that help in diagnosing data-model and/or model-model differences.</p>
<div id="data-preparation" class="section level4">
<h4><span class="header-section-number">7.2.7.1</span> Data Preparation</h4>
<p>All data that you want to compare with model runs must be registered in the database.
This is currently a step that must be done by hand either from the command line or through the online BETY interface.
The data must have three records:</p>
<ol style="list-style-type: decimal">
<li><p>An input record (Instructions <a href="adding-to-pecan.html#NewInput">here</a>)</p></li>
<li><p>A database file record (Instructions <a href="adding-to-pecan.html#NewInput">here</a>)</p></li>
<li><p>A format record (Instructions <a href="adding-to-pecan.html#NewFormat">here</a>)</p></li>
</ol>
</div>
<div id="model-runs" class="section level4">
<h4><span class="header-section-number">7.2.7.2</span> Model Runs</h4>
<p>Model runs can be setup and executed
- Using the PEcAn web interface online or with a VM (<a href="#GettingStarted">see setup</a>)
- By hand using the <a href="pecanXML.html#pecanXML">pecan.xml</a></p>
</div>
<div id="the-benchmarking-shiny-app" class="section level4">
<h4><span class="header-section-number">7.2.7.3</span> The Benchmarking Shiny App</h4>
<p>The entire benchmarking process can be done through the Benchmarking R Shiny app.</p>
<p>When the model run has completed, navigate to the workflow visualization Shiny app.</p>
<ul>
<li>Load model data
<ul>
<li>Select the workflow and run id</li>
<li>Make sure that your model output is loading properly (i.e. you can see plots of your data)</li>
</ul></li>
<li>Load benchmarking data
<ul>
<li>Again make sure that you can see the uploaded data plotted alongside the model output. In the future there will be more tools for double checking that your uploaded data is appropriate for benchmarking, but for now you may need to do the sanity checks by hand.</li>
</ul></li>
</ul>
</div>
<div id="create-a-reference-run-record" class="section level4">
<h4><span class="header-section-number">7.2.7.4</span> Create a reference run record</h4>
<ul>
<li>Navigate to the Benchmarking tab
<ul>
<li>The first step is to register the new model run as a reference run in the database. Benchmarking cannot be done before this step is completed. When the reference run record has been created, additional menus for benchmarking will appear.</li>
</ul></li>
</ul>
</div>
<div id="setup-benchmarks-and-metrics" class="section level4">
<h4><span class="header-section-number">7.2.7.5</span> Setup Benchmarks and metrics</h4>
<ul>
<li>From the menus select
<ul>
<li>The variables in the uploaded data that you wish to compare with model output.</li>
<li>The numerical metrics you would like to use in your comparison.</li>
<li>Additional comparison plots that you would like to see.</li>
</ul></li>
<li>Note: All these selections populate the benchmarking section of the <code>pecan.BENCH.xml</code> which is then saved in the same location as the original run output. This xml is purely for reference.</li>
</ul>
<div id="benchmarking-output" class="section level5">
<h5><span class="header-section-number">7.2.7.5.1</span> Benchmarking Output</h5>
<ul>
<li>All benchmarking results are stored in the benchmarking directory which is created in the same folder as the original model run.</li>
<li>The benchmaking directory contains subdirectories for each of the datasets compared with the model output. The names of these directories are the same as the corresponding data set’s input id in BETY.</li>
<li>Each input directory contains <code>benchmarking.output.Rdata</code>, an Rdata file contianing all the results of the benchmarking workflow. <code>load(benchmarking.output.Rdata)</code> loads a list called <code>result.out</code> which contains the following:
<ul>
<li><code>bench.results</code>: a data frame of all numeric benchmarking scores</li>
<li><code>format</code>: a data frame that can be used to see how the input data was transformed to make it comparable to the model output. This involves converting from the original variable names and units to the internal pecan standard.</li>
<li><code>aligned.dat</code>: a data frame of the final aligned model and input values.</li>
</ul></li>
<li><p>All plots are saved as pdf files with names with “benchmark_plot-type_variable_input-id.pdf”</p></li>
<li><p>To view interactive results, naviage to the Benchmarking Plots tab in the shiny app.</p></li>
</ul>
</div>
</div>
<div id="benchmarking-in-pecan.xml" class="section level4">
<h4><span class="header-section-number">7.2.7.6</span> Benchmarking in pecan.xml</h4>
<p>Before reading this section, it is recommended that you <a href="pecanXML.html#pecanXML">familiarize yourself with basics of the pecan.xml file.</a></p>
<p>The <code>pecan.xml</code> has an <em>optional</em> benchmarking section. Below are all the tags in the benchmarking section explained. Many of these field are filled in automatically during the benchmarking process when using the benchmarking shiny app.</p>
<p>The only time one should edit the benchmarking section by hand is for performing clone runs. See <a href="#CloneRun">clone run documentation.</a></p>
<p><code>&lt;benchmarking&gt;</code> settings:</p>
<ul>
<li><code>ensemble_id</code>: the id of the ensemble that you will be using - the settings from this ensemble will be saved in a reference run record and then <code>ensemble_id</code> will be replaced with <code>reference_run_id</code></li>
<li><code>new_run</code>: TRUE = create new run, FALSE = use existing run (required, default FALSE)</li>
</ul>
<p>It is possible to look at more than one benchmark with a particular run.
The specific settings related to each benchmark are in a sub section called <code>benchmark</code></p>
<ul>
<li><code>input_id</code>: the id of the benchmarking data (required)</li>
<li><code>variable_id</code>: the id of the variable of interest within the data. If you leave this blank, all variables that are shared between the input and model output will be used.</li>
<li><code>metric_id</code>: the id(s) of the metric(s) to be calculated. If you leave this blank, all metrics will be used.</li>
</ul>
<p>Example:
In this example,
- we are using a pre-existing run from <code>ensemble_id = 1000010983</code> (<code>new_run = FALSE</code>)
- the output will be compared to data from <code>input_id = 1000013743</code>, specifically two variables of interest: <code>variable_id = 411, variable_id = 18</code>
- for <code>variable_id = 411</code> we will perform only one metric of comparison <code>metric_id = 1000000001</code>
- for for <code>variable_id = 18</code> we will perform two metrics of comparison <code>metric_id = 1000000001, metric_id = 1000000002</code></p>
<div class="sourceCode" id="cb73"><pre class="sourceCode xml"><code class="sourceCode xml"><a class="sourceLine" id="cb73-1" data-line-number="1"><span class="kw">&lt;benchmarking&gt;</span></a>
<a class="sourceLine" id="cb73-2" data-line-number="2">  <span class="kw">&lt;ensemble_id&gt;</span>1000010983<span class="kw">&lt;/ensemble_id&gt;</span></a>
<a class="sourceLine" id="cb73-3" data-line-number="3">  <span class="kw">&lt;new_run&gt;</span>FALSE<span class="kw">&lt;/new_run&gt;</span></a>
<a class="sourceLine" id="cb73-4" data-line-number="4">  <span class="kw">&lt;benchmark&gt;</span></a>
<a class="sourceLine" id="cb73-5" data-line-number="5">   <span class="kw">&lt;input_id&gt;</span>1000013743<span class="kw">&lt;/input_id&gt;</span></a>
<a class="sourceLine" id="cb73-6" data-line-number="6">   <span class="kw">&lt;variable_id&gt;</span>411<span class="kw">&lt;/variable_id&gt;</span></a>
<a class="sourceLine" id="cb73-7" data-line-number="7">   <span class="kw">&lt;site_id&gt;</span>853<span class="kw">&lt;/site_id&gt;</span></a>
<a class="sourceLine" id="cb73-8" data-line-number="8">   <span class="kw">&lt;metrics&gt;</span></a>
<a class="sourceLine" id="cb73-9" data-line-number="9">    <span class="kw">&lt;metric_id&gt;</span>1000000001<span class="kw">&lt;/metric_id&gt;</span></a>
<a class="sourceLine" id="cb73-10" data-line-number="10">   <span class="kw">&lt;/metrics&gt;</span></a>
<a class="sourceLine" id="cb73-11" data-line-number="11">  <span class="kw">&lt;/benchmark&gt;</span></a>
<a class="sourceLine" id="cb73-12" data-line-number="12">  <span class="kw">&lt;benchmark&gt;</span></a>
<a class="sourceLine" id="cb73-13" data-line-number="13">   <span class="kw">&lt;input_id&gt;</span>1000013743<span class="kw">&lt;/input_id&gt;</span></a>
<a class="sourceLine" id="cb73-14" data-line-number="14">   <span class="kw">&lt;variable_id&gt;</span>18<span class="kw">&lt;/variable_id&gt;</span></a>
<a class="sourceLine" id="cb73-15" data-line-number="15">   <span class="kw">&lt;site_id&gt;</span>853<span class="kw">&lt;/site_id&gt;</span></a>
<a class="sourceLine" id="cb73-16" data-line-number="16">   <span class="kw">&lt;metrics&gt;</span></a>
<a class="sourceLine" id="cb73-17" data-line-number="17">    <span class="kw">&lt;metric_id&gt;</span>1000000001<span class="kw">&lt;/metric_id&gt;</span></a>
<a class="sourceLine" id="cb73-18" data-line-number="18">    <span class="kw">&lt;metric_id&gt;</span>1000000002<span class="kw">&lt;/metric_id&gt;</span></a>
<a class="sourceLine" id="cb73-19" data-line-number="19">   <span class="kw">&lt;/metrics&gt;</span></a>
<a class="sourceLine" id="cb73-20" data-line-number="20">  <span class="kw">&lt;/benchmark&gt;</span></a>
<a class="sourceLine" id="cb73-21" data-line-number="21"><span class="kw">&lt;/benchmarking&gt;</span></a></code></pre></div>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="basic-web-workflow.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="developer-guide.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tonygardella/pecan/edit/release/vtonydoc/book_source/02_demos_tutorials_workflows/04_more_web_interface/00_intermediate_users_guide.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
