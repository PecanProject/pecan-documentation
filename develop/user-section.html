<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 User Tutorial Section | The Predictive Ecosystem Analyzer</title>
  <meta name="description" content="5 User Tutorial Section | The Predictive Ecosystem Analyzer" />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="5 User Tutorial Section | The Predictive Ecosystem Analyzer" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 User Tutorial Section | The Predictive Ecosystem Analyzer" />
  
  
  

<meta name="author" content="By: PEcAn Team" />


<meta name="date" content="2019-06-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="pecan-manual-setup.html">
<link rel="next" href="basic-web-wrokflow.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.6/datatables.js"></script>
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.16/js/jquery.dataTables.min.js"></script>
<link href="libs/dt-ext-fixedcolumns-1.10.16/css/fixedColumns.dataTables.min.css" rel="stylesheet" />
<script src="libs/dt-ext-fixedcolumns-1.10.16/js/dataTables.fixedColumns.min.js"></script>
<script src="libs/jszip-1.10.16/jszip.min.js"></script>
<script src="libs/pdfmake-1.10.16/pdfmake.min.js"></script>
<script src="libs/pdfmake-1.10.16/vfs_fonts.js"></script>
<link href="libs/dt-ext-buttons-1.10.16/css/buttons.dataTables.min.css" rel="stylesheet" />
<script src="libs/dt-ext-buttons-1.10.16/js/dataTables.buttons.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.flash.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.html5.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.colVis.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.print.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="project-overview.html"><a href="project-overview.html"><i class="fa fa-check"></i><b>1</b> Project Overview</a></li>
<li class="chapter" data-level="2" data-path="contributor-covenant-code-of-conduct.html"><a href="contributor-covenant-code-of-conduct.html"><i class="fa fa-check"></i><b>2</b> Contributor Covenant Code of Conduct</a></li>
<li class="chapter" data-level="3" data-path="about-the-pecan-book.html"><a href="about-the-pecan-book.html"><i class="fa fa-check"></i><b>3</b> About the PEcAn Book</a><ul>
<li class="chapter" data-level="3.1" data-path="about-the-pecan-book.html"><a href="about-the-pecan-book.html#general-feedbackcommentssuggestions"><i class="fa fa-check"></i><b>3.1</b> General Feedback/Comments/Suggestions</a></li>
<li class="chapter" data-level="3.2" data-path="about-the-pecan-book.html"><a href="about-the-pecan-book.html#bookediting"><i class="fa fa-check"></i><b>3.2</b> Editing this book</a></li>
<li class="chapter" data-level="3.3" data-path="about-the-pecan-book.html"><a href="about-the-pecan-book.html#how-to-create-your-own-version-of-documentation"><i class="fa fa-check"></i><b>3.3</b> How to create your own version of Documentation</a></li>
</ul></li>
<li class="part"><span><b>II Tutorials, Demos and How To’s</b></span></li>
<li class="chapter" data-level="4" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html"><i class="fa fa-check"></i><b>4</b> Install PEcAn</a><ul>
<li class="chapter" data-level="4.1" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#install-vm"><i class="fa fa-check"></i><b>4.1</b> Virtual Machine (VM)</a></li>
<li class="chapter" data-level="4.2" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#install-docker"><i class="fa fa-check"></i><b>4.2</b> Docker</a></li>
<li class="chapter" data-level="4.3" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#install-native"><i class="fa fa-check"></i><b>4.3</b> (Advanced) Native install</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="user-section.html"><a href="user-section.html"><i class="fa fa-check"></i><b>5</b> User Tutorial Section</a><ul>
<li class="chapter" data-level="5.1" data-path="user-section.html"><a href="user-section.html#how-pecan-works-in-a-nutshell"><i class="fa fa-check"></i><b>5.1</b> How PEcAn Works in a nutshell</a></li>
<li class="chapter" data-level="5.2" data-path="user-section.html"><a href="user-section.html#demo-table"><i class="fa fa-check"></i><b>5.2</b> PEcAn Demos</a></li>
<li class="chapter" data-level="5.3" data-path="user-section.html"><a href="user-section.html#demo-01-basic-run-pecan"><i class="fa fa-check"></i><b>5.3</b> Demo 01: Basic Run PEcAn</a></li>
<li class="chapter" data-level="5.4" data-path="user-section.html"><a href="user-section.html#demo-02-sensitivity-and-uncertainty-analysis"><i class="fa fa-check"></i><b>5.4</b> Demo 02: Sensitivity and Uncertainty Analysis</a></li>
<li class="chapter" data-level="5.5" data-path="user-section.html"><a href="user-section.html#othervignettes"><i class="fa fa-check"></i><b>5.5</b> Other Vignettes</a><ul>
<li class="chapter" data-level="5.5.1" data-path="user-section.html"><a href="user-section.html#simple-model-data-comparisons"><i class="fa fa-check"></i><b>5.5.1</b> Simple Model-Data Comparisons</a></li>
<li class="chapter" data-level="5.5.2" data-path="user-section.html"><a href="user-section.html#data-assimilation-concepts"><i class="fa fa-check"></i><b>5.5.2</b> Data Assimilation Concepts</a></li>
<li class="chapter" data-level="5.5.3" data-path="user-section.html"><a href="user-section.html#parameter-data-assimilation"><i class="fa fa-check"></i><b>5.5.3</b> Parameter Data Assimilation</a></li>
<li class="chapter" data-level="5.5.4" data-path="user-section.html"><a href="user-section.html#state-variable-data-assimilation"><i class="fa fa-check"></i><b>5.5.4</b> State-Variable Data Assimilation</a></li>
<li class="chapter" data-level="5.5.5" data-path="user-section.html"><a href="user-section.html#pecan-testing-the-sensitivity-analysis-against-observations"><i class="fa fa-check"></i><b>5.5.5</b> PEcAn: Testing the Sensitivity Analysis Against Observations&quot;</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="user-section.html"><a href="user-section.html#advanced-user"><i class="fa fa-check"></i><b>5.6</b> Advanced User Guide</a><ul>
<li class="chapter" data-level="5.6.1" data-path="user-section.html"><a href="user-section.html#web-curl-submission"><i class="fa fa-check"></i><b>5.6.1</b> Submitting Workflow from Command Line</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html"><i class="fa fa-check"></i><b>6</b> Basic Web workflow</a><ul>
<li class="chapter" data-level="6.1" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#web-site-model"><i class="fa fa-check"></i><b>6.1</b> Site and model selection</a><ul>
<li class="chapter" data-level="6.1.1" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#selecting-a-model"><i class="fa fa-check"></i><b>6.1.1</b> Selecting a model</a></li>
<li class="chapter" data-level="6.1.2" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#selecting-a-site"><i class="fa fa-check"></i><b>6.1.2</b> Selecting a site</a></li>
<li class="chapter" data-level="6.1.3" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#site-groups"><i class="fa fa-check"></i><b>6.1.3</b> Site Groups</a></li>
<li class="chapter" data-level="6.1.4" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#using-existing-sites"><i class="fa fa-check"></i><b>6.1.4</b> Using existing sites</a></li>
<li class="chapter" data-level="6.1.5" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#adding-a-new-site"><i class="fa fa-check"></i><b>6.1.5</b> Adding a new site</a></li>
<li class="chapter" data-level="6.1.6" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#troubleshooting"><i class="fa fa-check"></i><b>6.1.6</b> Troubleshooting</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#web-model-config"><i class="fa fa-check"></i><b>6.2</b> Model configuration</a><ul>
<li class="chapter" data-level="6.2.1" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#choosing-meteorology"><i class="fa fa-check"></i><b>6.2.1</b> Choosing meteorology</a></li>
<li class="chapter" data-level="6.2.2" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#met-workflow"><i class="fa fa-check"></i><b>6.2.2</b> Met workflow</a></li>
<li class="chapter" data-level="6.2.3" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#troubleshooting-meteorological-conversions"><i class="fa fa-check"></i><b>6.2.3</b> Troubleshooting meteorological conversions</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#selecting-plant-functional-types-pfts-and-other-parameter-groupings."><i class="fa fa-check"></i><b>6.3</b> Selecting Plant Functional Types (PFTs) and other parameter groupings.</a><ul>
<li class="chapter" data-level="6.3.1" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#using-existing-pfts"><i class="fa fa-check"></i><b>6.3.1</b> Using existing PFTs</a></li>
<li class="chapter" data-level="6.3.2" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#creating-new-pfts"><i class="fa fa-check"></i><b>6.3.2</b> Creating new PFTs</a></li>
<li class="chapter" data-level="6.3.3" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#choosing-initial-vegetation"><i class="fa fa-check"></i><b>6.3.3</b> Choosing initial vegetation</a></li>
<li class="chapter" data-level="6.3.4" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#us-fia"><i class="fa fa-check"></i><b>6.3.4</b> US FIA</a></li>
<li class="chapter" data-level="6.3.5" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#spin-up"><i class="fa fa-check"></i><b>6.3.5</b> Spin up</a></li>
<li class="chapter" data-level="6.3.6" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#selecting-a-soils-product"><i class="fa fa-check"></i><b>6.3.6</b> Selecting a soils product</a></li>
<li class="chapter" data-level="6.3.7" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#soil-texture-depth-and-physical-parameters"><i class="fa fa-check"></i><b>6.3.7</b> Soil texture, depth, and physical parameters</a></li>
<li class="chapter" data-level="6.3.8" data-path="basic-web-wrokflow.html"><a href="basic-web-wrokflow.html#other-model-inputs"><i class="fa fa-check"></i><b>6.3.8</b> Other model inputs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="intermediate-user.html"><a href="intermediate-user.html"><i class="fa fa-check"></i><b>7</b> More on the PEcAn Web Interface</a><ul>
<li class="chapter" data-level="7.1" data-path="intermediate-user.html"><a href="intermediate-user.html#additional-web-configuration"><i class="fa fa-check"></i><b>7.1</b> Additional web configuration</a><ul>
<li class="chapter" data-level="7.1.1" data-path="intermediate-user.html"><a href="intermediate-user.html#intermediate-web-setup"><i class="fa fa-check"></i><b>7.1.1</b> Web interface setup</a></li>
<li class="chapter" data-level="7.1.2" data-path="intermediate-user.html"><a href="intermediate-user.html#browndog"><i class="fa fa-check"></i><b>7.1.2</b> Brown Dog</a></li>
<li class="chapter" data-level="7.1.3" data-path="intermediate-user.html"><a href="intermediate-user.html#intermediate-advanced-setup"><i class="fa fa-check"></i><b>7.1.3</b> Advanced Setup</a></li>
<li class="chapter" data-level="7.1.4" data-path="intermediate-user.html"><a href="intermediate-user.html#intermediate-model-config"><i class="fa fa-check"></i><b>7.1.4</b> Editing model configurations</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="intermediate-user.html"><a href="intermediate-user.html#settings-configured-analyses"><i class="fa fa-check"></i><b>7.2</b> Settings-configured analyses</a><ul>
<li class="chapter" data-level="7.2.1" data-path="intermediate-user.html"><a href="intermediate-user.html#pda"><i class="fa fa-check"></i><b>7.2.1</b> Parameter data assimilation (PDA)</a></li>
<li class="chapter" data-level="7.2.2" data-path="intermediate-user.html"><a href="intermediate-user.html#sda"><i class="fa fa-check"></i><b>7.2.2</b> State data assimilation (SDA)</a></li>
<li class="chapter" data-level="7.2.3" data-path="intermediate-user.html"><a href="intermediate-user.html#state-data-assimilation-methods"><i class="fa fa-check"></i><b>7.2.3</b> State Data Assimilation Methods</a></li>
<li class="chapter" data-level="7.2.4" data-path="intermediate-user.html"><a href="intermediate-user.html#multisettings"><i class="fa fa-check"></i><b>7.2.4</b> MultiSettings</a></li>
<li class="chapter" data-level="7.2.5" data-path="intermediate-user.html"><a href="intermediate-user.html#benchmarking"><i class="fa fa-check"></i><b>7.2.5</b> Benchmarking</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="developer-guide.html"><a href="developer-guide.html"><i class="fa fa-check"></i><b>8</b> Developer guide</a><ul>
<li class="chapter" data-level="8.1" data-path="developer-guide.html"><a href="developer-guide.html#updatebety"><i class="fa fa-check"></i><b>8.1</b> Updating PEcAn Code and Bety Database</a><ul>
<li class="chapter" data-level="8.1.1" data-path="developer-guide.html"><a href="developer-guide.html#pecan-make"><i class="fa fa-check"></i><b>8.1.1</b> Updating PEcAn</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="developer-guide.html"><a href="developer-guide.html#pecan-git"><i class="fa fa-check"></i><b>8.2</b> Git and GitHub Workflow</a><ul>
<li class="chapter" data-level="8.2.1" data-path="developer-guide.html"><a href="developer-guide.html#using-git"><i class="fa fa-check"></i><b>8.2.1</b> Using Git</a></li>
<li class="chapter" data-level="8.2.2" data-path="developer-guide.html"><a href="developer-guide.html#github-use-with-pecan"><i class="fa fa-check"></i><b>8.2.2</b> GitHub use with PEcAn</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="developer-guide.html"><a href="developer-guide.html#coding-practices"><i class="fa fa-check"></i><b>8.3</b> Coding Practices</a><ul>
<li class="chapter" data-level="8.3.1" data-path="developer-guide.html"><a href="developer-guide.html#developer-codestyle"><i class="fa fa-check"></i><b>8.3.1</b> Coding Style</a></li>
<li class="chapter" data-level="8.3.2" data-path="developer-guide.html"><a href="developer-guide.html#developer-logging"><i class="fa fa-check"></i><b>8.3.2</b> Logging</a></li>
<li class="chapter" data-level="8.3.3" data-path="developer-guide.html"><a href="developer-guide.html#developer-packagedata"><i class="fa fa-check"></i><b>8.3.3</b> Package Data</a></li>
<li class="chapter" data-level="8.3.4" data-path="developer-guide.html"><a href="developer-guide.html#developer-roxygen"><i class="fa fa-check"></i><b>8.3.4</b> Roxygen2</a></li>
<li class="chapter" data-level="8.3.5" data-path="developer-guide.html"><a href="developer-guide.html#developer-testing"><i class="fa fa-check"></i><b>8.3.5</b> Testing</a></li>
<li class="chapter" data-level="8.3.6" data-path="developer-guide.html"><a href="developer-guide.html#developer-devtools"><i class="fa fa-check"></i><b>8.3.6</b> <code>devtools</code> package</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="developer-guide.html"><a href="developer-guide.html#download-and-compile-pecan"><i class="fa fa-check"></i><b>8.4</b> Download and Compile PEcAn</a><ul>
<li class="chapter" data-level="8.4.1" data-path="developer-guide.html"><a href="developer-guide.html#download-compile-and-install-pecan-from-github"><i class="fa fa-check"></i><b>8.4.1</b> Download, compile and install PEcAn from GitHub</a></li>
<li class="chapter" data-level="8.4.2" data-path="developer-guide.html"><a href="developer-guide.html#pecan-testrun"><i class="fa fa-check"></i><b>8.4.2</b> PEcAn Testrun</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="developer-guide.html"><a href="developer-guide.html#directory-structure"><i class="fa fa-check"></i><b>8.5</b> Directory structure</a><ul>
<li class="chapter" data-level="8.5.1" data-path="developer-guide.html"><a href="developer-guide.html#overview-of-pecan-repository-as-of-pecan-1.5.3"><i class="fa fa-check"></i><b>8.5.1</b> Overview of PEcAn repository as of PEcAn 1.5.3</a></li>
<li class="chapter" data-level="8.5.2" data-path="developer-guide.html"><a href="developer-guide.html#generic-r-package-structure"><i class="fa fa-check"></i><b>8.5.2</b> Generic R package structure:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Topical Pages</b></span></li>
<li class="chapter" data-level="9" data-path="working-with-vm.html"><a href="working-with-vm.html"><i class="fa fa-check"></i><b>9</b> VM configuration and maintenance</a><ul>
<li class="chapter" data-level="9.1" data-path="working-with-vm.html"><a href="working-with-vm.html#maintain-vm"><i class="fa fa-check"></i><b>9.1</b> Updating the VM</a></li>
<li class="chapter" data-level="9.2" data-path="working-with-vm.html"><a href="working-with-vm.html#ssh-vm"><i class="fa fa-check"></i><b>9.2</b> Connecting to the VM via SSH</a></li>
<li class="chapter" data-level="9.3" data-path="working-with-vm.html"><a href="working-with-vm.html#ssh-vm-bety"><i class="fa fa-check"></i><b>9.3</b> Connecting to bety on the VM via SSh</a><ul>
<li class="chapter" data-level="9.3.1" data-path="working-with-vm.html"><a href="working-with-vm.html#awsvm"><i class="fa fa-check"></i><b>9.3.1</b> Using Amazon Web Services for a VM (AWS)</a></li>
<li class="chapter" data-level="9.3.2" data-path="working-with-vm.html"><a href="working-with-vm.html#createvm"><i class="fa fa-check"></i><b>9.3.2</b> Creating a Virtual Machine</a></li>
<li class="chapter" data-level="9.3.3" data-path="working-with-vm.html"><a href="working-with-vm.html#vm-dektop-conversion"><i class="fa fa-check"></i><b>9.3.3</b> VM Desktop Conversion</a></li>
<li class="chapter" data-level="9.3.4" data-path="working-with-vm.html"><a href="working-with-vm.html#install-rstudio"><i class="fa fa-check"></i><b>9.3.4</b> Install RStudio Desktop</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pecan-standards.html"><a href="pecan-standards.html"><i class="fa fa-check"></i><b>10</b> PEcAn standard formats</a><ul>
<li class="chapter" data-level="10.1" data-path="pecan-standards.html"><a href="pecan-standards.html#defining-new-input-formats"><i class="fa fa-check"></i><b>10.1</b> Defining new input formats</a></li>
<li class="chapter" data-level="10.2" data-path="pecan-standards.html"><a href="pecan-standards.html#time-standard"><i class="fa fa-check"></i><b>10.2</b> Time Standard</a><ul>
<li class="chapter" data-level="10.2.1" data-path="pecan-standards.html"><a href="pecan-standards.html#input-standards"><i class="fa fa-check"></i><b>10.2.1</b> Input Standards</a></li>
<li class="chapter" data-level="10.2.2" data-path="pecan-standards.html"><a href="pecan-standards.html#soils-and-vegetation-inputs"><i class="fa fa-check"></i><b>10.2.2</b> Soils and Vegetation Inputs</a></li>
<li class="chapter" data-level="10.2.3" data-path="pecan-standards.html"><a href="pecan-standards.html#output-standards"><i class="fa fa-check"></i><b>10.2.3</b> Output Standards</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="pecanXML.html"><a href="pecanXML.html"><i class="fa fa-check"></i><b>11</b> The PEcAn XML</a><ul>
<li class="chapter" data-level="11.0.1" data-path="pecanXML.html"><a href="pecanXML.html#xml-core-config"><i class="fa fa-check"></i><b>11.0.1</b> Core configuration</a></li>
<li class="chapter" data-level="11.0.2" data-path="pecanXML.html"><a href="pecanXML.html#xml-outdir"><i class="fa fa-check"></i><b>11.0.2</b> <code>outdir</code>: Output directory</a></li>
<li class="chapter" data-level="11.0.3" data-path="pecanXML.html"><a href="pecanXML.html#xml-database"><i class="fa fa-check"></i><b>11.0.3</b> <code>database</code>: PEcAn database settings</a></li>
<li class="chapter" data-level="11.0.4" data-path="pecanXML.html"><a href="pecanXML.html#xml-pft"><i class="fa fa-check"></i><b>11.0.4</b> <code>pft</code>: Plant functional type selection</a></li>
<li class="chapter" data-level="11.0.5" data-path="pecanXML.html"><a href="pecanXML.html#xml-meta-analysis"><i class="fa fa-check"></i><b>11.0.5</b> <code>meta.analysis</code>: Trait Meta Analysis</a></li>
<li class="chapter" data-level="11.0.6" data-path="pecanXML.html"><a href="pecanXML.html#xml-model"><i class="fa fa-check"></i><b>11.0.6</b> <code>model</code>: Model configuration</a></li>
<li class="chapter" data-level="11.0.7" data-path="pecanXML.html"><a href="pecanXML.html#xml-run"><i class="fa fa-check"></i><b>11.0.7</b> <code>run</code>: Run Setup</a></li>
<li class="chapter" data-level="11.0.8" data-path="pecanXML.html"><a href="pecanXML.html#xml-host"><i class="fa fa-check"></i><b>11.0.8</b> <code>host</code>: Host information for remote execution</a></li>
<li class="chapter" data-level="11.0.9" data-path="pecanXML.html"><a href="pecanXML.html#xml-advanced"><i class="fa fa-check"></i><b>11.0.9</b> Advanced features</a></li>
<li class="chapter" data-level="11.0.10" data-path="pecanXML.html"><a href="pecanXML.html#xml-ensemble"><i class="fa fa-check"></i><b>11.0.10</b> <code>ensemble</code>: Ensemble Runs</a></li>
<li class="chapter" data-level="11.0.11" data-path="pecanXML.html"><a href="pecanXML.html#xml-sensitivity-analysis"><i class="fa fa-check"></i><b>11.0.11</b> <code>sensitivity.analysis</code>: Sensitivity analysis</a></li>
<li class="chapter" data-level="11.0.12" data-path="pecanXML.html"><a href="pecanXML.html#xml-parameter-data-assimilation"><i class="fa fa-check"></i><b>11.0.12</b> Parameter Data Assimilation</a></li>
<li class="chapter" data-level="11.0.13" data-path="pecanXML.html"><a href="pecanXML.html#xml-multi-settings"><i class="fa fa-check"></i><b>11.0.13</b> Multi-Settings</a></li>
<li class="chapter" data-level="11.0.14" data-path="pecanXML.html"><a href="pecanXML.html#xml-state-data-assimilation"><i class="fa fa-check"></i><b>11.0.14</b> (experimental) State Data Assimilation</a></li>
<li class="chapter" data-level="11.0.15" data-path="pecanXML.html"><a href="pecanXML.html#xml-browndog"><i class="fa fa-check"></i><b>11.0.15</b> (experimental) Brown Dog</a></li>
<li class="chapter" data-level="11.0.16" data-path="pecanXML.html"><a href="pecanXML.html#xml-benchmarking"><i class="fa fa-check"></i><b>11.0.16</b> (experimental) Benchmarking</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="workflow.html"><a href="workflow.html"><i class="fa fa-check"></i><b>12</b> PEcAn workflow (web/workflow.R)</a><ul>
<li class="chapter" data-level="12.0.1" data-path="workflow.html"><a href="workflow.html#workflow-readsettings"><i class="fa fa-check"></i><b>12.0.1</b> Read Settings</a></li>
<li class="chapter" data-level="12.0.2" data-path="workflow.html"><a href="workflow.html#workflow-input"><i class="fa fa-check"></i><b>12.0.2</b> Input Conversions</a></li>
<li class="chapter" data-level="12.0.3" data-path="workflow.html"><a href="workflow.html#workflow-input-data"><i class="fa fa-check"></i><b>12.0.3</b> Input Data</a></li>
<li class="chapter" data-level="12.0.4" data-path="workflow.html"><a href="workflow.html#workflow-input-initial"><i class="fa fa-check"></i><b>12.0.4</b> Initial Conditions</a></li>
<li class="chapter" data-level="12.0.5" data-path="workflow.html"><a href="workflow.html#workflow-met"><i class="fa fa-check"></i><b>12.0.5</b> Meteorological Data</a></li>
<li class="chapter" data-level="12.0.6" data-path="workflow.html"><a href="workflow.html#workflow-met-standard"><i class="fa fa-check"></i><b>12.0.6</b> Converting raw data to PEcAn standard</a></li>
<li class="chapter" data-level="12.0.7" data-path="workflow.html"><a href="workflow.html#workflow-met-downscale"><i class="fa fa-check"></i><b>12.0.7</b> Downscaling and gapfilling (optional)</a></li>
<li class="chapter" data-level="12.0.8" data-path="workflow.html"><a href="workflow.html#workflow-met-model"><i class="fa fa-check"></i><b>12.0.8</b> Converting from PEcAn standard to model-specific format</a></li>
<li class="chapter" data-level="12.0.9" data-path="workflow.html"><a href="workflow.html#workflow-traits"><i class="fa fa-check"></i><b>12.0.9</b> Traits</a></li>
<li class="chapter" data-level="12.0.10" data-path="workflow.html"><a href="workflow.html#workflow-metaanalysis"><i class="fa fa-check"></i><b>12.0.10</b> Meta Analysis</a></li>
<li class="chapter" data-level="12.0.11" data-path="workflow.html"><a href="workflow.html#workflow-modelconfig"><i class="fa fa-check"></i><b>12.0.11</b> Model Configuration</a></li>
<li class="chapter" data-level="12.0.12" data-path="workflow.html"><a href="workflow.html#workflow-modelrun"><i class="fa fa-check"></i><b>12.0.12</b> Run Execution</a></li>
<li class="chapter" data-level="12.0.13" data-path="workflow.html"><a href="workflow.html#workflow-postrun"><i class="fa fa-check"></i><b>12.0.13</b> Post Run Analysis</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="pecan-models.html"><a href="pecan-models.html"><i class="fa fa-check"></i><b>13</b> PEcAn Models</a><ul>
<li class="chapter" data-level="13.0.1" data-path="pecan-models.html"><a href="pecan-models.html#models-biocro"><i class="fa fa-check"></i><b>13.0.1</b> BioCro</a></li>
<li class="chapter" data-level="13.0.2" data-path="pecan-models.html"><a href="pecan-models.html#models-clm"><i class="fa fa-check"></i><b>13.0.2</b> CLM</a></li>
<li class="chapter" data-level="13.0.3" data-path="pecan-models.html"><a href="pecan-models.html#models-dalec"><i class="fa fa-check"></i><b>13.0.3</b> DALEC</a></li>
<li class="chapter" data-level="13.0.4" data-path="pecan-models.html"><a href="pecan-models.html#models-ed"><i class="fa fa-check"></i><b>13.0.4</b> ED2</a></li>
<li class="chapter" data-level="13.0.5" data-path="pecan-models.html"><a href="pecan-models.html#models-gday"><i class="fa fa-check"></i><b>13.0.5</b> GDAY</a></li>
<li class="chapter" data-level="13.0.6" data-path="pecan-models.html"><a href="pecan-models.html#models-linkages"><i class="fa fa-check"></i><b>13.0.6</b> LINKAGES</a></li>
<li class="chapter" data-level="13.0.7" data-path="pecan-models.html"><a href="pecan-models.html#models-lpjguess"><i class="fa fa-check"></i><b>13.0.7</b> LPJ-GUESS</a></li>
<li class="chapter" data-level="13.0.8" data-path="pecan-models.html"><a href="pecan-models.html#models-maespa"><i class="fa fa-check"></i><b>13.0.8</b> MAESPA</a></li>
<li class="chapter" data-level="13.0.9" data-path="pecan-models.html"><a href="pecan-models.html#models-preles"><i class="fa fa-check"></i><b>13.0.9</b> PRELES</a></li>
<li class="chapter" data-level="13.0.10" data-path="pecan-models.html"><a href="pecan-models.html#models-sipnet"><i class="fa fa-check"></i><b>13.0.10</b> SiPNET</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html"><i class="fa fa-check"></i><b>14</b> Available Meteorological Drivers</a><ul>
<li class="chapter" data-level="14.0.1" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#ameriflux"><i class="fa fa-check"></i><b>14.0.1</b> Ameriflux</a></li>
<li class="chapter" data-level="14.0.2" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#amerifluxlbl"><i class="fa fa-check"></i><b>14.0.2</b> AmerifluxLBL</a></li>
<li class="chapter" data-level="14.0.3" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#fluxnet2015"><i class="fa fa-check"></i><b>14.0.3</b> Fluxnet2015</a></li>
<li class="chapter" data-level="14.0.4" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#narr"><i class="fa fa-check"></i><b>14.0.4</b> NARR</a></li>
<li class="chapter" data-level="14.0.5" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#cruncep"><i class="fa fa-check"></i><b>14.0.5</b> CRUNCEP</a></li>
<li class="chapter" data-level="14.0.6" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#cmip5"><i class="fa fa-check"></i><b>14.0.6</b> CMIP5</a></li>
<li class="chapter" data-level="14.0.7" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#nldas"><i class="fa fa-check"></i><b>14.0.7</b> NLDAS</a></li>
<li class="chapter" data-level="14.0.8" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#gldas"><i class="fa fa-check"></i><b>14.0.8</b> GLDAS</a></li>
<li class="chapter" data-level="14.0.9" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#paleon"><i class="fa fa-check"></i><b>14.0.9</b> PalEON</a></li>
<li class="chapter" data-level="14.0.10" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#fluxnetlathuile"><i class="fa fa-check"></i><b>14.0.10</b> FluxnetLaThuile</a></li>
<li class="chapter" data-level="14.0.11" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#geostreams"><i class="fa fa-check"></i><b>14.0.11</b> Geostreams</a></li>
<li class="chapter" data-level="14.0.12" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#download-gfdl"><i class="fa fa-check"></i><b>14.0.12</b> Download GFDL</a></li>
<li class="chapter" data-level="14.0.13" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#cm3"><i class="fa fa-check"></i><b>14.0.13</b> CM3</a></li>
<li class="chapter" data-level="14.0.14" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#esm2m-esm2g"><i class="fa fa-check"></i><b>14.0.14</b> ESM2M &amp; ESM2G</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="database-synchronization.html"><a href="database-synchronization.html"><i class="fa fa-check"></i><b>15</b> Database synchronization</a><ul>
<li class="chapter" data-level="15.0.1" data-path="database-synchronization.html"><a href="database-synchronization.html#how-does-it-work"><i class="fa fa-check"></i><b>15.0.1</b> How does it work?</a></li>
<li class="chapter" data-level="15.0.2" data-path="database-synchronization.html"><a href="database-synchronization.html#set-up"><i class="fa fa-check"></i><b>15.0.2</b> Set up</a></li>
<li class="chapter" data-level="15.0.3" data-path="database-synchronization.html"><a href="database-synchronization.html#fetch-latest-data"><i class="fa fa-check"></i><b>15.0.3</b> Fetch latest data</a></li>
<li class="chapter" data-level="15.0.4" data-path="database-synchronization.html"><a href="database-synchronization.html#sharing-data"><i class="fa fa-check"></i><b>15.0.4</b> Sharing data</a></li>
<li class="chapter" data-level="15.0.5" data-path="database-synchronization.html"><a href="database-synchronization.html#automation"><i class="fa fa-check"></i><b>15.0.5</b> Automation</a></li>
<li class="chapter" data-level="15.0.6" data-path="database-synchronization.html"><a href="database-synchronization.html#database-maintentance"><i class="fa fa-check"></i><b>15.0.6</b> Database maintentance</a></li>
<li class="chapter" data-level="15.0.7" data-path="database-synchronization.html"><a href="database-synchronization.html#troubleshooting-1"><i class="fa fa-check"></i><b>15.0.7</b> Troubleshooting</a></li>
<li class="chapter" data-level="15.0.8" data-path="database-synchronization.html"><a href="database-synchronization.html#network-status-map"><i class="fa fa-check"></i><b>15.0.8</b> Network Status Map</a></li>
<li class="chapter" data-level="15.0.9" data-path="database-synchronization.html"><a href="database-synchronization.html#tasks"><i class="fa fa-check"></i><b>15.0.9</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="standalone-tools-modules.html"><a href="standalone-tools-modules.html"><i class="fa fa-check"></i><b>16</b> Standalone tools (modules)</a><ul>
<li class="chapter" data-level="16.0.1" data-path="standalone-tools-modules.html"><a href="standalone-tools-modules.html#LoadData"><i class="fa fa-check"></i><b>16.0.1</b> Loading Data in PEcAn</a></li>
<li class="chapter" data-level="16.0.2" data-path="standalone-tools-modules.html"><a href="standalone-tools-modules.html#function-load_data"><i class="fa fa-check"></i><b>16.0.2</b> Function <code>load_data</code></a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="shiny.html"><a href="shiny.html"><i class="fa fa-check"></i><b>17</b> SHINY</a><ul>
<li class="chapter" data-level="17.0.1" data-path="shiny.html"><a href="shiny.html#debugging-shiny-apps"><i class="fa fa-check"></i><b>17.0.1</b> Debugging Shiny Apps</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html"><i class="fa fa-check"></i><b>18</b> Adding to PEcAn</a><ul>
<li class="chapter" data-level="18.1" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#adding-model"><i class="fa fa-check"></i><b>18.1</b> Adding An Ecosystem Model</a></li>
<li class="chapter" data-level="18.2" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#example-met-conversion-wrapper-function"><i class="fa fa-check"></i><b>18.2</b> Example met conversion wrapper function</a></li>
<li class="chapter" data-level="18.3" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#NewInput"><i class="fa fa-check"></i><b>18.3</b> Adding input data</a><ul>
<li class="chapter" data-level="18.3.1" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#meterological-data"><i class="fa fa-check"></i><b>18.3.1</b> Meterological Data</a></li>
<li class="chapter" data-level="18.3.2" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#vegetation-data-1"><i class="fa fa-check"></i><b>18.3.2</b> Vegetation Data</a></li>
<li class="chapter" data-level="18.3.3" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#soil-data-1"><i class="fa fa-check"></i><b>18.3.3</b> Soil Data</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#adding-data-web"><i class="fa fa-check"></i><b>18.4</b> Pecan Data Ingest via Web Interface</a></li>
<li class="chapter" data-level="18.5" data-path="adding-to-pecan.html"><a href="adding-to-pecan.html#NewFormat"><i class="fa fa-check"></i><b>18.5</b> Creating a new format</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html"><i class="fa fa-check"></i><b>19</b> Troubleshooting and Debugging PEcAn</a><ul>
<li class="chapter" data-level="19.0.1" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html#cookies-and-pecan-web-pages"><i class="fa fa-check"></i><b>19.0.1</b> Cookies and pecan web pages</a></li>
<li class="chapter" data-level="19.0.2" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html#warning-mkdir-function.mkdir-no-such-file-or-directory"><i class="fa fa-check"></i><b>19.0.2</b> <code>Warning: mkdir() [function.mkdir]: No such file or directory</code></a></li>
<li class="chapter" data-level="19.0.3" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html#after-creating-a-new-pft-the-tag-for-pft-not-passed-to-config.xml-in-ed"><i class="fa fa-check"></i><b>19.0.3</b> After creating a new PFT the <num> tag for PFT not passed to config.xml in ED</a></li>
<li class="chapter" data-level="19.1" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html#debugging"><i class="fa fa-check"></i><b>19.1</b> Debugging</a><ul>
<li class="chapter" data-level="19.1.1" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html#using-testsworkflow.r"><i class="fa fa-check"></i><b>19.1.1</b> Using <code>tests/workflow.R</code></a></li>
<li class="chapter" data-level="19.1.2" data-path="troubleshooting-and-debugging-pecan.html"><a href="troubleshooting-and-debugging-pecan.html#useful-scripts"><i class="fa fa-check"></i><b>19.1.2</b> Useful scripts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="database.html"><a href="database.html"><i class="fa fa-check"></i><b>20</b> BETY Database Administration</a><ul>
<li class="chapter" data-level="20.0.1" data-path="database.html"><a href="database.html#database-setup"><i class="fa fa-check"></i><b>20.0.1</b> Best practices</a></li>
<li class="chapter" data-level="20.0.2" data-path="database.html"><a href="database.html#backup-of-bety-database"><i class="fa fa-check"></i><b>20.0.2</b> Backup of BETY database</a></li>
<li class="chapter" data-level="20.0.3" data-path="database.html"><a href="database.html#restore-of-bety-database"><i class="fa fa-check"></i><b>20.0.3</b> Restore of BETY database</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="workflow-modules.html"><a href="workflow-modules.html"><i class="fa fa-check"></i><b>21</b> Workflow modules</a><ul>
<li class="chapter" data-level="21.0.1" data-path="workflow-modules.html"><a href="workflow-modules.html#overview-1"><i class="fa fa-check"></i><b>21.0.1</b> Overview</a></li>
<li class="chapter" data-level="21.0.2" data-path="workflow-modules.html"><a href="workflow-modules.html#load-settings"><i class="fa fa-check"></i><b>21.0.2</b> Load Settings:</a></li>
<li class="chapter" data-level="21.0.3" data-path="workflow-modules.html"><a href="workflow-modules.html#query-database"><i class="fa fa-check"></i><b>21.0.3</b> Query Database:</a></li>
<li class="chapter" data-level="21.0.4" data-path="workflow-modules.html"><a href="workflow-modules.html#meta-analysis"><i class="fa fa-check"></i><b>21.0.4</b> Meta Analysis:</a></li>
<li class="chapter" data-level="21.0.5" data-path="workflow-modules.html"><a href="workflow-modules.html#write-configuration-files"><i class="fa fa-check"></i><b>21.0.5</b> Write Configuration Files</a></li>
<li class="chapter" data-level="21.0.6" data-path="workflow-modules.html"><a href="workflow-modules.html#start-runs"><i class="fa fa-check"></i><b>21.0.6</b> Start Runs:</a></li>
<li class="chapter" data-level="21.0.7" data-path="workflow-modules.html"><a href="workflow-modules.html#get-model-output"><i class="fa fa-check"></i><b>21.0.7</b> Get Model Output</a></li>
<li class="chapter" data-level="21.0.8" data-path="workflow-modules.html"><a href="workflow-modules.html#ensemble-analysis"><i class="fa fa-check"></i><b>21.0.8</b> Ensemble Analysis</a></li>
<li class="chapter" data-level="21.0.9" data-path="workflow-modules.html"><a href="workflow-modules.html#sensitivity-analysis-variance-decomposition"><i class="fa fa-check"></i><b>21.0.9</b> Sensitivity Analysis, Variance Decomposition</a></li>
<li class="chapter" data-level="21.0.10" data-path="workflow-modules.html"><a href="workflow-modules.html#glossary"><i class="fa fa-check"></i><b>21.0.10</b> Glossary</a></li>
<li class="chapter" data-level="21.1" data-path="workflow-modules.html"><a href="workflow-modules.html#pecanvm"><i class="fa fa-check"></i><b>21.1</b> PEcAn Virtual Machine</a><ul>
<li class="chapter" data-level="21.1.1" data-path="workflow-modules.html"><a href="workflow-modules.html#aws-setup"><i class="fa fa-check"></i><b>21.1.1</b> AWS Setup</a></li>
<li class="chapter" data-level="21.1.2" data-path="workflow-modules.html"><a href="workflow-modules.html#porting-vm-to-aws"><i class="fa fa-check"></i><b>21.1.2</b> Porting VM to AWS</a></li>
<li class="chapter" data-level="21.1.3" data-path="workflow-modules.html"><a href="workflow-modules.html#set-up-multiple-instances-optional"><i class="fa fa-check"></i><b>21.1.3</b> Set up multiple instances (optional)</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="workflow-modules.html"><a href="workflow-modules.html#shiny-setup"><i class="fa fa-check"></i><b>21.2</b> Shiny Setup</a><ul>
<li class="chapter" data-level="21.2.1" data-path="workflow-modules.html"><a href="workflow-modules.html#install-the-shiny-r-package-and-shiny-server"><i class="fa fa-check"></i><b>21.2.1</b> Install the Shiny R package and Shiny server</a></li>
<li class="chapter" data-level="21.2.2" data-path="workflow-modules.html"><a href="workflow-modules.html#modify-the-shiny-configuration-file"><i class="fa fa-check"></i><b>21.2.2</b> Modify the shiny configuration file</a></li>
<li class="chapter" data-level="21.2.3" data-path="workflow-modules.html"><a href="workflow-modules.html#set-the-apache-proxy"><i class="fa fa-check"></i><b>21.2.3</b> Set the Apache proxy</a></li>
<li class="chapter" data-level="21.2.4" data-path="workflow-modules.html"><a href="workflow-modules.html#enable-and-start-the-shiny-server-and-restart-apache"><i class="fa fa-check"></i><b>21.2.4</b> Enable and start the shiny server, and restart apache</a></li>
<li class="chapter" data-level="21.2.5" data-path="workflow-modules.html"><a href="workflow-modules.html#troubleshooting-2"><i class="fa fa-check"></i><b>21.2.5</b> Troubleshooting</a></li>
<li class="chapter" data-level="21.2.6" data-path="workflow-modules.html"><a href="workflow-modules.html#further-reading"><i class="fa fa-check"></i><b>21.2.6</b> Further reading</a></li>
<li class="chapter" data-level="21.2.7" data-path="workflow-modules.html"><a href="workflow-modules.html#thredds-setup"><i class="fa fa-check"></i><b>21.2.7</b> Thredds Setup</a></li>
<li class="chapter" data-level="21.2.8" data-path="workflow-modules.html"><a href="workflow-modules.html#install-the-tomcat-8-and-thredds-webapp"><i class="fa fa-check"></i><b>21.2.8</b> Install the Tomcat 8 and Thredds webapp</a></li>
<li class="chapter" data-level="21.2.9" data-path="workflow-modules.html"><a href="workflow-modules.html#update-the-catalog"><i class="fa fa-check"></i><b>21.2.9</b> Update the catalog</a></li>
<li class="chapter" data-level="21.2.10" data-path="workflow-modules.html"><a href="workflow-modules.html#troubleshooting-3"><i class="fa fa-check"></i><b>21.2.10</b> Troubleshooting</a></li>
<li class="chapter" data-level="21.2.11" data-path="workflow-modules.html"><a href="workflow-modules.html#further-reading-1"><i class="fa fa-check"></i><b>21.2.11</b> Further reading</a></li>
<li class="chapter" data-level="21.2.12" data-path="workflow-modules.html"><a href="workflow-modules.html#osinstall"><i class="fa fa-check"></i><b>21.2.12</b> OS Specific Installations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="docker-index.html"><a href="docker-index.html"><i class="fa fa-check"></i><b>22</b> Docker</a><ul>
<li class="chapter" data-level="22.1" data-path="docker-index.html"><a href="docker-index.html#docker-intro"><i class="fa fa-check"></i><b>22.1</b> Introduction to Docker?</a><ul>
<li class="chapter" data-level="22.1.1" data-path="docker-index.html"><a href="docker-index.html#what-is-docker"><i class="fa fa-check"></i><b>22.1.1</b> What is Docker?</a></li>
<li class="chapter" data-level="22.1.2" data-path="docker-index.html"><a href="docker-index.html#working-with-docker"><i class="fa fa-check"></i><b>22.1.2</b> Working with Docker</a></li>
<li class="chapter" data-level="22.1.3" data-path="docker-index.html"><a href="docker-index.html#docker-compose"><i class="fa fa-check"></i><b>22.1.3</b> <code>docker-compose</code></a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="docker-index.html"><a href="docker-index.html#docker-quickstart"><i class="fa fa-check"></i><b>22.2</b> The PEcAn docker install process in detail</a><ul>
<li class="chapter" data-level="22.2.1" data-path="docker-index.html"><a href="docker-index.html#pecan-setup-compose-configure"><i class="fa fa-check"></i><b>22.2.1</b> Configure docker-compose</a></li>
<li class="chapter" data-level="22.2.2" data-path="docker-index.html"><a href="docker-index.html#pecan-docker-quickstart-init"><i class="fa fa-check"></i><b>22.2.2</b> Initialize PEcAn (first time only)</a></li>
<li class="chapter" data-level="22.2.3" data-path="docker-index.html"><a href="docker-index.html#docker-quickstart-troubleshooting"><i class="fa fa-check"></i><b>22.2.3</b> Troubleshooting</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="docker-index.html"><a href="docker-index.html#pecan-docker"><i class="fa fa-check"></i><b>22.3</b> PEcAn Docker Architecture</a><ul>
<li class="chapter" data-level="22.3.1" data-path="docker-index.html"><a href="docker-index.html#pecan-docker-overview"><i class="fa fa-check"></i><b>22.3.1</b> Overview</a></li>
<li class="chapter" data-level="22.3.2" data-path="docker-index.html"><a href="docker-index.html#pecan-docker-compose"><i class="fa fa-check"></i><b>22.3.2</b> PEcAn’s <code>docker-compose</code></a></li>
<li class="chapter" data-level="22.3.3" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-structure"><i class="fa fa-check"></i><b>22.3.3</b> Top-level structure</a></li>
<li class="chapter" data-level="22.3.4" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-traefik"><i class="fa fa-check"></i><b>22.3.4</b> <code>traefik</code></a></li>
<li class="chapter" data-level="22.3.5" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-portainer"><i class="fa fa-check"></i><b>22.3.5</b> <code>portainer</code></a></li>
<li class="chapter" data-level="22.3.6" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-minio"><i class="fa fa-check"></i><b>22.3.6</b> <code>minio</code></a></li>
<li class="chapter" data-level="22.3.7" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-thredds"><i class="fa fa-check"></i><b>22.3.7</b> <code>thredds</code></a></li>
<li class="chapter" data-level="22.3.8" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-postgres"><i class="fa fa-check"></i><b>22.3.8</b> <code>postgres</code></a></li>
<li class="chapter" data-level="22.3.9" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-rabbitmq"><i class="fa fa-check"></i><b>22.3.9</b> <code>rabbitmq</code></a></li>
<li class="chapter" data-level="22.3.10" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-bety"><i class="fa fa-check"></i><b>22.3.10</b> <code>bety</code></a></li>
<li class="chapter" data-level="22.3.11" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-docs"><i class="fa fa-check"></i><b>22.3.11</b> <code>docs</code></a></li>
<li class="chapter" data-level="22.3.12" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-web"><i class="fa fa-check"></i><b>22.3.12</b> <code>web</code></a></li>
<li class="chapter" data-level="22.3.13" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-executor"><i class="fa fa-check"></i><b>22.3.13</b> <code>executor</code></a></li>
<li class="chapter" data-level="22.3.14" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-monitor"><i class="fa fa-check"></i><b>22.3.14</b> <code>monitor</code></a></li>
<li class="chapter" data-level="22.3.15" data-path="docker-index.html"><a href="docker-index.html#pecan-dc-models"><i class="fa fa-check"></i><b>22.3.15</b> Model-specific containers</a></li>
</ul></li>
<li class="chapter" data-level="22.4" data-path="docker-index.html"><a href="docker-index.html#model-docker"><i class="fa fa-check"></i><b>22.4</b> Models using Docker</a><ul>
<li class="chapter" data-level="22.4.1" data-path="docker-index.html"><a href="docker-index.html#model-docker-json-file"><i class="fa fa-check"></i><b>22.4.1</b> Model information</a></li>
<li class="chapter" data-level="22.4.2" data-path="docker-index.html"><a href="docker-index.html#model-docker-Dockerfile"><i class="fa fa-check"></i><b>22.4.2</b> Model build</a></li>
<li class="chapter" data-level="22.4.3" data-path="docker-index.html"><a href="docker-index.html#common-docker-problems"><i class="fa fa-check"></i><b>22.4.3</b> Common problems</a></li>
<li class="chapter" data-level="22.4.4" data-path="docker-index.html"><a href="docker-index.html#debugging-missing-libraries"><i class="fa fa-check"></i><b>22.4.4</b> Debugging missing libraries</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path="docker-index.html"><a href="docker-index.html#docker-build-images"><i class="fa fa-check"></i><b>22.5</b> Building and modifying images</a><ul>
<li class="chapter" data-level="22.5.1" data-path="docker-index.html"><a href="docker-index.html#docker-local-devel"><i class="fa fa-check"></i><b>22.5.1</b> Local development and testing with Docker</a></li>
</ul></li>
<li class="chapter" data-level="22.6" data-path="docker-index.html"><a href="docker-index.html#docker-troubleshooting"><i class="fa fa-check"></i><b>22.6</b> Troubleshooting Docker</a><ul>
<li class="chapter" data-level="22.6.1" data-path="docker-index.html"><a href="docker-index.html#package-not-available-while-building-images"><i class="fa fa-check"></i><b>22.6.1</b> “Package not available” while building images</a></li>
</ul></li>
<li class="chapter" data-level="22.7" data-path="docker-index.html"><a href="docker-index.html#docker-migrate"><i class="fa fa-check"></i><b>22.7</b> Migrating PEcAn from VM to Docker</a><ul>
<li class="chapter" data-level="22.7.1" data-path="docker-index.html"><a href="docker-index.html#running-bety-as-a-docker-container"><i class="fa fa-check"></i><b>22.7.1</b> Running BETY as a docker container</a></li>
</ul></li>
<li class="chapter" data-level="22.8" data-path="docker-index.html"><a href="docker-index.html#pecan-api"><i class="fa fa-check"></i><b>22.8</b> The PEcAn Docker API</a></li>
<li class="chapter" data-level="22.9" data-path="docker-index.html"><a href="docker-index.html#rabbitmq"><i class="fa fa-check"></i><b>22.9</b> RabbitMQ</a><ul>
<li class="chapter" data-level="22.9.1" data-path="docker-index.html"><a href="docker-index.html#rabbitmq-basics-sender"><i class="fa fa-check"></i><b>22.9.1</b> Producer – <code>sender.py</code></a></li>
<li class="chapter" data-level="22.9.2" data-path="docker-index.html"><a href="docker-index.html#rabbitmq-basics-receiver"><i class="fa fa-check"></i><b>22.9.2</b> Consumer – <code>receiver.py</code></a></li>
<li class="chapter" data-level="22.9.3" data-path="docker-index.html"><a href="docker-index.html#rabbitmq-web"><i class="fa fa-check"></i><b>22.9.3</b> RabbitMQ and the PEcAn web interface</a></li>
<li class="chapter" data-level="22.9.4" data-path="docker-index.html"><a href="docker-index.html#rabbitmq-xml"><i class="fa fa-check"></i><b>22.9.4</b> RabbitMQ in the PEcAn XML</a></li>
<li class="chapter" data-level="22.9.5" data-path="docker-index.html"><a href="docker-index.html#rabbitmq-dockerfile"><i class="fa fa-check"></i><b>22.9.5</b> RabbitMQ configuration in Dockerfiles</a></li>
<li class="chapter" data-level="22.9.6" data-path="docker-index.html"><a href="docker-index.html#rabbitmq-case-study"><i class="fa fa-check"></i><b>22.9.6</b> Case study: PEcAn web interface</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="pecan-remote.html"><a href="pecan-remote.html"><i class="fa fa-check"></i><b>23</b> Remote execution with PEcAn</a><ul>
<li class="chapter" data-level="23.1" data-path="pecan-remote.html"><a href="pecan-remote.html#basics-of-ssh"><i class="fa fa-check"></i><b>23.1</b> Basics of SSH</a></li>
<li class="chapter" data-level="23.2" data-path="pecan-remote.html"><a href="pecan-remote.html#ssh-authentication-password-vs.ssh-key"><i class="fa fa-check"></i><b>23.2</b> SSH authentication – password vs. SSH key</a></li>
<li class="chapter" data-level="23.3" data-path="pecan-remote.html"><a href="pecan-remote.html#ssh-tunneling"><i class="fa fa-check"></i><b>23.3</b> SSH tunneling</a></li>
<li class="chapter" data-level="23.4" data-path="pecan-remote.html"><a href="pecan-remote.html#ssh-tunnels-and-pecan"><i class="fa fa-check"></i><b>23.4</b> SSH tunnels and PEcAn</a></li>
<li class="chapter" data-level="23.5" data-path="pecan-remote.html"><a href="pecan-remote.html#basic-remote-execute-functions"><i class="fa fa-check"></i><b>23.5</b> Basic remote execute functions</a></li>
<li class="chapter" data-level="23.6" data-path="pecan-remote.html"><a href="pecan-remote.html#remote-model-execution-with-pecan"><i class="fa fa-check"></i><b>23.6</b> Remote model execution with PEcAn</a></li>
<li class="chapter" data-level="23.7" data-path="pecan-remote.html"><a href="pecan-remote.html#xml-configuration"><i class="fa fa-check"></i><b>23.7</b> XML configuration</a></li>
<li class="chapter" data-level="23.8" data-path="pecan-remote.html"><a href="pecan-remote.html#configuration-for-pecan-web-interface"><i class="fa fa-check"></i><b>23.8</b> Configuration for PEcAn web interface</a></li>
<li class="chapter" data-level="23.9" data-path="pecan-remote.html"><a href="pecan-remote.html#running-pecan-code-for-remotely"><i class="fa fa-check"></i><b>23.9</b> Running PEcAn code for remotely</a></li>
<li class="chapter" data-level="23.10" data-path="pecan-remote.html"><a href="pecan-remote.html#special-case-geo.bu.edu"><i class="fa fa-check"></i><b>23.10</b> Special case: <code>geo.bu.edu</code></a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="data-assimilation-with-dart.html"><a href="data-assimilation-with-dart.html"><i class="fa fa-check"></i><b>24</b> Data assimilation with DART</a></li>
<li class="part"><span><b>IV Appendix</b></span></li>
<li class="chapter" data-level="25" data-path="miscellaneous.html"><a href="miscellaneous.html"><i class="fa fa-check"></i><b>25</b> Miscellaneous</a><ul>
<li class="chapter" data-level="25.1" data-path="miscellaneous.html"><a href="miscellaneous.html#todo"><i class="fa fa-check"></i><b>25.1</b> TODO</a></li>
<li class="chapter" data-level="25.2" data-path="miscellaneous.html"><a href="miscellaneous.html#using-the-pecan-download.file-function"><i class="fa fa-check"></i><b>25.2</b> Using the PEcAn download.file() function</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="faq.html"><a href="faq.html"><i class="fa fa-check"></i><b>26</b> FAQ</a></li>
<li class="chapter" data-level="27" data-path="pecan-project-used-in-courses.html"><a href="pecan-project-used-in-courses.html"><i class="fa fa-check"></i><b>27</b> PEcAn Project Used in Courses</a><ul>
<li class="chapter" data-level="27.0.1" data-path="pecan-project-used-in-courses.html"><a href="pecan-project-used-in-courses.html#university-classes"><i class="fa fa-check"></i><b>27.0.1</b> University classes</a></li>
<li class="chapter" data-level="27.0.2" data-path="pecan-project-used-in-courses.html"><a href="pecan-project-used-in-courses.html#summer-courses-workshops"><i class="fa fa-check"></i><b>27.0.2</b> Summer Courses / Workshops</a></li>
<li class="chapter" data-level="27.0.3" data-path="pecan-project-used-in-courses.html"><a href="pecan-project-used-in-courses.html#selected-publications"><i class="fa fa-check"></i><b>27.0.3</b> Selected Publications</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Predictive Ecosystem Analyzer</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="user-section" class="section level1">
<h1><span class="header-section-number">5</span> User Tutorial Section</h1>
<p>The user Section contains the following sections:
<a href="basic-web-wrokflow.html#basic-web-wrokflow">Basic Web Workflow Usage</a>
<a href="#intermediate%20User%20Guide">PEcAn Web Interface</a>
<a href="user-section.html#advanced-user">PEcAn from the Command Line</a></p>
<div id="how-pecan-works-in-a-nutshell" class="section level2">
<h2><span class="header-section-number">5.1</span> How PEcAn Works in a nutshell</h2>
<p>PEcAn provides an interface to a variety of ecosystem models and attempts to standardize and automate the processes of model parameterization, execution, and analysis. First, you choose an ecosystem model, then the time and location of interest (a site), the plant community (or crop) that you are interested in simulating, and a source of atmospheric data from the BETY database (LeBauer et al, 2010). These are set in a “settings” file, commonly named <code>pecan.xml</code> which can be edited manually if desired. From here, PEcAn will take over and set up and execute the selected model using your settings. The key is that PEcAn uses models as-is, and all of the translation steps are done within PEcAn so no modifications are required of the model itself. Once the model is finished it will allow you to create graphs with the results of the simulation as well as download the results. It is also possible to see all past experiments and simulations.</p>
<p>There are two ways of using PEcAn, via the web interface and directly within R. Even for users familiar with R, using the web interface is a good place to start because it provides a high level overview of the PEcAn workflow. The quickest way to get started is to download the virtual machine or use an AWS instance.</p>
</div>
<div id="demo-table" class="section level2">
<h2><span class="header-section-number">5.2</span> PEcAn Demos</h2>
<p>The following Tutorials assume you have installed PEcAn. If you have not, please consult the <a href="pecan-manual-setup.html#pecan-manual-setup">PEcAn Installation Section</a>.</p>
<table>
<thead>
<tr class="header">
<th align="center">Type</th>
<th align="center">Title</th>
<th align="center">Web Link</th>
<th align="center">Source Rmd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Demo</td>
<td align="center">Basic Run</td>
<td align="center"><a href="https://pecanproject.github.io/pecan-documentation/tutorials/Demo01.html">html</a></td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/develop/documentation/tutorials/01_Demo_Basic_Run/Demo01.Rmd">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Demo</td>
<td align="center">Uncertainty Analysis</td>
<td align="center"><a href="https://pecanproject.github.io/pecan-documentation/tutorials/Demo02.html">html</a></td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/master/documentation/tutorials/02_Demo_Uncertainty_Analysis">Rmd</a></td>
</tr>
<tr class="odd">
<td align="center">Demo</td>
<td align="center">Output Analysis</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/develop/documentation/tutorials/AnalyzeOutput">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Demo</td>
<td align="center">MCMC</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/develop/documentation/tutorials/MCMC">Rmd</a></td>
</tr>
<tr class="odd">
<td align="center">Demo</td>
<td align="center">Parameter Assimilation</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/develop/documentation/tutorials/ParameterAssimilation">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Demo</td>
<td align="center">State Assimilation</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/develop/documentation/tutorials/StateAssimilation">Rmd</a></td>
</tr>
<tr class="odd">
<td align="center">Demo</td>
<td align="center">Sensitivity</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/develop/documentation/tutorials/sensitivity">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Vignette</td>
<td align="center">Allometries</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/master/modules/allometry/vignettes/AllomVignette.Rmd">Rmd</a></td>
</tr>
<tr class="odd">
<td align="center">Vignette</td>
<td align="center">MCMC</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/master/modules/assim.batch/vignettes/AssimBatchVignette.Rmd">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Vignette</td>
<td align="center">Meteorological Data</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/master/modules/data.atmosphere/vignettes">Rmd</a></td>
</tr>
<tr class="odd">
<td align="center">Vignette</td>
<td align="center">Meta-Analysis</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/master/modules/meta.analysis/vignettes/single.MA_demo.Rmd">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Vignette</td>
<td align="center">Photosynthetic Response Curves</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/master/modules/photosynthesis/vignettes/ResponseCurves.Rmd">Rmd</a></td>
</tr>
<tr class="odd">
<td align="center">Vignette</td>
<td align="center">Priors</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/master/modules/priors/vignettes/priors_demo.Rmd">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Vignette</td>
<td align="center">Leaf Spectra:PROSPECT inversion</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/master/modules/rtm/vignettes/pecanrtm.vignette.Rmd">Rmd</a></td>
</tr>
</tbody>
</table>

</div>
<div id="demo-01-basic-run-pecan" class="section level2">
<h2><span class="header-section-number">5.3</span> Demo 01: Basic Run PEcAn</h2>
<div id="objective" class="section level4">
<h4><span class="header-section-number">5.3.0.1</span> Objective</h4>
<p>We will begin by exploring a set of web-based tools that are designed to run single-site model runs. A lot of the detail about what’s going on under the hood, and all the outputs that PEcAn produces, are left to Demo 2. This demo will also demonstrate how to use PEcAn outputs in additional analyses outside of PEcAn.</p>
</div>
<div id="pecan-url" class="section level4">
<h4><span class="header-section-number">5.3.0.2</span> PEcAn URL</h4>
<p>In the following demo, <strong>URL</strong> is the web address of a PEcAn server and will refer to one of the following:</p>
<ul>
<li>If you are doing a live demo with the PEcAn team, <strong>URL was provided</strong></li>
<li>If you are running the PEcAn <a href="#basicvm">virtual machine</a>: <strong>URL = localhost:6480</strong></li>
<li>If you are running PEcAn using <a href="working-with-vm.html#awsvm">Amazon Web Services (AWS)</a>, <strong>URL is the Public IP</strong></li>
<li>If you are running PEcAn using <a href="#dockervm">Docker</a>, <strong>URL is localhost:8000/pecan/</strong> (trailing backslash is important!)</li>
<li>If you followed instructions found in [Install PEcAn by hand], <strong>URL is your server’s IP</strong></li>
</ul>
</div>
<div id="start-pecan" class="section level4">
<h4><span class="header-section-number">5.3.0.3</span> Start PEcAn:</h4>
<ol style="list-style-type: decimal">
<li><strong>Enter URL in your web browser</strong></li>
<li><strong>Click “Run Models”</strong></li>
<li><strong>Click the ‘Next’ button</strong> to move to the “Site Selection” page.</li>
</ol>
<p><img src="extfiles/startpecan.jpg" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="site-selection" class="section level4">
<h4><span class="header-section-number">5.3.0.4</span> Site Selection</h4>
<p><img src="extfiles/mapmodel.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="host" class="section level4">
<h4><span class="header-section-number">5.3.0.5</span> Host</h4>
<p><strong>Select the local machine “pecan”</strong>. Other options exist if you’ve read and followed instructions found in <a href="pecan-remote.html#pecan-remote">Remote execution with PEcAn</a>.</p>
</div>
<div id="mode" class="section level4">
<h4><span class="header-section-number">5.3.0.6</span> Mode</h4>
<p>Select <strong>SIPNET</strong> (r136) from the available models because it is quick &amp; simple. Reference material can be found in [Models in PEcAn]</p>
</div>
<div id="site-group" class="section level4">
<h4><span class="header-section-number">5.3.0.7</span> Site Group</h4>
<p>To filter sites, you can <strong>select a specific group of sites</strong>. For this tutorial we will use <strong>Ameriflux</strong>.</p>
</div>
<div id="conversion" class="section level4">
<h4><span class="header-section-number">5.3.0.8</span> Conversion:</h4>
<p><strong>Select the conversion check box</strong>, to show all sites that PEcAn is capable of generating model drivers for automatically. By default (unchecked), PEcAn only displays sites where model drivers already exist in the system database</p>
</div>
<div id="site" class="section level4">
<h4><span class="header-section-number">5.3.0.9</span> Site:</h4>
<p><strong>For this tutorial, type <em>US-NR1</em> in the search box to display the Niwot Ridge Ameriflux site (US-NR1), and then click on the pin icon</strong>. When you click on a site’s flag on the map, it will give you the name and location of the site and put that site in the “Site:” box on the left hand site, indicating your current selection.</p>
<p>Once you are finished with the above steps, <strong>click “Next”</strong>.</p>
</div>
<div id="run-specification" class="section level4">
<h4><span class="header-section-number">5.3.0.10</span> Run Specification</h4>
<p><img src="extfiles/runspec.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Next we will specify settings required to run the model. Be aware that the inputs required for any particular model may vary somewhat so there may be addition optional or required input selections available for other models.</p>
</div>
<div id="pft-plant-functional-type" class="section level4">
<h4><span class="header-section-number">5.3.0.11</span> PFT (Plant Functional Type):</h4>
<p><strong>Niwot Ridge is temperate coniferous</strong>. Available PFTs will vary by model and some models allow multiple competing PFTs to be selected. Also select <strong>soil</strong> to control the soil parameters</p>
</div>
<div id="startend-date" class="section level4">
<h4><span class="header-section-number">5.3.0.12</span> Start/End Date:</h4>
<p>Select <strong>2003/01/01</strong> to <strong>2006/12/31</strong>. In general, be careful to select dates for which there is available driver data.</p>
</div>
<div id="weather-data" class="section level4">
<h4><span class="header-section-number">5.3.0.13</span> Weather Data:</h4>
<p><strong>Select “Use AmerifluxLBL”</strong> from the <a href="available-meteorological-drivers.html#available-meteorological-drivers">Available Meteorological Drivers</a>.</p>
</div>
<div id="optional-settings" class="section level4">
<h4><span class="header-section-number">5.3.0.14</span> Optional Settings:</h4>
<p><strong>Leave all blank for demo run</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Email</strong> sends a message when the run is complete.</li>
<li><strong>Use Brown Dog</strong> will use the Brown Dog web services in order to do input file conversions. (<strong>Note: Required if you select <em>Use NARR</em> for Weather Data</strong>)</li>
<li><strong>Edit pecan.xml</strong> allows you to configure advanced settings via the PEcAn settings file</li>
<li><strong>Edit model config</strong> pauses the workflow after PEcAn has written all model specific settings but before the model runs are called and allows users to configure any additional settings internal to the model.</li>
<li><strong>Advanced Setup</strong> controls ensemble and sensitivity run settings discussed in Demo 2.</li>
</ol>
<p>Finally, <strong>click “Next”</strong> to start the model run.</p>
</div>
<div id="data-use-policies" class="section level4">
<h4><span class="header-section-number">5.3.0.15</span> Data Use Policies</h4>
<p>You will see a data policy statement if you selected a data source with a policy. Agreeing to the policy is required prior to starting the run.</p>
</div>
<div id="if-you-get-an-error-in-your-run" class="section level4">
<h4><span class="header-section-number">5.3.0.16</span> If you get an error in your run</h4>
<p>If you get an error in your run as part of a live demo or class activity, it is probably simplest to start over and try changing options and re-running (e.g. with a different site or PFT), as time does not permit detailed debugging. If the source of the error is not immediately obvious, you may want to take a look at the workflow.Rout to see the log of the PEcAn workflow or the logfile.txt to see the model execution output log and then refer to the <a href="http://pecanproject.github.io/documentation.html">Documentation</a> or the <a href="https://join.slack.com/t/pecanproject/shared_invite/enQtMzkyODUyMjQyNTgzLTYyZTZiZWQ4NGE1YWU3YWIyMTVmZjEyYzA3OWJhYTZmOWQwMDkwZGU0Mjc4Nzk0NGYwYTIyM2RiZmMyNjg5MTE">Chat Room</a> for help.</p>
</div>
<div id="model-run-workflow" class="section level4">
<h4><span class="header-section-number">5.3.0.17</span> Model Run Workflow</h4>
<p><img src="extfiles/execstatus.jpg" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="met-process" class="section level4">
<h4><span class="header-section-number">5.3.0.18</span> MET Process:</h4>
<p>First, PEcAn will download meteorological data based on the type of the Weather Data you chose, and process it into the specific format for the chosen model</p>
</div>
<div id="trait-meta" class="section level4">
<h4><span class="header-section-number">5.3.0.19</span> TRAIT / META:</h4>
<p>PEcAn then estimates model parameters by performing a meta-analysis of the available trait data for a PFT. TRAIT will extract relevant trait data from the database. META performs a hierarchical Bayes meta-analysis of available trait data. The output of this analysis is a probability distribution for each model parameter. PEcAn selects the median value of this parameter as the default, but in Demo 2 we will see how PEcAn can use this parameter uncertainty to make probabilistic forecasts and assess model sensitivity and uncertainty. Errors at this stage usually indicate errors in the trait database or incorrectly specified PFTs (e.g. defining a variable twice).</p>
</div>
<div id="config" class="section level4">
<h4><span class="header-section-number">5.3.0.20</span> CONFIG:</h4>
<p>writes model-specific settings and parameter files</p>
</div>
<div id="model" class="section level4">
<h4><span class="header-section-number">5.3.0.21</span> MODEL:</h4>
<p>runs model.</p>
</div>
<div id="output" class="section level4">
<h4><span class="header-section-number">5.3.0.22</span> OUTPUT:</h4>
<p>All model outputs are converted to <a href="http://nacp.ornl.gov/MsTMIP_variables.shtml">standard netCDF format</a></p>
</div>
<div id="ensemble-sensitivity" class="section level4">
<h4><span class="header-section-number">5.3.0.23</span> ENSEMBLE &amp; SENSITIVITY:</h4>
<p>If enabled post-process output for these analyses</p>
<p>If at any point a Stage Name has the <strong>Status “ERROR”</strong> please notify the PEcAn team member that is administering the demo or feel free to do any of the following:</p>
<ul>
<li>Refer to the PEcAn Documentation for documentation</li>
<li>Post the end of your workflow log on our Gitter chat</li>
<li>Post an issue on Github.</li>
</ul>
<p>The entire PEcAn team welcomes any questions you may have!</p>
<p><strong>If the Finished Stage has a Status of “DONE”, congratulations!</strong> If you got this far, you have managed to run an ecosystem model without ever touching a line of code! Now it’s time to look at the results <strong>click Finished</strong>.</p>
<p>FYI, <a href="https://pecanproject.github.io/pecan-documentation/master/adding-an-ecosystem-model.html">adding a new model</a> to PEcAn does not require modification of the model’s code, just the implementation of a wrapper function.</p>
</div>
<div id="output-and-visualization" class="section level4">
<h4><span class="header-section-number">5.3.0.24</span> Output and Visualization</h4>
<p><strong>For now focus on graphs, we will explore all of PEcAn’s outputs in more detail in Demo 02.</strong></p>
</div>
<div id="graphs" class="section level4">
<h4><span class="header-section-number">5.3.0.25</span> Graphs</h4>
<ol style="list-style-type: decimal">
<li><strong>Select a Year and Y-axis Variable, and then click ‘Plot run/year/variable’.</strong> Initially leave the X-axis as time.</li>
<li>Within this figure the <strong>points indicate the daily mean</strong> for the variable while the <strong>envelope encompasses the diurnal variability (max and min)</strong>.</li>
<li>Variable names and units are based on a <a href="http://nacp.ornl.gov/MsTMIP_variables.shtml">standard netCDF format</a>.</li>
<li>Try looking at a number of different output variables over different years.</li>
<li>Try <strong>changing the X-axis</strong> to look at bivariate plots of how different output variables are related to one another. Be aware that PEcAn currently runs a moving min/mean/max through bivariate plots, just as it does with time series plots. In some cases this makes more sense than others.</li>
</ol>
</div>
<div id="alternative-visualization-r-shiny" class="section level4">
<h4><span class="header-section-number">5.3.0.26</span> Alternative Visualization: R Shiny</h4>
<ol style="list-style-type: decimal">
<li><strong>Click on Open SHINY</strong>, which will open a new browser window. The shiny app will automatically access your run’s output files and allow you to visualize all output variables as a function of time.</li>
</ol>
<p><img src="extfiles/workflowshiny.png" width="100%" style="display: block; margin: auto;" /></p>
<ol start="2" style="list-style-type: decimal">
<li>Use the pull down menu under <strong>Variable Name</strong> to choose whichever output variable you wish to plot.</li>
</ol>
</div>
<div id="model-run-archive" class="section level4">
<h4><span class="header-section-number">5.3.0.27</span> Model Run Archive</h4>
<p><strong>Return to the output window and Click on the HISTORY button. Click on any previous run in the “ID” column</strong> to go to the current state of that run’s execution – you can always return to old runs and runs in-progress this way. The run you just did should be the more recent entry in the table. <strong>For the next analysis, make note of the ID number from your run.</strong></p>
</div>
<div id="next-steps" class="section level4">
<h4><span class="header-section-number">5.3.0.28</span> Next steps</h4>
<div id="analyzing-model-output" class="section level5">
<h5><span class="header-section-number">5.3.0.28.1</span> Analyzing model output</h5>
<p>Follow this tutorial, [Analyze Output] to learn how to <strong>open model output in R and compare to observed data</strong></p>
</div>
</div>
<div id="demo-02" class="section level4">
<h4><span class="header-section-number">5.3.0.29</span> DEMO 02</h4>
<p><a href="user-section.html#demo-02-sensitivity-and-uncertainty-analysis">Demo 02: Sensitivity and Uncertainty Analysis</a> will show how to perform <strong>Ensemble &amp; Sensitivity Analyses</strong> through the web interface and explore the PEcAn outputs in greater detail, including the <strong>trait meta-analysis</strong></p>

</div>
</div>
<div id="demo-02-sensitivity-and-uncertainty-analysis" class="section level2">
<h2><span class="header-section-number">5.4</span> Demo 02: Sensitivity and Uncertainty Analysis</h2>
<p>In Demo 2 we will be looking at how PEcAn can use information about parameter uncertainty to perform three automated analyses:</p>
<ul>
<li><strong>Ensemble Analysis</strong>: Repeat numerous model runs, each sampling from the parameter uncertainty, to generate a probability distribution of model projections. <strong>Allows us to put a confidence interval on the model</strong></li>
<li><strong>Sensitivity Analysis</strong>: Repeats numerous model runs to assess how changes in model parameters will affect model outputs. <strong>Allows us to identify which parameters the model is most sensitive to.</strong></li>
<li><strong>Uncertainty Analysis</strong>: Combines information about model sensitivity with information about parameter uncertainty to determine the contribution of each model parameter to the uncertainty in model outputs. <strong>Allow us to identify which parameters are driving model uncertainty.</strong></li>
</ul>
<div id="run-specification-1" class="section level4">
<h4><span class="header-section-number">5.4.0.1</span> Run Specification</h4>
<ol style="list-style-type: decimal">
<li><p>Return to the main menu for the PEcAn web interface: <strong>URL &gt; Run Models</strong></p></li>
<li><p>Repeat the steps for site selection and run specification from Demo 01, but also <strong>click on “Advanced setup”</strong>, then click Next.</p></li>
<li><p>By clicking Advanced setup, PEcAn will first show an Analysis Menu, where we are going to specify new settings.</p></li>
</ol>
<ul>
<li><p>For an ensemble analysis, increase the number of runs in the ensemble, in this case set <strong>Runs to 50</strong>. In practice you would want to use a larger ensemble size (100-5000) than we are using in the demo. The ensemble analysis samples parameters from their posterior distributions to propagate this uncertainty into the model output.</p></li>
<li><p>PEcAn’s sensitivity analysis holds all parameters at their median value and then varies each parameter one-at-a-time based on the quantiles of the posterior distribution. PEcAn also includes a handy shortcut, which is the default behavior for the web interface, that converts a specified standard deviation into its Normal quantile equivalent (e.g. 1 and -1 are converted to 0.157 and 0.841). In this example <strong>set Sensitivity to -2,-1,1,2</strong> (the median value, 0, occurs by default).</p></li>
<li><p>We also can tell PEcAn which variable to run the sensitivity on. Here, <strong>set Variables to NEE</strong>, so we can compare against flux tower NEE observations.</p></li>
</ul>
<p><strong>Click Next</strong></p>
</div>
<div id="additional-outputs" class="section level4">
<h4><span class="header-section-number">5.4.0.2</span> Additional Outputs:</h4>
<p>The PEcAn workflow will take considerably longer to complete since we have just asked for over a hundred model runs. Once the runs are complete you will return to the output visualization page were there will be a few new outputs to explore, as well as outputs that were present earlier that we’ll explore in greater details:</p>
</div>
<div id="run-id" class="section level4">
<h4><span class="header-section-number">5.4.0.3</span> Run ID:</h4>
<p>While the sensitivity and ensemble analyses synthesize across runs, you can also select individual runs from the Run ID menu. You can use the Graphs menu to visualize each individual run, or open individual runs in Shiny</p>
</div>
<div id="inputs" class="section level4">
<h4><span class="header-section-number">5.4.0.4</span> Inputs:</h4>
<p>This menu shows the contents of /run which lets you look at and download:</p>
<ol style="list-style-type: decimal">
<li>A summary file (README.txt) describing each run: location, run ID, model, dates, whether it was in the sensitivity or ensemble analysis, variables modifed, etc.</li>
<li>The model-specific input files fed into the model</li>
<li>The jobs.sh file used to submit the model run</li>
</ol>
</div>
<div id="outputs" class="section level4">
<h4><span class="header-section-number">5.4.0.5</span> Outputs:</h4>
<p>This menu shows the contents of /out. A number of files generated by the underlying ecosystem model are archived and available for download. These include:</p>
<ol style="list-style-type: decimal">
<li>Output files in the standardized netCDF ([year].nc) that can be downloaded for visualization and analysis (R, Matlab, ncview, panoply, etc)</li>
<li>Raw model output in model-specific format (e.g. sipnet.out).</li>
<li>Logfile.txt contains job.sh &amp; model error, warning, and informational messages</li>
</ol>
</div>
<div id="pfts" class="section level4">
<h4><span class="header-section-number">5.4.0.6</span> PFTs:</h4>
<p>This menu shows the contents of /pft. There is a wide array of outputs available that are related to the process of estimating the model parameters and running sensitivity/uncertainty analyses for a specific Plant Functional Type.</p>
<ol style="list-style-type: decimal">
<li><strong>TRAITS</strong>: The Rdata files <strong>trait.data.Rdata</strong> and <strong>madata.Rdata</strong> are, respectively, the available trait data extracted from the database that was used to estimate the model parameters and that same data cleaned and formatted for the statistical code. The <strong>list of variables that are queried is determined by what variables have priors associated with them in the definition of the PFTs</strong>. Priors are output into <strong>prior.distns.Rdata</strong>. Likewise, the <strong>list of species that are associated with a PFT determines what subset of data is extracted</strong> out of all data matching a given variable name. Demo 3 will demonstrate how a PFT can be created or modified. To look at these files in RStudio <strong>click on these files to load them into your workspace</strong>. You can further examine them in the <em>Environment</em> window or accessing them at the command line. For example, try typing <code>names(trait.data)</code> as this will tell you what variables were extracted, <code>names(trait.data$Amax)</code> will tell you the names of the columns in the Amax table, and <code>summary(trait.data$Amax)</code> will give you summary data about the Amax values.</li>
<li><strong>META-ANALYSIS</strong>:</li>
</ol>
<ul>
<li><code>*.bug</code>: The evaluation of the meta-analysis is done using a Bayesian statistical software package called JAGS that is called by the R code. For each trait, the R code will generate a [trait].model.bug file that is the JAGS code for the meta-analysis itself. This code is generated on the fly, with PEcAn adding or subtracting the site, treatment, and greenhouse terms depending upon the presence of these effects in the data itself. If the &lt;random.effects&gt; tag is set to FALSE then all random effects will be turned off even if there are multiple sites.</li>
<li><code>meta-analysis.log</code> contains a number of diagnostics, including the summary statistics of the model, an assessment of whether the posterior is consistent with the prior, and the status of the Gelman-Brooks-Rubin convergence statistic (which is ideally 1.0 but should be less than 1.1).</li>
<li><code>ma.summaryplots.*.pdf</code> are collections of diagnostic plots produced in R after the above JAGS code is run that are useful in assessing the statistical model. <em>Open up one of these pdfs</em> to evaluate the shape of the posterior distributions (they should generally be unimodal), the convergence of the MCMC chains (all chains should be mixing well from the same distribution), and the autocorrelation of the samples (should be low).</li>
<li><code>traits.mcmc.Rdata</code> contains the raw output from the statistical code. This includes samples from all of the parameters in the meta-analysis model, not just those that feed forward to the ecosystem, but also the variances, fixed effects, and random effects.</li>
<li><code>post.distns.Rdata</code> stores a simple tables of the posterior distributions for all model parameters in terms of the name of the distribution and its parameters.</li>
<li><code>posteriors.pdf</code> provides graphics showing, for each model parameter, the prior distribution, the data, the smoothed histogram of the posterior distribution (labeled post), and the best-fit analytical approximation to that smoothed histogram (labeled approx). <em>Open posteriors.pdf and compare the posteriors to the priors and data</em></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><strong>SENSITIVITY ANALYSIS</strong></li>
</ol>
<ul>
<li><code>sensitivity.analysis.[RunID].[Variable].[StartYear].[EndYear].pdf</code> shows the raw data points from univariate one-at-a-time analyses and spline fits through the points. <em>Open this file</em> to determine which parameters are most and least sensitive</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li><strong>UNCERTAINTY ANALYSIS</strong></li>
</ol>
<ul>
<li><code>variance.decomposition.[RunID].[Variable].[StartYear].[EndYear].pdf</code>, contains three columns, the coefficient of variation (normalized posterior variance), the elasticity (normalized sensitivity), and the partial standard deviation of each model parameter. <strong>Open this file for BOTH the soil and conifer PFTS and answer the following questions:</strong></li>
<li>The Variance Decomposition graph is sorted by the variable explaining the largest amount of variability in the model output (right hand column). <strong>From this graph identify the top-tier parameters that you would target for future constraint.</strong><br />
</li>
<li>A parameter can be important because it is highly sensitive, because it is highly uncertain, or both. <strong>Identify parameters in your output that meet each of these criteria.</strong> Additionally, <strong>identify parameters that are highly uncertain but unimportant (due to low sensitivity) and those that are highly sensitive but unimportant (due to low uncertainty)</strong>.</li>
<li>Parameter constraints could come from further literature synthesis, from direct measurement of the trait, or from data assimilation. <strong>Choose the parameter that you think provides the most efficient means of reducing model uncertainty and propose how you might best reduce uncertainty in this process</strong>. In making this choice remember that not all processes in models can be directly observed, and that the cost-per-sample for different measurements can vary tremendously (and thus the parameter you measure next is not always the one contributing the most to model variability). Also consider the role of parameter uncertainty versus model sensitivity in justifying your choice of what parameters to constrain.</li>
</ul>
</div>
<div id="pecan-files" class="section level4">
<h4><span class="header-section-number">5.4.0.7</span> PEcAn Files:</h4>
<p>This menu shows the contents of the root workflow folder that are not in one of the folders indicated above. It mostly contains log files from the PEcAn workflow that are useful if the workflow generates an error, and as metadata &amp; provenance (a detailed record of how data was generated).</p>
<ol style="list-style-type: decimal">
<li><code>STATUS</code> gives a summary of the steps of the workflow, the time they took, and whether they were successful</li>
<li><code>pecan.*.xml</code> are PEcAn settings files</li>
<li><code>workflow.R</code> is the workflow script</li>
<li><code>workflow.Rout</code> is the corresponding log file</li>
<li><code>samples.Rdata</code> contains the parameter values used in the runs. This file contains two data objects, sa.samples and ensemble.samples, that are the parameter values for the sensitivity analysis and ensemble runs respectively</li>
<li><code>sensitivity.output.[RunID].[Variable].[StartYear].[EndYear].Rdata</code> contains the object sensitivity.output which is the model outputs corresponding to the parameter values in sa.samples.</li>
<li>ENSEMBLE ANALYSIS</li>
</ol>
<ul>
<li><code>ensemble.Rdata</code> contains contains the object ensemble.output, which is the model predictions at the parameter values given in ensemble.samples.</li>
<li><code>ensemble.analysis.[RunID].[Variable].[StarYear].[EndYear].pdf</code> contains the ensemble prediction as both a histogram and a boxplot.</li>
<li><code>ensemble.ts.[RunID].[Variable].[StartYear].[EndYear].pdf</code> contains a time-series plot of the ensemble mean, median, and 95% CI</li>
</ul>
</div>
<div id="global-sensitivity-shiny" class="section level4">
<h4><span class="header-section-number">5.4.0.8</span> Global Sensitivity: Shiny</h4>
<p><strong>Navigate to URL/shiny/global-sensitivity.</strong></p>
<p>This app uses the output from the ENSEMBLE runs to perform a global Monte Carlo sensitivity analysis. There are three modes controlled by Output type:</p>
<ol style="list-style-type: decimal">
<li><strong>Pairwise</strong> looks at the relationship between a specific parameter (X) and output (Y)</li>
<li><strong>All parameters</strong> looks at how all parameters affect a specific output (Y)</li>
<li><strong>All variables</strong> looks at how all outputs are affected by a specific parameter(X)</li>
</ol>
<p>In all of these analyses, the app also fits a linear regression to these scatterplots and reports a number of summary statistics. Among these, the slope is an indicator of <strong>global sensitivity</strong> and the R2 is an indicator of the contribution to <strong>global uncertainty</strong></p>
</div>
<div id="next-steps-1" class="section level4">
<h4><span class="header-section-number">5.4.0.9</span> Next Steps</h4>
<p>The next set of tutorials will focus on the process of data assimilation and parameter estimation. The next two steps are in “.Rmd” files which can be viewed online.</p>
</div>
<div id="assimilation-by-hand" class="section level4">
<h4><span class="header-section-number">5.4.0.10</span> Assimilation ‘by hand’</h4>
<p><a href="https://github.com/PecanProject/pecan/blob/master/documentation/tutorials/sensitivity/PEcAn_sensitivity_tutorial_v1.0.Rmd">Explore</a> how model error changes as a function of parameter value (i.e. data assimilation ‘by hand’)</p>
</div>
<div id="mcmc-concepts" class="section level4">
<h4><span class="header-section-number">5.4.0.11</span> MCMC Concepts</h4>
<p><a href="https://github.com/PecanProject/pecan/blob/master/documentation/tutorials/MCMC/MCMC_Concepts.Rmd">Explore</a> Bayesian MCMC concepts using the photosynthesis module</p>
</div>
<div id="more-info-about-tools-analyses-and-specific-tasks" class="section level4">
<h4><span class="header-section-number">5.4.0.12</span> More info about tools, analyses, and specific tasks…</h4>
<p>Additional information about specific tasks (adding sites, models, data; software updates; etc.) and analyses (e.g. data assimilation) can be found in the PEcAn <a href="https://pecanproject.github.io/pecan-documentation/">documentation</a></p>
<p>If you encounter a problem with PEcAn that’s not covered in the documentation, or if PEcAn is missing functionality you need, please search <a href="https://github.com/PecanProject/pecan/issues?q=">known bugs and issues</a>, submit a <a href="https://github.com/PecanProject/pecan/issues/new">bug report</a>, or ask a question in our <a href="https://join.slack.com/t/pecanproject/shared_invite/enQtMzkyODUyMjQyNTgzLTYyZTZiZWQ4NGE1YWU3YWIyMTVmZjEyYzA3OWJhYTZmOWQwMDkwZGU0Mjc4Nzk0NGYwYTIyM2RiZmMyNjg5MTE">chat room</a>. Additional questions can be directed to the <a href="mailto:tonygard@bu.edu?subject=PEcAn%20Demo::">project manager</a></p>

</div>
</div>
<div id="othervignettes" class="section level2">
<h2><span class="header-section-number">5.5</span> Other Vignettes</h2>

<div id="simple-model-data-comparisons" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Simple Model-Data Comparisons</h3>
<div id="author-istem-fer-tess-mccabe" class="section level4">
<h4><span class="header-section-number">5.5.1.1</span> Author: Istem Fer, Tess McCabe</h4>
<p>In this tutorial we will compare model outputs to data outside of the PEcAn web interface. The goal of this is to demonstrate how to perform additional analyses using PEcAn’s outputs. To do this you can download each of the Output files, and then perform the analyses using whatever software you prefer, or you can perform analyses directly on the PEcAn server itself. Here we’ll be analyzing model outputs in R using a browser-based version of RStudio that’s installed on the server</p>
</div>
<div id="starting-rstudio-server" class="section level4">
<h4><span class="header-section-number">5.5.1.2</span> Starting RStudio Server</h4>
<ol style="list-style-type: decimal">
<li><p>Open RStudio Server in a new window at <strong>URL/rstudio</strong></p></li>
<li><p>The username is carya and the password is illinois.</p></li>
<li><p>To open a new R script click File &gt; New File &gt; R Script</p></li>
<li><p>Use the Files browser on the lower right pane to find where your run(s) are located</p></li>
</ol>
<ul>
<li><p>All PEcAn outputs are stored in the output folder. Click on this to open it up.</p></li>
<li><p>Within the outputs folder, there will be one folder for each workflow execution. For example, click to open the folder PEcAn_99000000001 if that’s your workflow ID</p></li>
<li><p>A workflow folder will have a few log and settings files (e.g. pecan.xml) and the following subfolders</p></li>
</ul>
<pre><code>run     contains all the inputs for each run
out     contains all the outputs from each run
pft     contains the parameter information for each PFT</code></pre>
<p>Within both the run and out folders there will be one folder for each unique model run, where the folder name is the run ID. Click to open the out folder. For our simple case we only did one run so there should be only one folder (e.g. 99000000001). Click to open this folder.</p>
<ul>
<li>Within this folder you will find, among other things, files of the format <year>.nc. Each of these files contains one year of model output in the standard PEcAn netCDF format. This is the model output that we will use to compare to data.</li>
</ul>
</div>
<div id="read-in-settings-from-an-xml-file" class="section level4">
<h4><span class="header-section-number">5.5.1.3</span> Read in settings From an XML file</h4>
<pre class="sourceCode r"><code class="sourceCode r">## Read in the xml

settings&lt;-PEcAn.settings<span class="op">::</span><span class="kw">read.settings</span>(<span class="st">&quot;~/output/PEcAn_99000000001/pecan.CONFIGS.xml&quot;</span>)

## To read in the model output 
runid&lt;-<span class="kw">as.character</span>(<span class="kw">read.table</span>(<span class="kw">paste</span>(settings<span class="op">$</span>outdir, <span class="st">&quot;/run/&quot;</span>,<span class="st">&quot;runs.txt&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))[<span class="dv">1</span>,<span class="dv">1</span>]) <span class="co"># Note: if you are using an xml from a run with multiple ensembles this line will provide only the first run id </span>
outdir&lt;-<span class="st"> </span><span class="kw">paste</span>(settings<span class="op">$</span>outdir,<span class="st">&quot;/out/&quot;</span>,runid,<span class="dt">sep=</span> <span class="st">&quot;&quot;</span>)
start.year&lt;-<span class="kw">as.numeric</span>(lubridate<span class="op">::</span><span class="kw">year</span>(settings<span class="op">$</span>run<span class="op">$</span>start.date))
end.year&lt;-<span class="kw">as.numeric</span>(lubridate<span class="op">::</span><span class="kw">year</span>(settings<span class="op">$</span>run<span class="op">$</span>end.date))

site.id&lt;-settings<span class="op">$</span>run<span class="op">$</span>site<span class="op">$</span>id
File_path&lt;-<span class="st">&quot;~/output/dbfiles/AmerifluxLBL_site_0-772/AMF_US-NR1_BASE_HH_9-1.csv&quot;</span>

## Open up a connection to The Bety Database 
bety &lt;-dplyr<span class="op">::</span><span class="kw">src_postgres</span>(<span class="dt">host =</span> settings<span class="op">$</span>database<span class="op">$</span>bety<span class="op">$</span>host, <span class="dt">user =</span> settings<span class="op">$</span>database<span class="op">$</span>bety<span class="op">$</span>user, <span class="dt">password =</span> settings<span class="op">$</span>database<span class="op">$</span>bety<span class="op">$</span>password, <span class="dt">dbname =</span> settings<span class="op">$</span>database<span class="op">$</span>bety<span class="op">$</span>dbname)</code></pre>
</div>
<div id="read-in-model-output-from-specific-variables" class="section level4">
<h4><span class="header-section-number">5.5.1.4</span> Read in model output from specific variables</h4>
<pre class="sourceCode r"><code class="sourceCode r">model_vars&lt;-<span class="kw">c</span>(<span class="st">&quot;time&quot;</span>, <span class="st">&quot;NEE&quot;</span>) <span class="co">#varibles being read</span>
model &lt;-<span class="st"> </span>PEcAn.utils<span class="op">::</span><span class="kw">read.output</span>(runid,outdir,start.year, end.year, model_vars,<span class="dt">dataframe=</span><span class="ot">TRUE</span>)</code></pre>
<p>The arguments to read.output are the run ID, the folder where the run is located, the start year, the end year, and the variables being read. The README file in the Input file dropdown menu of any successful run lists the run ID, the output folder, and the start and end year.</p>
</div>
<div id="compare-model-to-flux-observations" class="section level4">
<h4><span class="header-section-number">5.5.1.5</span> Compare model to flux observations</h4>
<p><strong>First</strong> <em>load up the observations</em> and take a look at the contents of the file</p>
<pre class="sourceCode r"><code class="sourceCode r">File_format&lt;-PEcAn.DB<span class="op">::</span><span class="kw">query.format.vars</span>(<span class="dt">bety =</span> bety, <span class="dt">format.id =</span> <span class="dv">5000000002</span>) <span class="co">#This matches the file with a premade &quot;format&quot; or a template that describes how the information in the file is organized</span>

site&lt;-PEcAn.DB<span class="op">::</span><span class="kw">query.site</span>(site.id,bety<span class="op">$</span>con) <span class="co">#This tells PEcAn where the data comes from</span>

observations&lt;-PEcAn.benchmark<span class="op">::</span><span class="kw">load_data</span>(<span class="dt">data.path =</span> File_path, <span class="dt">format=</span> File_format, <span class="dt">time.row =</span> File_format<span class="op">$</span>time.row,  <span class="dt">site =</span> site, <span class="dt">start_year =</span> start.year, <span class="dt">end_year =</span> end.year) <span class="co">#This will throw an error that not all of the units can be converted. That&#39;s ok, as the units of the varibles of interest (NEE) are being converted. </span></code></pre>
<p>File_Path refers to where you stored your observational data. In this example the default file path is an Ameriflux dataset from Niwot Ridge.</p>
<p>File_format queries the database for the format your file is in. The defualt format ID “5000000002” is for csv files downloaded from the Ameriflux website.
You could query for diffent kinds of formats that exist in bety or <a href="https://pecanproject.github.io/pecan-documentation/adding-an-ecosystem-model.html#formats">make your own</a>.</p>
<p>Here 772 is the database site ID for Niwot Ridge Forest, which tells pecan where the data is from and what time zone to assign any time data read in.</p>
<p><strong>Second</strong> <em>apply a conservative u* filter to observations</em></p>
<pre class="sourceCode r"><code class="sourceCode r">observations<span class="op">$</span>NEE[observations<span class="op">$</span>UST<span class="op">&lt;</span><span class="fl">0.2</span>]&lt;-<span class="ot">NA</span></code></pre>
<p><strong>Third</strong> <em>align model output and observations</em></p>
<pre class="sourceCode r"><code class="sourceCode r">aligned_dat =<span class="st"> </span>PEcAn.benchmark<span class="op">::</span><span class="kw">align_data</span>(<span class="dt">model.calc =</span> model, <span class="dt">obvs.calc =</span> observations, <span class="dt">var =</span><span class="st">&quot;NEE&quot;</span>, <span class="dt">align_method =</span> <span class="st">&quot;match_timestep&quot;</span>)</code></pre>
<p>When we aligned the data, we got a dataframe with the variables we requested in a <span class="math inline">\(NEE.m\)</span> and a <span class="math inline">\(NEE.o\)</span> format. The <span class="math inline">\(.o\)</span> is for observations, and the <span class="math inline">\(.m\)</span> is for model. The posix column allows for easy plotting along a timeseries.</p>
<p><strong>Fourth</strong>, <em>plot model predictions vs. observations</em> and compare this to a 1:1 line</p>
<pre class="sourceCode r"><code class="sourceCode r">## predicted vs observed plot
<span class="kw">plot</span>(aligned_dat<span class="op">$</span>NEE.m, aligned_dat<span class="op">$</span>NEE.o)
<span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)  ## intercept=0, slope=1</code></pre>
<p><strong>Fifth</strong>, <em>calculate the Root Mean Square Error (RMSE)</em> between the model and the data</p>
<pre class="sourceCode r"><code class="sourceCode r">rmse =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>((aligned_dat<span class="op">$</span>NEE.m<span class="op">-</span>aligned_dat<span class="op">$</span>NEE.o)<span class="op">^</span><span class="dv">2</span>,<span class="dt">na.rm =</span> <span class="ot">TRUE</span>))</code></pre>
<p><em>na.rm</em> makes sure we don’t include missing or screened values in either time series.</p>
<p><strong>Finally</strong>, <em>plot time-series</em> of both the model and data together</p>
<pre class="sourceCode r"><code class="sourceCode r">## plot aligned data
<span class="kw">plot</span>(aligned_dat<span class="op">$</span>posix, aligned_dat<span class="op">$</span>NEE.o, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>)
<span class="kw">lines</span>(aligned_dat<span class="op">$</span>posix,aligned_dat<span class="op">$</span>NEE.m, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</code></pre>
<p><strong>Bonus</strong> <em>How would you compare aggregated data?</em></p>
<p>Try RMSE against monthly NEE instead of half-hourly. In this case, first average the values up to monthly in the observations. Then, use align_data to match the monthly timestep in model output.</p>
<p><strong>NOTE</strong>: Align_data uses two seperate alignment function, match_timestep and mean_over_larger_timestep. Match_timestep will use only that data that is present in both the model and the observation. This is helpful for sparse observations. Mean_over_larger_timestep aggregates the values over the largest timestep present. If you were to look at averaged monthly data, you would use mean_over_larger_timestep.</p>
<pre class="sourceCode r"><code class="sourceCode r">monthlyNEEobs&lt;-<span class="kw">aggregate</span>(observations, <span class="dt">by=</span> <span class="kw">list</span>(<span class="kw">month</span>(observations<span class="op">$</span>posix)), <span class="dt">simplify=</span><span class="ot">TRUE</span>, <span class="dt">FUN =</span>mean, <span class="dt">na.rm=</span> <span class="ot">TRUE</span>)
plottable&lt;-<span class="kw">align_data</span>(<span class="dt">model.calc =</span> model, <span class="dt">obvs.calc =</span> monthlyNEEobs, <span class="dt">align_method =</span> <span class="st">&quot;mean_over_larger_timestep&quot;</span>, <span class="dt">var=</span> <span class="st">&quot;NEE&quot;</span>)
<span class="kw">head</span>(plottable)</code></pre>

</div>
</div>
<div id="data-assimilation-concepts" class="section level3">
<h3><span class="header-section-number">5.5.2</span> Data Assimilation Concepts</h3>
<p>The goal of this tutorial is to help you gain some hands-on familiarity with some of the concepts, tools, and techniques involved in Bayesian Calibration. As a warm-up to more advanced approaches to model-data fusion involving full ecosystem models, this example will focus on fitting the Farquhar, von Caemmerer, and Berry (1980) photosynthesis model [FvCB model] to leaf-level photosynthetic data. This is a simple, nonlinear model consisting of 3 equations that models net carbon assimilation, <span class="math inline">\(A^{(m)}\)</span>, at the scale of an individual leaf as a function of light and CO2.</p>
<p><span class="math display">\[A_j = \frac{\alpha Q}{\sqrt{1+(\alpha^2 Q^2)/(Jmax^2)}} \frac{C_i- \Gamma}{4 C_i + 8 \Gamma}\]</span></p>
<p><span class="math display">\[A_c = V_{cmax} \frac{C_i - \Gamma}{C_i+ K_C (1+[O]/K_O) }\]</span></p>
<p><span class="math display">\[A^{(m)} = min(A_j,A_c) - r\]</span></p>
<p>The first equation <span class="math inline">\(A_j\)</span> describes the RUBP-regeneration limited case. In this equation the first fraction is a nonrectangular hyperbola predicting <span class="math inline">\(J\)</span>, the electron transport rate, as a function of incident light <span class="math inline">\(Q\)</span>, quantum yield <span class="math inline">\(\alpha\)</span>, and the assymptotic saturation of <span class="math inline">\(J\)</span> at high light <span class="math inline">\(J_{max}\)</span>. The second equation, <span class="math inline">\(A_c\)</span>, describes the Rubisco limited case. The third equation says that the overall net assimilation is determined by whichever of the two above cases is limiting, minus the leaf respiration rate, <span class="math inline">\(r\)</span>.</p>
<p>To keep things simple, as a Data Model (a.k.a. Likelihood or Cost Function) we’ll assume that the observed leaf-level assimilation <span class="math inline">\(A^{(o)}\)</span> is Normally distributed around the model predictions with observation error <span class="math inline">\(\tau\)</span>.</p>
<p><span class="math display">\[A^{(o)} \sim N(A^{(m)},\tau)\]</span></p>
<p>To fit this model to data we’re going to rely on a piece of statistical software known as JAGS. The above model would be written in JAGS as:</p>
<pre><code>model{

## Priors
  Jmax ~ dlnorm(4.7,2.7)             ## maximum electron transport rate prior
  alpha~dnorm(0.25,100)              ##quantum yield  (mol electrons/mole photon) prior
  vmax ~dlnorm(4.6,2.7)              ## maximum rubisco capacity prior

  r ~ dlnorm(0.75,1.56)              ## leaf respiration prior
  cp ~ dlnorm(1.9,2.7)               ## CO2 compensation point prior
  tau ~ dgamma(0.1,0.1)

  for(i in 1:n){

     ## electron transport limited
     Aj[i]&lt;-(alpha*q[i]/(sqrt(1+(alpha*alpha*q[i]*q[i])/(Jmax*Jmax))))*(pi[i]-cp)/(4*pi[i]+8*cp)    

     ## maximum rubisco limited without covariates
     Ac[i]&lt;- vmax*(pi[i]-cp)/(pi[i]+Kc*(1+po/Ko))                                                    

     Am[i]&lt;-min(Aj[i], Ac[i]) - r      ## predicted net photosynthesis
     Ao[i]~dnorm(Am[i],tau)            ## likelihood
     }

}</code></pre>
<p>The first chunk of code defines the <em>prior</em> probability distributions. In Bayesian inference every unknown parameter that needs to be estimated is required to have a prior distribution. Priors are the expression of our belief about what values a parameter might take on <strong>prior to observing the data</strong>. They can arise from many sources of information (literature survey, meta-analysis, expert opinion, etc.) provided that they do not make use of the data that is being used to fit the model. In this particular case, the priors were defined by Feng and Dietze 2013. Most priors are lognormal or gamma, which were choosen because most of these parameters need to be positive.</p>
<p>After the priors is the Data Model, which in JAGS needs to be implemented as a loop over every observation. This is simply a codified version of the earlier equations.</p>
<p>Table 1: FvCB model parameters in the statistical code, their symbols in equations, and definitions</p>
<table>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>alpha0</td>
<td><span class="math inline">\(\alpha\)</span></td>
<td>quantum yield (mol electrons/mole photon)</td>
</tr>
<tr class="even">
<td>Jmax</td>
<td><span class="math inline">\(J_{max}\)</span></td>
<td>maximum electron transport</td>
</tr>
<tr class="odd">
<td>cp</td>
<td><span class="math inline">\(\Gamma\)</span></td>
<td>CO2 compensation point</td>
</tr>
<tr class="even">
<td>vmax0</td>
<td><span class="math inline">\(V_{cmax}\)</span></td>
<td>maximum Rubisco capacity (a.k.a Vcmax)</td>
</tr>
<tr class="odd">
<td>r</td>
<td><span class="math inline">\(R_d\)</span></td>
<td>leaf respiration</td>
</tr>
<tr class="even">
<td>tau</td>
<td><span class="math inline">\(\tau\)</span></td>
<td>residual precision</td>
</tr>
<tr class="odd">
<td>q</td>
<td><span class="math inline">\(Q\)</span></td>
<td>PAR</td>
</tr>
<tr class="even">
<td>pi</td>
<td><span class="math inline">\(C_i\)</span></td>
<td>CO2 concentration</td>
</tr>
</tbody>
</table>
<div id="fitting-the-model" class="section level4">
<h4><span class="header-section-number">5.5.2.1</span> Fitting the model</h4>
<p>To begin with we’ll load up an example A-Ci and A-Q curve that was collected during the 2012 edition of the <a href="http://www.fluxcourse.org/">Flux Course</a> at Niwot Ridge. The exact syntax below may be a bit confusing to those unaccustomed to R, but the essence is that the <code>filenames</code> line is looking up where the example data is stored in the PEcAn.photosynthesis package and the <code>dat</code> line is loading up two files (once A-Ci, the other A-Q) and concatanating them together.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PEcAn.photosynthesis)

### Load built in data
filenames &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="kw">paste0</span>(<span class="st">&quot;flux-course-3&quot;</span>,<span class="kw">c</span>(<span class="st">&quot;aci&quot;</span>,<span class="st">&quot;aq&quot;</span>)), <span class="dt">package =</span> <span class="st">&quot;PEcAn.photosynthesis&quot;</span>)
dat&lt;-<span class="kw">do.call</span>(<span class="st">&quot;rbind&quot;</span>, <span class="kw">lapply</span>(filenames, read_Licor))

## Simple plots
aci =<span class="st"> </span><span class="kw">as.character</span>(dat<span class="op">$</span>fname) <span class="op">==</span><span class="st"> </span><span class="kw">basename</span>(filenames[<span class="dv">1</span>])
<span class="kw">plot</span>(dat<span class="op">$</span>Ci[aci],dat<span class="op">$</span>Photo[aci],<span class="dt">main=</span><span class="st">&quot;ACi&quot;</span>)
<span class="kw">plot</span>(dat<span class="op">$</span>PARi[<span class="op">!</span>aci],dat<span class="op">$</span>Photo[<span class="op">!</span>aci],<span class="dt">main=</span><span class="st">&quot;AQ&quot;</span>)</code></pre>
<p>In PEcAn we’ve written a wrapper function, <span class="math inline">\(fitA\)</span>, around the statistical model discussed above, which has a number of other bells and whistles discussed in the <a href="https://github.com/PecanProject/pecan/blob/master/modules/photosynthesis/vignettes/ResponseCurves.Rmd">PEcAn Photosynthesis Vignette</a>. For today we’ll just use the most basic version, which takes as arguments the data and the number of MCMC iterations we want to run.</p>
<pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw">fitA</span>(dat,<span class="dt">model=</span><span class="kw">list</span>(<span class="dt">n.iter=</span><span class="dv">10000</span>))</code></pre>
</div>
<div id="whats-going-on" class="section level4">
<h4><span class="header-section-number">5.5.2.2</span> What’s going on</h4>
<p>Bayesian numerical methods for model calibration are based on sampling parameter values from the posterior distribution. Fundamentally what’s returned is a matrix, with the number of iterations as rows and the number of parameters as columns, which are samples from the posterior distribution, from which we can approximate any quantity of interest (mean, median, variance, CI, etc.).</p>
<p>The following plots follow the trajectory of two correlated parameters, Jmax and alpha. In the first figure, arrows show the first 10 iterations. Internally JAGS is choosing between a variety of different Bayesian sampling methods (e.g. Metropolis-Hasting, Gibbs sampling, slice sampling, rejection sampling, etc) to draw a new value for each parameter conditional on the current value. After just 10 steps we don’t have a good picture of the overall posterior, but it should still be clear that the sampling is not a complete random walk.</p>
<pre class="sourceCode r"><code class="sourceCode r">params &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(fit<span class="op">$</span>params)
xrng =<span class="st"> </span><span class="kw">range</span>(fit<span class="op">$</span>params[,<span class="st">&quot;alpha0&quot;</span>])
yrng =<span class="st"> </span><span class="kw">range</span>(fit<span class="op">$</span>params[,<span class="st">&quot;Jmax0&quot;</span>])

n =<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">10</span>
<span class="kw">plot</span>(params[n,<span class="st">&quot;alpha0&quot;</span>],params[n,<span class="st">&quot;Jmax0&quot;</span>],<span class="dt">type=</span><span class="st">&#39;n&#39;</span>,<span class="dt">xlim=</span>xrng,<span class="dt">ylim=</span>yrng)
<span class="kw">arrows</span>(params[n[<span class="op">-</span><span class="dv">10</span>],<span class="st">&quot;alpha0&quot;</span>],params[n[<span class="op">-</span><span class="dv">10</span>],<span class="st">&quot;Jmax0&quot;</span>],params[n[<span class="op">-</span><span class="dv">1</span>],<span class="st">&quot;alpha0&quot;</span>],params[n[<span class="op">-</span><span class="dv">1</span>],<span class="st">&quot;Jmax0&quot;</span>],<span class="dt">length=</span><span class="fl">0.125</span>,<span class="dt">lwd=</span><span class="fl">1.1</span>)</code></pre>
<p>After 100 steps, we can see a cloud start to form, with occassional wanderings around the periphery.</p>
<pre class="sourceCode r"><code class="sourceCode r">n =<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">100</span>
<span class="kw">plot</span>(params[n,<span class="st">&quot;alpha0&quot;</span>],params[n,<span class="st">&quot;Jmax0&quot;</span>],<span class="dt">type=</span><span class="st">&#39;l&#39;</span>,<span class="dt">xlim=</span>xrng,<span class="dt">ylim=</span>yrng)</code></pre>
<p>After <span class="math inline">\(nrow(params)\)</span> steps what we see is a point cloud of samples from the joint posterior distribution. When viewed sequentially, points are not independent, but we are interested in working with the overall distribution, where the order of samples is not important.</p>
<pre class="sourceCode r"><code class="sourceCode r">n =<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(params)
<span class="kw">plot</span>(params[n,<span class="st">&quot;alpha0&quot;</span>],params[n,<span class="st">&quot;Jmax0&quot;</span>],<span class="dt">type=</span><span class="st">&#39;p&#39;</span>,<span class="dt">pch=</span><span class="st">&quot;+&quot;</span>,<span class="dt">cex=</span><span class="fl">0.5</span>,<span class="dt">xlim=</span>xrng,<span class="dt">ylim=</span>yrng)</code></pre>
</div>
<div id="evaluating-the-model-output" class="section level4">
<h4><span class="header-section-number">5.5.2.3</span> Evaluating the model output</h4>
<p>A really important aspect of Bayesian inference is that the output is the <strong>joint</strong> posterior probability of all the parameters. This is very different from an optimization approach, which tries to find a single best parameter value. It is also different from estimating the independent posterior probabilities of each parameter – Bayesian posteriors frequently have strong correlation among parameters for reasons having to do both with model structure and the underlying data.</p>
<p>The model we’re fitting has six free parameters, and therefore the output matrix has 6 columns, of which we’ve only looked at two. Unfortunately it is impossible to visualize a 6 dimensional parameter space on a two dimensional screen, so a very common practice (for models with a small to medium number of parameters) is to look at all pairwise scatterplots. If parameters are uncorrelated we will typically see oval shaped clouds that are oriented in the same directions as the axes. For parameters with linear correlations those clouds will be along a diagonal. For parameters with nonlinear trade-offs the shapes of the parameter clouds can be more complex, such as the banana-shaped or triangular. For the FvCB model we see very few parameters that are uncorrelated or have simple linear correlations, a fact that we should keep in mind when interpreting individual parameters.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pairs</span>(params,<span class="dt">pch=</span><span class="st">&quot;.&quot;</span>)</code></pre>
<p>The three most common outputs that are performed on almost all Bayesian analyses are to look at the MCMC chains themselves, the marginal distributions of each parameter, and the overall summary statistics.</p>
<p>The ‘trace’ diagrams below show the history of individual parameters during the MCMC sampling. There are different color lines that represent the fact that JAGS ran the MCMC multiple times, with each run (i.e. each color) being refered to as a different <span class="math inline">\(chain\)</span>. It is common to run multiple chains in order to assess whether the model, started from different points, consistently converges on the same answer. The ideal trace plot looks like white noise with all chains in agreement.</p>
<p>The ‘density’ figures represent smoothed versions of the <em>marginal</em> distributions of each parameter. The tick marks on the x-axis are the actual samples. You will note that some posteriors will look approximately Normal, while others may be skewed or have clearly defined boundaries. On occassion there will even be posteriors that are multimodal. There is no assumption built into Bayesian statistics that the posteriors need be Normal, so as long as an MCMC has converged this diversity of shapes is valid. [note: the most common cause of multi-modal posteriors is a lack of convergence]</p>
<p>Finally, the summary table reports, for each parameter, a mean, standard deviation, two variants of standard error, and standard quantile estimates (95% CI, interquartile, and median). The standard deviation of the posterior is a good summary statistic about <strong>how uncertain we are about a parameter</strong>. The Naive SE is the traditonal <span class="math inline">\(\frac{SD}{\sqrt{n}}\)</span>, which is an estimate of the <strong>NUMERICAL accuracy in our estimate of the mean</strong>. As we run the MCMC longer (i.e. take more samples), we get an answer that is numerically more precise (SE converges to 0) but the uncertainty in the parameter (i.e. SD) stays the same because that’s determined by the sample size of the DATA not the length of the MCMC. Finally, the Time-series SE is a variant of the SE calculation that accounts for the autocorrelation in the MCMC samples. In practice is is therefore more appropriate to use this term to assess numerical accuracy.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(fit<span class="op">$</span>params,<span class="dt">auto.layout =</span> <span class="ot">FALSE</span>)    ## MCMC diagnostic plots
<span class="kw">summary</span>(fit<span class="op">$</span>params) ## parameter estimates  </code></pre>
<p>Assessing the convergence of the MCMC is first done visually, but more generally the use of statistical diagnostics to assess convergence is highly encouraged. There are a number of metrics in the literature, but the most common is the Gelman-Brooks-Rubin statistic, which compare the variance within each chain to the variance across chains. If the chains have converged then this quantity should be 1. Values less than 1.05 are typically considered sufficient by most statisticians, but these are just rules-of-thumb.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gelman.plot</span>(fit<span class="op">$</span>params,<span class="dt">auto.layout =</span> <span class="ot">FALSE</span>)
<span class="kw">gelman.diag</span>(fit<span class="op">$</span>params)</code></pre>
<p>As with any modeling, whether statistical or process-based, another common diagnostic is a predicted vs observed plot. In a perfect model the data would fall along the 1:1 line. The deviations away from this line are the model residuals. If observations lie along a line other than the 1:1 this indicates that the model is biased in some way. This bias is often assessed by fitting a linear regression to the points, though two important things are noteworthy about this practice. First, the <span class="math inline">\(R^2\)</span> and residual error of this regression are not the appropriate statistics to use to assess model performance (though you will frequently find them reported incorrectly in the literature). The correct <span class="math inline">\(R^2\)</span> and residual error (a.k.a Root Mean Square Error, RMSE) are based on deviations from the 1:1 line, not the regression. The code below shows these two terms calculated by hand. The second thing to note about the regression line is that the standard regression F-test, which assesses deviations from 0, is not the test you are actually interested in, which is whether the line differs from 1:1. Therefore, while the test on the intercept is correct, as this value should be 0 in an unbiased model, the test statistic on the slope is typically of less interest (unless your question really is about whether the model is doing better than random). However, this form of bias can easily be assessed by looking to see if the CI for the slope overlaps with 1.</p>
<pre class="sourceCode r"><code class="sourceCode r">## predicted vs observed plot
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))
mstats =<span class="st"> </span><span class="kw">summary</span>(fit<span class="op">$</span>predict)
pmean =<span class="st"> </span>mstats<span class="op">$</span>statistics[<span class="kw">grep</span>(<span class="st">&quot;pmean&quot;</span>,<span class="kw">rownames</span>(mstats<span class="op">$</span>statistics)),<span class="dv">1</span>]
<span class="kw">plot</span>(pmean,dat<span class="op">$</span>Photo,<span class="dt">pch=</span><span class="st">&quot;+&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;Predicted A&quot;</span>,<span class="dt">ylab =</span> <span class="st">&quot;Observed A&quot;</span>)
<span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">col=</span><span class="dv">2</span>,<span class="dt">lwd=</span><span class="dv">2</span>)
bias.fit =<span class="st"> </span><span class="kw">lm</span>(dat<span class="op">$</span>Photo<span class="op">~</span>pmean)
<span class="kw">abline</span>(bias.fit,<span class="dt">col=</span><span class="dv">3</span>,<span class="dt">lty=</span><span class="dv">2</span>,<span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>,<span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;1:1&quot;</span>,<span class="st">&quot;regression&quot;</span>),<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">col=</span><span class="dv">2</span><span class="op">:</span><span class="dv">3</span>,<span class="dt">lty=</span><span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)
<span class="kw">summary</span>(bias.fit)
RMSE =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>((pmean<span class="op">-</span>dat<span class="op">$</span>Photo)<span class="op">^</span><span class="dv">2</span>))
RMSE
R2 =<span class="st"> </span><span class="dv">1</span><span class="op">-</span>RMSE<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="kw">var</span>(dat<span class="op">$</span>Photo)
R2
<span class="kw">confint</span>(bias.fit)</code></pre>
<p>In the final set of plots we look at the actual A-Ci and A-Q curves themselves. Here we’ve added two interval estimates around the curves. The CI captures the uncertainty in the <em>parameters</em> and will asympotically shrink with more and more data. The PI (predictive interval) includes the parameter and residual error. If our fit is good then 95% PI should thus encompass at least 95% of the observations. That said, as with any statistical model we want to look for systematic deviations in the residuals from either the mean or the range of the PI.</p>
<pre class="sourceCode r"><code class="sourceCode r">## Response curve
<span class="kw">plot_photo</span>(dat,fit)</code></pre>
<p>Note: on the last figure you will get warnings about “No ACi” and “No AQ” which can be ignored. These are occuring because the file that had the ACi curve didn’t have an AQ curve, and the file that had the AQ curve didn’t have an ACi curve.</p>
</div>
<div id="additional-information" class="section level4">
<h4><span class="header-section-number">5.5.2.4</span> Additional information</h4>
<p>There is a more detailed R Vignette on the use of the PEcAn photosynthesis module available in the <a href="https://github.com/PecanProject/pecan/blob/master/modules/photosynthesis/vignettes/ResponseCurves.Rmd">PEcAn Repository</a>.</p>
</div>
<div id="citations" class="section level4">
<h4><span class="header-section-number">5.5.2.5</span> Citations</h4>
<p>Dietze, M.C. (2014). Gaps in knowledge and data driving uncertainty in models of photosynthesis. Photosynth. Res., 19, 3–14.</p>
<p>Farquhar, G., Caemmerer, S. &amp; Berry, J.A. (1980). A biochemical model of photosynthetic CO2 assimilation in leaves of C3 species. Planta, 149, 78–90.</p>
<p>Feng, X. &amp; Dietze, M.C. (2013). Scale dependence in the effects of leaf ecophysiological traits on photosynthesis: Bayesian parameterization of photosynthesis models. New Phytol., 200, 1132–1144.</p>

</div>
</div>
<div id="parameter-data-assimilation" class="section level3">
<h3><span class="header-section-number">5.5.3</span> Parameter Data Assimilation</h3>
<div id="objectives" class="section level4">
<h4><span class="header-section-number">5.5.3.1</span> Objectives</h4>
<ul>
<li>Gain hands-on experience in using Bayesian MCMC techniques to calibrate a simple ecosystem model using parameter data assimilation (PDA)</li>
<li>Set up and run a PDA in PEcAn using model emulation technique, assimilating NEE data from Niwot Ridge</li>
<li>Examine outputs from a PDA for the SIPNET model and evaluation of the calibrated model against i) data used to constrain model, ii) additional data for the same site</li>
</ul>
</div>
<div id="larger-context" class="section level4">
<h4><span class="header-section-number">5.5.3.2</span> Larger Context</h4>
<p>Parameter data assimilation (PDA) occurs as one step in the larger process of model calibration, validation, and application. The goal of PDA is to update our estimates of the posterior distributions of the model parameters using data that correspond to model outputs. This differs from our previous use of PEcAn to constrain a simple model using data that map directly to the model parameters. Briefly, the recommended overall approach for model calibration and validation consists of the following steps:</p>
<ol style="list-style-type: decimal">
<li>Assemble and process data sets required by the model as drivers</li>
<li>Perform an initial test-run of the model as a basic sanity check</li>
</ol>
<ul>
<li>Were there errors in drivers? (return to 1)</li>
<li>Is the model in the same ballpark as the data?</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Construct priors for model parameters</li>
<li>Collect/assemble the data that can be used to constrain model parameters and outputs</li>
<li>Meta-analysis</li>
<li>Sensitivity analysis (SA)</li>
<li>Variance Decomposition (VD)</li>
<li>Determine what parameters need further constraint</li>
</ol>
<ul>
<li>Does this data exist in the literature? (repeat 4-8)</li>
<li>Can I collect this data in the field? (repeat 4-8)</li>
</ul>
<ol start="9" style="list-style-type: decimal">
<li>Ensemble Analysis</li>
</ol>
<ul>
<li>Is reality within the range of the uncertainty in the model?</li>
</ul>
<ol start="10" style="list-style-type: decimal">
<li>Evaluate/estimate uncertainties in the data</li>
<li>Parameter Data Assimilation:</li>
</ol>
<ul>
<li>Propose new parameter values</li>
<li>Evaluate L(data | param) &amp; prior(param)</li>
<li>Accept or reject the proposed parameter values</li>
<li>Repeat many times until a histogram of accepted parameter values approximates the true posterior distribution.<br />
</li>
</ul>
<ol start="12" style="list-style-type: decimal">
<li>Model evaluation [preferably ensemble based]</li>
</ol>
<ul>
<li>Against data used to constrain model</li>
<li>Against additional data for this site
<ul>
<li>Same variable, different time</li>
<li>Different variables</li>
</ul></li>
<li>Against data at a new site</li>
<li>Do I need more data? Repeat 4-9 (direct data constraint) or 6-11 (parameter data assimilation).</li>
</ul>
<ol start="13" style="list-style-type: decimal">
<li>Application [preferably ensemble forecast or hindcast]</li>
</ol>
</div>
<div id="connect-to-rstudio" class="section level4">
<h4><span class="header-section-number">5.5.3.3</span> Connect to Rstudio</h4>
<p>Today, we’re again going to work mostly in Rstudio, in order to easily edit advanced PEcAn settings and browse files. So if you haven’t already, connect now to the Rstudio server on your VM ([URL]/rstudio).</p>
<p>This tutorial assumes you have successfully completed an ensemble and a sensitivity analysis (Demo 2) before.</p>
</div>
<div id="defining-variables" class="section level4">
<h4><span class="header-section-number">5.5.3.4</span> Defining variables</h4>
<p>The following variables need to be set specific to the site being run and the workflow being run</p>
<pre class="sourceCode r"><code class="sourceCode r">workflow_id &lt;-<span class="st"> </span><span class="dv">99000000002</span>  ## comes from the History table, your successful ensemble run&#39;s workflow ID

## from URL/bety/inputs.  
##   Search by Ameriflux ID (e.g. US-NR1)
##   Find the &quot;plain&quot; site record (no CF or model name) that&#39;s on your server 
##    (probably last in the list)
##   Click on the magnifying glass icon then look under &quot;View Related Files&quot;
datadir     &lt;-<span class="st"> &quot;/home/carya/output/dbfiles/AmerifluxLBL_site_0-772/&quot;</span> 

## where PEcAn is saving output (default OK on VM)
outdir      &lt;-<span class="st"> &quot;/home/carya/output/&quot;</span> </code></pre>
</div>
<div id="initial-ensemble-analysis" class="section level4">
<h4><span class="header-section-number">5.5.3.5</span> Initial Ensemble Analysis</h4>
<p>A good place to start when thinking about a new PDA analysis is to look at the current model fit to observed data. In fact, we want to compare data to a full ensemble prediction from the model. This is important because our current parameter distributions will be the priors for PDA. While the analysis will translate these priors into more optimal (in terms of producing model output that matches observations) and more confident (i.e. narrower) posterior distributions, these results are inherently constrained by the current parameter distributions. Thus, if reality falls far outside the prior ensemble confidence interval (which reflects the current uncertainty of all model parameters), data assimilation will not be able to fix this. In such cases, the prior parameter estimates must already be over-constrained, or there are structural errors in the model itself that need fixing.
To begin, let’s load up some NEE observations so that we can plot them along with our ensemble predictions. In the code below the elements in bold may vary depending on site and your previous runs.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PEcAn.all)

<span class="co"># read settings</span>
settings &lt;-<span class="st"> </span><span class="kw">read.settings</span>(<span class="kw">file.path</span>(outdir,<span class="kw">paste0</span>(<span class="st">&quot;PEcAn_&quot;</span>,workflow_id),<span class="st">&quot;pecan.CONFIGS.xml&quot;</span>))

<span class="co"># open up a DB connection</span>
bety&lt;-settings<span class="op">$</span>database<span class="op">$</span>bety
bety &lt;-dplyr<span class="op">::</span><span class="kw">src_postgres</span>(<span class="dt">host =</span> bety<span class="op">$</span>host, <span class="dt">user =</span> bety<span class="op">$</span>user, <span class="dt">password =</span> bety<span class="op">$</span>password, <span class="dt">dbname =</span> bety<span class="op">$</span>dbname)

<span class="co"># Fill out the arguments needed by load_data function</span>

<span class="co"># read file format information</span>
format     &lt;-<span class="st"> </span>PEcAn.DB<span class="op">::</span><span class="kw">query.format.vars</span>(<span class="dt">bety =</span> bety, <span class="dt">format.id =</span> <span class="dv">5000000002</span>)
start_year &lt;-<span class="st"> </span>lubridate<span class="op">::</span><span class="kw">year</span>(settings<span class="op">$</span>run<span class="op">$</span>start.date)
end_year   &lt;-<span class="st"> </span>lubridate<span class="op">::</span><span class="kw">year</span>(settings<span class="op">$</span>run<span class="op">$</span>end.date)
vars.used.index &lt;-<span class="st"> </span><span class="kw">which</span>(format<span class="op">$</span>vars<span class="op">$</span>bety_name <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;NEE&quot;</span>, <span class="st">&quot;UST&quot;</span>))

obs &lt;-PEcAn.benchmark<span class="op">::</span><span class="kw">load_data</span>(<span class="dt">data.path =</span> <span class="kw">file.path</span>(datadir, <span class="st">&quot;AMF_US-NR1_BASE_HH_9-1.csv&quot;</span>), 
                                 <span class="dt">format =</span> format, <span class="dt">start_year =</span> start_year,  <span class="dt">end_year =</span> end_year,
                                  <span class="dt">site =</span> settings<span class="op">$</span>run<span class="op">$</span>site, 
                                  <span class="dt">vars.used.index =</span> vars.used.index,
                                  <span class="dt">time.row =</span> format<span class="op">$</span>time.row)

obs<span class="op">$</span>NEE[obs<span class="op">$</span>UST<span class="op">&lt;</span><span class="fl">0.4</span>] &lt;-<span class="st"> </span><span class="ot">NA</span>  ## U* filter
NEEo &lt;-<span class="st"> </span>obs<span class="op">$</span>NEE</code></pre>
<p>Now let’s load up our ensemble outputs from the previous ensemble analysis (Demo 2) and plot our ensemble predictions against our NEE observations.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load outputs, try not to delete prePDA ensemble output filename from your environment</span>
prePDA_ensemble_output_file &lt;-<span class="st"> </span><span class="kw">file.path</span>(outdir,<span class="kw">paste0</span>(<span class="st">&quot;PEcAn_&quot;</span>,workflow_id, <span class="st">&quot;/ensemble.ts.&quot;</span>, settings<span class="op">$</span>ensemble<span class="op">$</span>ensemble.id, <span class="st">&quot;.NEE.2003.2006.Rdata&quot;</span>))
<span class="kw">load</span>(prePDA_ensemble_output_file)

<span class="co"># calculate CI</span>
pre_pda_ens &lt;-<span class="st"> </span>ensemble.ts[[<span class="st">&quot;NEE&quot;</span>]]
preCI &lt;-<span class="st"> </span><span class="kw">apply</span>(pre_pda_ens, <span class="dv">2</span>, quantile, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.5</span>, <span class="fl">0.975</span>), <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)

<span class="co"># plot model ensemble</span>
ymin &lt;-<span class="st"> </span><span class="kw">min</span>(<span class="kw">min</span>(<span class="kw">c</span>(preCI, NEEo), <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))
ymax &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw">max</span>(<span class="kw">c</span>(preCI, NEEo), <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))
<span class="kw">plot</span>(preCI[<span class="dv">2</span>,], <span class="dt">ylim =</span> <span class="kw">c</span>(ymin, ymax), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">xlab =</span> <span class="st">&quot;time&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;NEE&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;pre-PDA model ensemble vs data&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;n&quot;</span>)
prepoly &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(preCI)[<span class="dv">2</span>]
<span class="kw">polygon</span>(<span class="kw">c</span>(prepoly, <span class="kw">rev</span>(prepoly)), <span class="kw">c</span>(preCI[<span class="dv">3</span>,], <span class="kw">rev</span>(preCI[<span class="dv">1</span>,])), <span class="dt">col=</span><span class="st">&#39;khaki&#39;</span>, <span class="dt">border=</span><span class="ot">NA</span>)

<span class="co"># add data</span>
<span class="kw">points</span>(NEEo, <span class="dt">pch =</span> <span class="st">&quot;.&quot;</span>, <span class="dt">col=</span> <span class="kw">adjustcolor</span>(<span class="st">&quot;purple&quot;</span>,<span class="dt">alpha.f=</span><span class="fl">0.5</span>))
<span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;Data&quot;</span>,<span class="st">&quot;Pre-PDA Model&quot;</span>), <span class="dt">pch=</span><span class="kw">c</span>(<span class="dv">15</span>,<span class="dv">15</span>),
        <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;purple&quot;</span>,<span class="st">&quot;khaki&quot;</span>))</code></pre>
<p>When interpreting your results it is important to remember the difference between a confidence interval, which just includes parameter uncertainties, and a predictive interval, which includes parameter and residual uncertainties. Your ensemble analysis plot illustrates the former—i.e., the confidence in the mean NEE. By contrast, the data reflect both changes in mean NEE, and random variability. As such, we can’t expect all the data to fall within the CI; in fact, if we had unlimited data to constrain mean NEE, the CI would collapse to a single line and none of the data would be contained! However, your plot will give you an idea of how much uncertainty there is in your model currently, and help to identify systematic errors like bias (values consistently too high or low) or poorly represented seasonal patterns.</p>
</div>
<div id="questions" class="section level4">
<h4><span class="header-section-number">5.5.3.6</span> Questions:</h4>
<ul>
<li>Does your ensemble agree well with the data?</li>
<li>If so, how much room for improvement is there, in terms of tightening the CI?</li>
<li>If not, what are the greatest discrepancies?</li>
<li>What are some of the problems (with model, data, and/or PEcAn) that might explain the data-model disparity you see?</li>
</ul>
</div>
<div id="choosing-parameters" class="section level4">
<h4><span class="header-section-number">5.5.3.7</span> Choosing Parameters</h4>
<p>Beyond exploratory exercises, the first step of PDA analysis is to choose the model parameters you will target for optimization. PDA is computationally expensive (even when using an emulator), and the cost increases exponentially with the number of parameters targeted. The number you can handle in any given analysis completely depends on the complexity of the model and your available computational resources, but in practice it’s going to be rather small (~1–10) relative to the large number of parameters in a mechanistic ecosystem model (~10–100).
Given this limitation, it is important to target parameters that can contribute substantially to improving model fit. If you recall, identifying those parameters was the goal of the uncertainty analysis you conducted previously, in the second PEcAn demo. Let’s revisit that analysis now. Open your variance decomposition graph from Demo 2
From this figure decide which variables you will target with PDA. As noted, an obvious criterion is that the parameter should be contributing a large amount of uncertainty to the current model, because otherwise it simply can’t change the model output much no matter how much you try to optimize it. But there are other considerations too. For example, if two parameters have similar or competing roles in the model, you may have trouble optimizing both simultaneously. In practice, there will likely be some guess-and-testing involved, though a good understanding of how the model works will help. It may also help to look at the shape of the Sensitivity responses and details of model fit to data (your ensemble analysis from the previous section).
For the purposes of this demo, choose eight to ten parameters (in total, if you have more than one PFT) that contribute high uncertainty to model output and/or seem like good choices for some other rational reason.</p>
</div>
<div id="questions-1" class="section level4">
<h4><span class="header-section-number">5.5.3.8</span> Questions:</h4>
<ul>
<li>Which parameters did you choose, and why?</li>
</ul>
</div>
<div id="editing-pecan-settings" class="section level4">
<h4><span class="header-section-number">5.5.3.9</span> Editing PEcAn settings</h4>
<p>Now let’s add settings to tell PEcAn how to run the PDA with emulator, we will come to the details of model emulation later. Open up the pecan.CONFIGS.xml file you located previously, and choose <code>File &gt; Save as...</code> from the menu to save a new copy as <strong>pecan.PDA.xml</strong>. Now add the block of XML listed below to the file, immediately after the <pecan> line. Check and fill in the parts corresponding to your run when necessary.
In this block, use the <code>&lt;param.names&gt;&lt;param&gt;</code> tags to identify the parameters you’ve chosen for PDA (it’s up to you to choose the number of parameters you want to constrain, then you can set the <code>&lt;n.knot&gt;</code> to be &gt;= 10 per parameter you choose, e.g. 200 knots for 10 parameters). Here, you need to use PEcAn’s standard parameter names, which are generally not the same as what’s printed on your variance decomposition graph. To find your parameters look at the row names in the <code>prior.distns.csv</code> file for each PFT under the PFT pulldown menu. Insert the variable name (exactly, and case sensitive) into the <code>&lt;param&gt;</code> tags of the XML code below.
In addition, you may need to edit <code>&lt;inputs&gt;&lt;file&gt;&lt;path&gt;</code>, depending on the site and year you ran previously. The rest of the settings control options for the PDA analysis (how long to run, etc.), and also identify the data to be used for assimilation. For more details, see the assim.batch vignette on the PEcAn GitHub page (<a href="https://goo.gl/9hYVPQ" class="uri">https://goo.gl/9hYVPQ</a>).</p>
<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;    &lt;-- These lines are already in there. Don&#39;t duplicate them,   
&lt;pecan&gt;                  &lt;-- just paste the &lt;assim.batch&gt; block below right after them. 
  &lt;assim.batch&gt;
    &lt;method&gt;emulator&lt;/method&gt;
    &lt;n.knot&gt;160&lt;/n.knot&gt;                         &lt;-- FILL IN
    &lt;iter&gt;25000&lt;/iter&gt;
    &lt;chain&gt;3&lt;/chain&gt;
    &lt;param.names&gt;
      &lt;soil&gt;
        &lt;param&gt;YOUR_PFT_1_PARAM_1&lt;/param&gt;        &lt;-- FILL IN
        &lt;param&gt;YOUR_PFT_1_PARAM_2&lt;/param&gt;        &lt;-- FILL IN
      &lt;/soil&gt;
       &lt;temperate.coniferous&gt;                                      
         &lt;param&gt;YOUR_PFT_2_PARAM_1&lt;/param&gt;       &lt;-- FILL IN
         &lt;param&gt;YOUR_PFT_2_PARAM_2&lt;/param&gt;       &lt;-- FILL IN
         &lt;param&gt;YOUR_PFT_2_PARAM_3&lt;/param&gt;       &lt;-- FILL IN
         &lt;param&gt;YOUR_PFT_2_PARAM_4&lt;/param&gt;       &lt;-- FILL IN
         &lt;param&gt;YOUR_PFT_2_PARAM_5&lt;/param&gt;       &lt;-- FILL IN
         &lt;param&gt;YOUR_PFT_2_PARAM_6&lt;/param&gt;       &lt;-- FILL IN
       &lt;/temperate.coniferous&gt; 
    &lt;/param.names&gt;
    &lt;jump&gt;
        &lt;adapt&gt;100&lt;/adapt&gt;
        &lt;adj.min&gt;0.1&lt;/adj.min&gt;
        &lt;ar.target&gt;0.3&lt;/ar.target&gt;
    &lt;/jump&gt;
    &lt;inputs&gt;
     &lt;file&gt;
      &lt;path&gt;
         &lt;path&gt;/home/carya/output/dbfiles/AmerifluxLBL_site_0-772/AMF_US-NR1_BASE_HH_9-1.csv&lt;/path&gt;       
      &lt;/path&gt;
      &lt;format&gt;5000000002&lt;/format&gt;
      &lt;input.id&gt;1000011238&lt;/input.id&gt;        &lt;-- FILL IN, from BETY inputs table, this is *NOT* the workflow ID
      &lt;likelihood&gt;Laplace&lt;/likelihood&gt;
      &lt;variable.name&gt;
        &lt;variable.name&gt;NEE&lt;/variable.name&gt;
        &lt;variable.name&gt;UST&lt;/variable.name&gt;
      &lt;/variable.name&gt;
      &lt;variable.id&gt;297&lt;/variable.id&gt;
     &lt;/file&gt;
    &lt;/inputs&gt;
  &lt;/assim.batch&gt;</code></pre>
<p>Once you’ve made and saved the changes to your XML, load the file and check that it contains the new settings:</p>
<pre class="sourceCode r"><code class="sourceCode r">settings &lt;-<span class="st"> </span><span class="kw">read.settings</span>(<span class="kw">file.path</span>(outdir,<span class="kw">paste0</span>(<span class="st">&quot;PEcAn_&quot;</span>,workflow_id),<span class="st">&quot;pecan.PDA.xml&quot;</span>))
settings<span class="op">$</span>assim.batch</code></pre>
<p>If the printed list contains everything you just added to pecan.PDA.xml, you’re ready to proceed.</p>
</div>
<div id="investigating-pecan-function-pda.emulator-optional" class="section level4">
<h4><span class="header-section-number">5.5.3.10</span> Investigating PEcAn function pda.emulator (optional)</h4>
<p>Before we run the data assimilation, let’s take a high-level look at the organization of the code. Use the Rstudio file browser to open up <code>~/pecan/modules/assim.batch/R/pda.emulator.R.</code> This code works in much the same way as the pure statistical models that we learned about earlier in the week, except that the model being fit is a statistical model that emulates a complicated process-based computer simulation (i.e., an ecosystem model). We could have directly used the ecosystem model (indeed PEcAn’s other PDA functions perform MCMC by actually running the ecosystem model at each iteration, see pda.mcmc.R script as an example), however, this would require a lot more computational time than we have today. Instead here we will use a technique called model emulation. This technique allows us to run the model for a relatively smaller number of times with parameter values that have been carefully chosen to give a good coverage of parameter space. Then we can interpolate the likelihood calculated for each of those runs to get a surface that “emulates” the true likelihood and perform regular MCMC, except instead of actually running the model on every iteration to get a likelihood, this time we will just get an approximation from the likelihood emulator. The general algorithm of this method can be further expressed as:</p>
<ol style="list-style-type: decimal">
<li>Propose initial parameter set sampling design</li>
<li>Run full model for each parameter set</li>
<li>Evaluate the likelihoods</li>
<li>Construct emulator of multivariate likelihood surface</li>
<li>Use emulator to estimate posterior parameter distributions</li>
<li>(Optional) Refine emulator by proposing new design points, goto 2)</li>
</ol>
<p>For now, we just want you to get a glimpse at the overall structure of the code, which is laid out in the comment headers in <code>pda.emulator()</code>. Most of the real work gets done by the functions this code calls, which are all located in the file <code>~/pecan/modules/assim.batch/R/pda.utils.R</code> and the MCMC will be performed by the <code>mcmc.GP()</code> function in <code>~/pecan/modules/emulator/R/minimize.GP.R</code>. To delve deeper into how the code works, take a look at these files when you have the time.</p>
</div>
<div id="running-a-demo-pda" class="section level4">
<h4><span class="header-section-number">5.5.3.11</span> Running a demo PDA</h4>
<p>Now we can go ahead and run a data assimilation MCMC with emulator. Since you’ve already loaded the settings containing your modified &lt;assim.batch&gt; XML block, all you need to do to start the PDA is run <code>pda.emulator(settings)</code>. But, in the emulator workflow, there is a bit of a time consuming step where we calculate the effective sample size of the input data, and we have already done this step for you. You could load it up and pass it to the function explicitly in order to skip this step:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load input data</span>
<span class="kw">load</span>(<span class="st">&quot;/home/carya/pda/pda_externals.Rdata&quot;</span>)
postPDA.settings &lt;-<span class="st"> </span><span class="kw">pda.emulator</span>(settings, <span class="dt">external.data =</span> inputs_w_neff)</code></pre>
<p>After executing the code above, you will see print-outs to the console. The code begins with loading the prior values which in this case are the posterior distributions coming from your previous meta analysis. Then, normally, it loads the observational data and carries out necessary conversions and formatting to align it with model outputs, as we did separately above, but today it will skip this step as we are passing data externally. After this step, you will see a progress bar where the actual model is run n.knot times with the proposed parameter sets and then the outputs from these runs are read. Next, this model output is compared to the specified observational data, and the likelihood is calculated using the heteroskedastic Laplacian discussed previously. Once we calculate the likelihoods, we fit an emulator which interpolates the model output in parameter space between the points where the model has actually been run. Now we can put this emulator in the MCMC algorithm instead of the model itself. Within the MCMC loop the code proposes new parameter value from a multivariate normal jump distribution. The corresponding likelihood will be approximated by the emulator and the new parameter value is accepted or rejected based on its posterior probability relative to the current value.</p>
</div>
<div id="outputs-from-pecans-parameter-data-assimilation" class="section level4">
<h4><span class="header-section-number">5.5.3.12</span> Outputs from PEcAn’s Parameter Data Assimilation</h4>
<p>When the PDA is finished, a number of outputs are automatically produced that are either the same as or similar to posterior outputs that we’ve seen before. These are located in the <code>PEcAn_[workflow_id]/pft/*</code> output directory and are identified by <code>pda.[PFT]_[workflow_id]</code> in the filenames:</p>
<ul>
<li>posteriors.pda.[PFT]*.pdf shows the posterior distributions resulting from your PDA</li>
<li>trait.mcmc.pda.[PFT]*.Rdata contains all the parameter samples contained in the PDA posterior</li>
<li>mcmc.pda.[PFT]*.Rdata is essentially the same thing in a different format</li>
<li>mcmc.diagnostics.pda.[PFT]*.pdf shows trace plots and posterior densities for each assimilated parameter, as well as pairs plots showing all pairwise parameter correlations.</li>
</ul>
<p>Together, these files allow you to evaluate whether a completed PDA analysis has converged and how the posterior distributions compare to the priors, and to use the posterior samples in further analyses, including additional PDA.
If you haven’t done so already, take a look at all of the outputs described here.</p>
</div>
<div id="questions-2" class="section level4">
<h4><span class="header-section-number">5.5.3.13</span> Questions:</h4>
<ul>
<li>Do the diagnostic figures indicate that your likelihood at least improved over the course of the analysis?</li>
<li>Does the MCMC appear to have converged?</li>
<li>Are the posterior distributions well resolved?</li>
</ul>
</div>
<div id="post-pda-analyses" class="section level4">
<h4><span class="header-section-number">5.5.3.14</span> Post-PDA analyses</h4>
<p>In addition to the outputs of the PDA itself, you may want to conduct ensemble and/or sensitivity analyses based on the posteriors of the data assimilation, in order to check progress towards improved model fit and/or changing sensitivity. For this, you need to generate new model runs based on parameters sampled from the updated (by PDA) posterior, which is a simple matter of rerunning several steps of the PEcAn workflow.
The PDA you ran has automatically produced an updated XML file (<code>pecan.pda***.xml</code>) that includes the posterior id to be used in the next round of runs. Locate this file in your run directory and load the file for the post-pda ensemble/sensitivity analysis (if you already have the <code>settings</code> list in your working environment you don’t need to re-read the settings):</p>
<pre class="sourceCode r"><code class="sourceCode r"> <span class="co"># read post-PDA settings if you don&#39;t have them in your wotking environment</span>
 <span class="co"># replace the *** with the ensemble id given by the workflow</span>
 <span class="co"># postPDA.settings &lt;- read.settings(file.path(outdir,paste0(&quot;PEcAn_&quot;, workflow_id),&quot;pecan.pda***.xml&quot;))</span>

 <span class="co"># Call model specific write.configs</span>
  postPDA.settings &lt;-<span class="st"> </span><span class="kw">run.write.configs</span>(postPDA.settings,
                          <span class="dt">write=</span>postPDA.settings<span class="op">$</span>database<span class="op">$</span>bety<span class="op">$</span>write,     
                          <span class="dt">ens.sample.method=</span>postPDA.settings<span class="op">$</span>ensemble<span class="op">$</span>method)

 <span class="co"># Let&#39;s save the settings with the new ensemble id </span>
  PEcAn.settings<span class="op">::</span><span class="kw">write.settings</span>(settings, <span class="dt">outputfile=</span><span class="kw">paste0</span>(<span class="st">&#39;pecan.pda&#39;</span>, postPDA.settings<span class="op">$</span>assim.batch<span class="op">$</span>ensemble.id,<span class="st">&#39;.xml&#39;</span>))

 <span class="co"># Start ecosystem model runs, this one takes awhile...</span>
  PEcAn.remote<span class="op">::</span><span class="kw">start.model.runs</span>(postPDA.settings, postPDA.settings<span class="op">$</span>database<span class="op">$</span>bety<span class="op">$</span>write)

 <span class="co"># Get results of model runs</span>
  <span class="kw">get.results</span>(postPDA.settings)

 <span class="co"># Repeat ensemble analysis with PDA-constrained params </span>
 <span class="kw">run.ensemble.analysis</span>(postPDA.settings, <span class="ot">TRUE</span>)
 
 <span class="co"># let&#39;s re-load the pre-PDA ensemble outputs</span>
 <span class="kw">load</span>(prePDA_ensemble_output_file)
 pre_pda_ens &lt;-<span class="st"> </span>ensemble.ts[[<span class="st">&quot;NEE&quot;</span>]]
 
 <span class="co"># nowload the post-PDA ensemble outputs </span>
 postPDA_ensemble_output_file &lt;-<span class="st"> </span><span class="kw">file.path</span>(outdir,<span class="kw">paste0</span>(<span class="st">&quot;PEcAn_&quot;</span>, workflow_id, <span class="st">&quot;/ensemble.ts.&quot;</span>, postPDA.settings<span class="op">$</span>ensemble<span class="op">$</span>ensemble.id, <span class="st">&quot;.NEE.2003.2006.Rdata&quot;</span>))
 <span class="kw">load</span>(postPDA_ensemble_output_file)
 post_pda_ens &lt;-<span class="st"> </span>ensemble.ts[[<span class="st">&quot;NEE&quot;</span>]]
 
 <span class="co"># try changing the window value for daily, weekly, monthly smoothing later</span>
 <span class="co"># see if this changes your model-data agreement, why?</span>
 window &lt;-<span class="st"> </span><span class="dv">1</span> <span class="co"># no smoothing</span>
 pre_pda &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">apply</span>(pre_pda_ens, <span class="dv">1</span>, <span class="cf">function</span>(x) {
        <span class="kw">tapply</span>(x, <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>(<span class="kw">length</span>(x)<span class="op">/</span>window <span class="op">+</span><span class="st"> </span><span class="dv">1</span>), <span class="dt">each =</span> window)[<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(x)], 
               mean, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)}))
 post_pda &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">apply</span>(post_pda_ens, <span class="dv">1</span>, <span class="cf">function</span>(x) {
        <span class="kw">tapply</span>(x, <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>(<span class="kw">length</span>(x)<span class="op">/</span>window <span class="op">+</span><span class="st"> </span><span class="dv">1</span>), <span class="dt">each =</span> window)[<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(x)], 
               mean, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)}))
 fobs &lt;-<span class="st"> </span><span class="kw">tapply</span>(NEEo, <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>(<span class="kw">length</span>(NEEo) <span class="op">/</span><span class="st"> </span>window <span class="op">+</span><span class="st"> </span><span class="dv">1</span>), 
                          <span class="dt">each =</span> window)[<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(NEEo)], mean, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)
 
 
 <span class="co"># save the comparison plots to pdf</span>
 <span class="kw">pdf</span>(<span class="kw">file.path</span>(outdir,<span class="kw">paste0</span>(<span class="st">&quot;PEcAn_&quot;</span>,workflow_id),<span class="st">&quot;model.data.comparison.pdf&quot;</span>), <span class="dt">onefile=</span>T,
     <span class="dt">paper=</span><span class="st">&#39;A4r&#39;</span>, <span class="dt">height=</span><span class="dv">15</span>, <span class="dt">width=</span><span class="dv">20</span>) 
 
 <span class="co"># now plot the pre-PDA ensemble similar to the way we did before</span>
 preCI &lt;-<span class="st"> </span><span class="kw">apply</span>(pre_pda, <span class="dv">2</span>, quantile, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.5</span>, <span class="fl">0.975</span>), <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)
 ymin &lt;-<span class="st"> </span><span class="kw">min</span>(<span class="kw">min</span>(<span class="kw">c</span>(preCI, fobs), <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))
 ymax &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw">max</span>(<span class="kw">c</span>(preCI, fobs), <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))
 <span class="kw">plot</span>(pre_pda[<span class="dv">1</span>,], <span class="dt">ylim =</span> <span class="kw">c</span>(ymin, ymax), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">xlab =</span> <span class="st">&quot;time&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;NEE&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;pre-PDA vs post-PDA&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;n&quot;</span>)
 prepoly &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(preCI)[<span class="dv">2</span>]
 <span class="kw">polygon</span>(<span class="kw">c</span>(prepoly, <span class="kw">rev</span>(prepoly)),<span class="kw">c</span>(preCI[<span class="dv">3</span>,], <span class="kw">rev</span>(preCI[<span class="dv">1</span>,])),<span class="dt">col=</span><span class="st">&#39;khaki&#39;</span>,<span class="dt">border=</span><span class="ot">NA</span>)

 <span class="co"># plot the post-PDA ensemble</span>
 postCI &lt;-<span class="st"> </span><span class="kw">apply</span>(post_pda, <span class="dv">2</span>, quantile, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.5</span>, <span class="fl">0.975</span>), <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)
 postpoly &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(postCI)[<span class="dv">2</span>]
 <span class="kw">polygon</span>(<span class="kw">c</span>(postpoly, <span class="kw">rev</span>(postpoly)),<span class="kw">c</span>(postCI[<span class="dv">3</span>,], <span class="kw">rev</span>(postCI[<span class="dv">1</span>,])),<span class="dt">col=</span><span class="st">&#39;lightblue&#39;</span>,<span class="dt">border=</span><span class="ot">NA</span>)
 
 <span class="co"># finally let&#39;s add the data and see how we did</span>
 <span class="kw">points</span>(fobs, <span class="dt">pch =</span> <span class="st">&quot;.&quot;</span>, <span class="dt">col=</span> <span class="kw">adjustcolor</span>(<span class="st">&quot;purple&quot;</span>,<span class="dt">alpha.f=</span><span class="fl">0.7</span>))
 <span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;Data&quot;</span>,<span class="st">&quot;Pre-PDA Model&quot;</span>, <span class="st">&quot;Post-PDA Model&quot;</span>), <span class="dt">pch=</span><span class="kw">c</span>(<span class="dv">15</span>,<span class="dv">15</span>,<span class="dv">15</span>),
        <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;purple&quot;</span>,<span class="st">&quot;khaki&quot;</span>,<span class="st">&quot;lightblue&quot;</span>))
 
 <span class="kw">dev.off</span>()


 <span class="co"># Repeat variance decomposition to see how constraints have changed</span>
 <span class="kw">run.sensitivity.analysis</span>(postPDA.settings)</code></pre>
<p>Now you can check the new figures produced by your analyses under <code>PEcAn_[workflow_id]/pft/*/variance.decomposition.*.pdf</code> and <code>PEcAn_[workflow_id]/pft/*/sensitivity.analysis.*.pdf</code>, and compare them to the previous ones. Also, take a look at the comparison of model outputs to data when we run SIPNET with pre- and post-PDA parameter (mean) values under <code>PEcAn_[workflow_id]/model.data.comparison.pdf</code>.</p>
</div>
<div id="questions-3" class="section level4">
<h4><span class="header-section-number">5.5.3.15</span> Questions:</h4>
<ul>
<li>Looking at the ensemble analysis outputs in order (i.e., in order of increasing ID in the filenames), qualitatively how did the model fit to data change over the course of the analysis?</li>
<li>Based on the final ensemble analysis, what are the major remaining discrepancies between model and data?</li>
<li>Can you think of the processes / parameters that are likely contributing to the differences?</li>
<li>What would be your next steps towards evaluating or improving model performance?</li>
</ul>

</div>
</div>
<div id="state-variable-data-assimilation" class="section level3">
<h3><span class="header-section-number">5.5.4</span> State-Variable Data Assimilation</h3>
<div id="objectives-1" class="section level4">
<h4><span class="header-section-number">5.5.4.1</span> Objectives:</h4>
<ul>
<li>Assimilate tree ring estimated NPP &amp; inventory AGB within the SIPNET model in order to:</li>
<li>Reconcile data and model NPP &amp; AGB estimates</li>
<li>Constrain inferences about other ecosystem responses.</li>
</ul>
</div>
<div id="overview" class="section level4">
<h4><span class="header-section-number">5.5.4.2</span> Overview:</h4>
<ul>
<li>Initial Run</li>
<li>Settings</li>
<li>Load and match plot and increment data</li>
<li>Estimate tree-level data uncertainties</li>
<li>Estimate allometric relationships</li>
<li>Estimate stand-level NPP</li>
<li>Sample initial conditions and parameters</li>
<li>Run Ensemble Kalman Filter</li>
</ul>
</div>
<div id="initial-run" class="section level4">
<h4><span class="header-section-number">5.5.4.3</span> Initial Run</h4>
<p>Perform a site-level SIPNET run using the following settings</p>
<ul>
<li>Site = UNDERC</li>
<li>Start = 01/01/1979</li>
<li>End = 12/31/2015</li>
<li>Met = NARR</li>
<li>Check <strong>Brown Dog</strong></li>
<li>When the run is complete, open the pecan.xml and cut-and-paste the <strong>outdir</strong> for later use</li>
</ul>
</div>
<div id="settings" class="section level4">
<h4><span class="header-section-number">5.5.4.4</span> Settings:</h4>
<ul>
<li><p>Open the PEcAn RStudio environment back up.</p></li>
<li><p>Set your working directory to the outdir from above <code>setwd(outdir)</code> and shift the file browser to that location (Files &gt; More &gt; Go To Working Directory)</p></li>
<li><p>Open up the latest settings file <code>pecan.CONFIG.xml</code>.</p></li>
<li><p>At the top of the file add the following tags to set the ensemble size</p></li>
</ul>
<pre><code>   &lt;state.data.assimilation&gt;
   &lt;n.ensemble&gt;35&lt;/n.ensemble&gt;
   &lt;process.variance&gt;FALSE&lt;/process.variance&gt;
   &lt;sample.parameters&gt;TRUE&lt;/sample.parameters&gt;
   &lt;data&gt;
    &lt;format_id&gt;1000000040&lt;/format_id&gt;
    &lt;input.id&gt;1000013298&lt;/input.id&gt;
  &lt;/data&gt;
   &lt;state.variables&gt;
   &lt;variable&gt;
   &lt;variable.name&gt;NPP&lt;/variable.name&gt;
   &lt;unit&gt;MgC/ha/yr&lt;/unit&gt;
        &lt;min_value&gt;-9999&lt;/min_value&gt;
        &lt;max_value&gt;9999&lt;/max_value&gt;
   &lt;/variable&gt;
   &lt;variable&gt;
   &lt;variable.name&gt;AbvGrndWood&lt;/variable.name&gt;
       &lt;unit&gt;KgC/m^2&lt;/unit&gt;
       &lt;min_value&gt;0&lt;/min_value&gt;
       &lt;max_value&gt;9999&lt;/max_value&gt;
   &lt;/variable&gt;
   &lt;variable&gt;
   &lt;variable.name&gt;TotSoilCarb&lt;/variable.name&gt;
      &lt;unit&gt;KgC/m^2&lt;/unit&gt;
      &lt;min_value&gt;0&lt;/min_value&gt;
      &lt;max_value&gt;9999&lt;/max_value&gt;
   &lt;/variable&gt;
   &lt;variable&gt;
   &lt;variable.name&gt;LeafC&lt;/variable.name&gt;
         &lt;unit&gt;m^2/m^2&lt;/unit&gt;
         &lt;min_value&gt;0&lt;/min_value&gt;
         &lt;max_value&gt;9999&lt;/max_value&gt;
   &lt;/variable&gt;
   &lt;variable&gt;
   &lt;variable.name&gt;SoilMoistFrac&lt;/variable.name&gt;
         &lt;unit&gt;&lt;/unit&gt;
         &lt;min_value&gt;0&lt;/min_value&gt;
         &lt;max_value&gt;9999&lt;/max_value&gt;
   &lt;/variable&gt;
   &lt;variable&gt;
   &lt;variable.name&gt;SWE&lt;/variable.name&gt;
         &lt;unit&gt;cm&lt;/unit&gt;
         &lt;min_value&gt;0&lt;/min_value&gt;
         &lt;max_value&gt;9999&lt;/max_value&gt;
   &lt;/variable&gt;
   &lt;variable&gt;
   &lt;variable.name&gt;Litter&lt;/variable.name&gt;
         &lt;unit&gt;gC/m^2&lt;/unit&gt;
         &lt;min_value&gt;0&lt;/min_value&gt;
         &lt;max_value&gt;9999&lt;/max_value&gt;
   &lt;/variable&gt;
   &lt;/state.variables&gt;
   &lt;forecast.time.step&gt;year&lt;/forecast.time.step&gt;
  &lt;start.date&gt;1980/01/01&lt;/start.date&gt;
  &lt;end.date&gt;2015/12/31&lt;/end.date&gt;
  &lt;/state.data.assimilation&gt;</code></pre>
<ul>
<li><p>Delete the `<code>&lt;pfts&gt;</code> block from the settings</p></li>
<li><p>In the PEcAn History, go to your PDA run and open <code>pecan.pda[UNIQUEID].xml</code> (the one PEcAn saved for you AFTER you finished the PDA)</p></li>
<li><p>Cut-and-paste the PDA <code>&lt;pfts&gt;</code> block into the SDA settings file</p></li>
<li><p>Save the file as <code>pecan.SDA.xml</code></p></li>
</ul>
</div>
<div id="loading-data" class="section level4">
<h4><span class="header-section-number">5.5.4.5</span> Loading data</h4>
<ul>
<li>If you have not done so already, clone (new) or pull (update) the PalEON Camp2016 repository</li>
<li>Open a shell under Tools &gt; Shell</li>
<li>`<code>cd</code> to go to your home directory</li>
<li>To clone: <code>git clone git@github.com:PalEON-Project/Camp2016.git</code></li>
<li><p>To pull: <code>cd Camp2016; git pull https://github.com/PalEON-Project/Camp2016.git master</code></p></li>
<li><p>Open the tree-ring data assimilation workflow under Home &gt; pecan &gt; scripts &gt; workflow.treering.R</p></li>
<li><p>Run the script from the start up through the LOAD DATA section</p></li>
</ul>
</div>
<div id="estimating-tree-level-data-uncertainties" class="section level4">
<h4><span class="header-section-number">5.5.4.6</span> Estimating tree-level data uncertainties</h4>
<p>One thing that is critical for data assimilation, whether it is being used to estimate parameters or state variables, is the careful consideration and treatment of the uncertainties in the data itself. For this analysis we will be using a combination of forest plot and tree ring data in order to estimate stand-level productivity. The basic idea is that we will be using the plot-sample of measured DBHs as an estimate of the size structure of the forest, and will use the annual growth increments to project that forest backward in time. Tree biomass is estimated using empirical allometric equations relating DBH to aboveground biomass. There are a number of sources of uncertainty in this approach, and before moving you are encouraged to think about and write down a few:</p>
<hr />
<hr />
<hr />
<hr />
<hr />
<hr />
<hr />
<hr />
<p>Today we will use a statistical model based on the model developed by Clark et al 2007 that partitions out a number of sources of variability and uncertainty in tree ring and plot data (Fig 1). This model is a Bayesian statespace model that treats the true diameters (D) and increments (X) as latent variables that are connected through a fairly simple mixed effects process model</p>
<p><span class="math display">\[D_{ij,t+1} = D_{ij,t} + \mu + \alpha_{i} + \alpha_t + \epsilon_{ij,t}\]</span></p>
<p>where i = individual, j = plot, t = time (year). Each of these terms are represented at normal distributions, where <span class="math inline">\(\mu\)</span> is a fixed effect (overall mean growth rate) and individual and year are random effects</p>
<p><span class="math display">\[\mu \sim N(0.5,0.5)\]</span>
<span class="math display">\[\alpha_{i} \sim N(0,\tau_{i})\]</span>
<span class="math display">\[\alpha_{t} \sim N(0,\tau_{t})\]</span>
<span class="math display">\[\epsilon_{ij,t} \sim N(0,\tau_{e})\]</span></p>
<p>The connection between the true (latent) variable and the observations is also represented as normal with these variances representing measurement error:</p>
<p><span class="math display">\[D_{ij,t}^O \sim N( D_{ij,t},\tau_D)\]</span>
<span class="math display">\[X_{ij,t}^O \sim N( X_{ij,t},\tau_r)\]</span></p>
<p>Finally, there are five gamma priors on the precisions, one for the residual process error (<span class="math inline">\(\tau_{e}\)</span>), two for the random effects on individual (<span class="math inline">\(\tau_{i}\)</span>) and time (<span class="math inline">\(\tau_t\)</span>),
and two measurement errors or DBH (<span class="math inline">\(\tau_D\)</span>) and tree rings (<span class="math inline">\(\tau_r\)</span>)</p>
<p><span class="math display">\[\tau_{e} \sim Gamma(a_e,r_e)\]</span>
<span class="math display">\[\tau_{i} \sim Gamma(a_i,r_i)\]</span>
<span class="math display">\[\tau_{t} \sim Gamma(a_t,r_t)\]</span>
<span class="math display">\[\tau_{D} \sim Gamma(a_D,r_D)\]</span>
<span class="math display">\[\tau_{r} \sim Gamma(a_r,r_r)\]</span></p>
<p>This model is encapsulated in the PEcAn function:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">InventoryGrowthFusion</span>(combined,n,iter)</code></pre>
<p>where the first argument is the combined data set formatted for JAGS and the second is the number of MCMC interations. The model itself is written for JAGS and is embedded in the function. Running the above InventoryGrowthFusion will run a full MCMC algorithm, so it does take a while to run. The code returns the results as an mcmc.list object, and the next line in the script saves this to the outputs directory We then call the function InventoryGrowthFusionDiagnostics to print out a set of MCMC diagnostics and example time-series for growth and DBH.</p>
</div>
<div id="allometric-equations" class="section level4">
<h4><span class="header-section-number">5.5.4.7</span> Allometric equations</h4>
<p>Aboveground NPP is estimated as the increment in annual total aboveground biomass. This estimate is imperfect, but not unreasonable for demonstration purposes. As mentioned above, we will take an allometric approach of scaling from diameter to biomass: Biomass = b0 * DBH b1 We will generate the allometric equation on a PFT level using another Bayesian model that synthesizes across a database of species-level allometric equations (Jenkins et al 2004). This model has two steps within the overall MCMC loop. First it simulates data from each equation, including both parameter and residual uncertainties, and then it updated the parameters of a single allometric relationship across all observations. The code also fits a second model, which includes a random site effect, but for simplicity we will not be using output from this version. Prior to running the model we have to first query the species codes for our pfts. Next we pass this PFT list to the model, AllomAve, which saves the results to the output directory in addition to returning a summary of the parameters and covariances.</p>
</div>
<div id="estimate-stand-level-npp" class="section level4">
<h4><span class="header-section-number">5.5.4.8</span> Estimate stand-level NPP</h4>
<p>If we have no uncertainty in our data or allometric equations, we could estimate the stand aboveground biomass (AGB) for every year by summing over the biomass of all the trees in the plot and then divide by the plot area. We would then estimate NPP by the difference in AGB between years. One approach to propagating uncertainties into NPP would be to transform the distribution of DBH for each individual tree and year into a distribution for biomass, then sum over those distributions to get a distribution for AGB and then subtract the distributions to get the distributions of NPP. However, if we do this we will greatly overestimate the uncertainty in NPP because we ignore the fact that our increment data has much lower uncertainty than our diameter data. In essence, if we take a random draw from a distribution of AGB in year and it comes back above average, the AGB is much more likely to also be above average the following year than if we were to do an independent draw from that distribution. Accounting for this covariance requires a fairly simple change in our approach and takes advantage of the nature of the MCMC output. The basic idea is that we are going to take a random draw from the full individual x year diameter matrix, as well as a random draw of allometric parameters, and perform the ‘zero-error’ calculation approach described above. We will then create a distribution of all the NPP estimates that comes out of repeated draws for the full diameter matrix. This approach is encapsulated in the function <code>plot2AGB</code>. The argument unit.conv is a factor that combines both the area of the plot and the unit conversion from tree biomass (kg/tree) to stand AGB (Mg/ha). There are two outputs from plot2AGB: a pdf depicting estimated NPP and AGB (mean and 95% CI) time series, with each page being a plot; and plot2AGB.Rdata, a binary record of the function output that is read into the data assimilation code. The latter is also returned from the fuction and assigned to the variable “state”. Finally, we calculate the mean and standard deviation of NPP and save this as obs.</p>
</div>
<div id="build-initial-conditions" class="section level4">
<h4><span class="header-section-number">5.5.4.9</span> Build Initial Conditions</h4>
<p>The function sample.IC.SIPNET uses the AGB estimate from the previous function in order to initialize the data assimilation routine. Specifically it samples n.ensemble values from the first time step of the AGB estimate. Embedded in this function are also a number of prior distributions for other state variables, which are also samples in order to create a full set of initial conditions for SIPNET.</p>
</div>
<div id="load-priors" class="section level4">
<h4><span class="header-section-number">5.5.4.10</span> Load Priors</h4>
<p>The function sample.parameters samples values from the most recent posterior parameter distributions. You can also specify a specific set of parameters so sample from by specifying the argument <code>&lt;prior&gt;</code> within <code>&lt;assim.sequential&gt;</code> as the posterior.id you want to use. This is useful to know if you want to go back and run with the Meta-analysis posteriors, or if you end up rerunning the meta-analysis and need to go back and specify the parameter data assimilation posteriors instead of the most recent.</p>
</div>
<div id="ensemble-kalman-filter" class="section level4">
<h4><span class="header-section-number">5.5.4.11</span> Ensemble Kalman Filter</h4>
<p>The function <code>sda.enkf</code> will run SIPNET in Ensemble Kalman Filter mode. The output of this function will be all the of run outputs, a PDF of diagnostics, and an Rdata object that includes three lists:</p>
<ul>
<li>FORECAST will be the ensemble forecasts for each year</li>
<li>ANALYSIS will be the updated ensemble sample given the NPP observations</li>
<li>enkf.params contains the prior and posterior mean vector and covariance matrix for each time step.</li>
</ul>
<p>If you look within this function you will find that much of the format is similar to the pda.mcmc function, but in general is much simpler. The function begins by setting parameters, opening a database connection, and generating workflow and ensemble ID’s. Next we split the SIPNET clim meteorology file up into individual annual files since we will be running SIPNET for a year at a time between updates. Next we perform an initial set of runs starting from the initial states and parameters we described above. In doing so we create the run and output directories, the README file, and the runs.txt file that is read by start.model.runs. Worth noting is that the README and runs.txt don’t need to be updated within the forecast loop. Given this initial run we then enter the forecast loop. Within this loop over years we perform four basic steps. First, we read the output from the latest runs. Second, we calculate the updated posterior state estimates based on the model ensemble prior and observation likelihood. Third, we resample the state estimates based on these posterior parameters. Finally, we start a new set of runs based on this sample. The sda.enfk function then ends by saving the outputs and generating some diagnostic figures. The first set of these shows the data, forecast, analysis. The second set shows pairs plots of the covariance structure for the Forecast and Analysis steps. The final set shows the time-series plots for the Analysis of the over state variables produced by SIPNET.</p>
</div>
<div id="finishing-up" class="section level4">
<h4><span class="header-section-number">5.5.4.12</span> Finishing up</h4>
<p>The final bit of code in the script will register the workflow as complete in the database. After this is run you should be able to find all of the runs, and all of the outputs generated above, from within the PEcAn webpages.</p>

</div>
</div>
<div id="pecan-testing-the-sensitivity-analysis-against-observations" class="section level3">
<h3><span class="header-section-number">5.5.5</span> PEcAn: Testing the Sensitivity Analysis Against Observations&quot;</h3>
<div id="author-ankur-desai" class="section level4">
<h4><span class="header-section-number">5.5.5.1</span> Author: “Ankur Desai”</h4>
</div>
<div id="flux-measurements-and-modeling-course-tutorial-part-2" class="section level4">
<h4><span class="header-section-number">5.5.5.2</span> Flux Measurements and Modeling Course, <em>Tutorial Part 2</em></h4>
<p>This tutorial assumes you have successfully completed the Demo01, Demo02 and the modelVSdata tutorial.</p>
</div>
<div id="introduction" class="section level4">
<h4><span class="header-section-number">5.5.5.3</span> Introduction</h4>
<p>Now that you have successfully run PEcAn through the web interface and have learned how to do a simple comparison of flux tower observations to model output, let’s start looking at how data assimilation and parameter estimation would work with an ecosystem model.</p>
<p>Before we start a full data assimilation exercise, let’s try something simple – single parameter selection by hand.</p>
<ul>
<li>Open <a href="http://localhost:3280/rstudio" class="uri">http://localhost:3280/rstudio</a> or <a href="http://localhost:6480/rstudio" class="uri">http://localhost:6480/rstudio</a> or the Amazon URL/rstudio if running on the cloud.</li>
</ul>
<p>In Demo02, you have ran a sensitivity analysis of SIPNET model runs at Niwot Ridge sampling across quantiles of a parameter prior, while holding all others to the median value. The pecan.xml file told PEcAn to run an sensitivity analysis, which simply meant SIPNET was run multiple times with the same driver, but varying parameter values one at a time (while holding all others to their median), and the parameter range also specified in the pecan.xml file (as quantiles, which were then sampled against the BETY database of observed variation in the parameter for species within the specific plant functional type).</p>
<p>Let’s try to compare Ameriflux NEE to SIPNET NEE across all these runs to make a plot of parameter vs. goodness-of-fit. We’ll start with root mean square error (<strong>RMSE</strong>), but then discuss some other tests, too.</p>
</div>
<div id="a.-read-in-settings-object-from-a-run-xml" class="section level4">
<h4><span class="header-section-number">5.5.5.4</span> A. Read in settings object from a run xml</h4>
<p>Open up a connection to the bety database and create a settings object from your xml, just like in the modelVSdata tutorial.</p>
<pre class="sourceCode r"><code class="sourceCode r">settings&lt;-PEcAn.settings<span class="op">::</span><span class="kw">read.settings</span>(<span class="st">&quot;~/output/PEcAn_99000000002/pecan.CONFIGS.xml&quot;</span>)

bety&lt;-settings<span class="op">$</span>database<span class="op">$</span>bety
bety &lt;-dplyr<span class="op">::</span><span class="kw">src_postgres</span>(<span class="dt">host =</span> bety<span class="op">$</span>host, <span class="dt">user =</span> bety<span class="op">$</span>user, <span class="dt">password =</span> bety<span class="op">$</span>password, <span class="dt">dbname =</span> bety<span class="op">$</span>dbname)</code></pre>
<p>We read in the pecan.CONFIG.xml instead of the pecan.xml because the pecan.CONFIG.xml has already incorperated some of the information from the database we would have to query again if we used the pecan.xml.</p>
<pre class="sourceCode r"><code class="sourceCode r">runid&lt;-<span class="kw">as.character</span>(<span class="kw">read.table</span>(<span class="kw">paste</span>(settings<span class="op">$</span>outdir, <span class="st">&quot;/run/&quot;</span>,<span class="st">&quot;runs.txt&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))[<span class="dv">1</span>,<span class="dv">1</span>]) <span class="co"># Note: if you are using an xml from a run with multiple ensembles this line will provide only the first run id </span>
outdir&lt;-<span class="st"> </span><span class="kw">paste</span>(settings<span class="op">$</span>outdir,<span class="st">&quot;/out/&quot;</span>,runid,<span class="dt">sep=</span> <span class="st">&quot;&quot;</span>)
start.year&lt;-<span class="kw">as.numeric</span>(lubridate<span class="op">::</span><span class="kw">year</span>(settings<span class="op">$</span>run<span class="op">$</span>start.date))
end.year&lt;-<span class="kw">as.numeric</span>(lubridate<span class="op">::</span><span class="kw">year</span>(settings<span class="op">$</span>run<span class="op">$</span>end.date))

site.id&lt;-settings<span class="op">$</span>run<span class="op">$</span>site<span class="op">$</span>id</code></pre>
<p>Back to the files pane, within the <em>run/</em> folder, find a folder called <em>pft/</em> and within that a folder with the pft name (such as <em>temprature.coniferous</em>). Within that is a PDF file that starts <em>sensitivity.analysis</em>. In Rstudio, just click on the PDF to view it. You discussed this PDF last tutorial, through the web interface. Here, we see how the model NEE in SIPNET changes with each parameter.</p>
<p>Let’s read that sensitivity output. Navigate back up (<em>..</em>) to the <em>~/output/<strong>RUNDIR</strong>/</em> folder. Find a series of files that end in “<em>.RData</em>”. These files contain the R variables used to make these plots. In particular, there is <strong>sensitivity.output.<em>.RData<strong> which contains the annual NEE as a function of each parameter quantile. Click on it to load a variable into your environment. There is </strong>sensitivity.results.</em>.RData</strong> which contains plotting functions and variance decomposition output, which we don’t need in this tutorial. And finally, there is **sensitivity.samples.*.RData** which contains the actual parameter values and the RunIDs associated with each sensitivity run.</p>
<p>Click on <em>sensitivity.samples.</em>.RData* to load it into your environment, or run the <code>{r}load()</code> script below. You should see a set of five new variables (pft.names, trait.names, sa.ensemble.id, sa.run.ids, sa.samples).</p>
<p>Let’s extract a parameter and it’s sensitivity NEE output from the list sa.samples, which is organized by PFT, and then by parameter. First, let’s look at a list of PFTs and parameters available:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="kw">paste</span>(settings<span class="op">$</span>outdir,<span class="st">&quot;/sensitivity.samples.&quot;</span>, settings<span class="op">$</span>sensitivity.analysis<span class="op">$</span>ensemble.id,<span class="st">&quot;.Rdata&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))

<span class="kw">names</span>(sa.samples)
<span class="kw">names</span>(sa.samples<span class="op">$</span>temperate.coniferous)</code></pre>
<p>Now to see the actual parameter values used by the runs, just pick a parameter and type:</p>
<pre class="sourceCode r"><code class="sourceCode r">sa.samples<span class="op">$</span>temperate.coniferous<span class="op">$</span>psnTOpt</code></pre>
<p>Let’s store that value for future use:</p>
<pre class="sourceCode r"><code class="sourceCode r">psnTOpt &lt;-<span class="st"> </span>sa.samples<span class="op">$</span>temperate.coniferous<span class="op">$</span>psnTOpt</code></pre>
<p>Now, to see the annual NEE output from the model for a particular PFT and parameter range, try</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="kw">paste</span>(settings<span class="op">$</span>outdir,<span class="kw">paste</span>(<span class="st">&quot;/sensitivity.output&quot;</span>, settings<span class="op">$</span>sensitivity.analysis<span class="op">$</span>ensemble.id,settings<span class="op">$</span>sensitivity.analysis<span class="op">$</span>variable,start.year,end.year,<span class="st">&quot;Rdata&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;.&quot;</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))

sensitivity.output<span class="op">$</span>temperate.coniferous<span class="op">$</span>psnTOpt</code></pre>
<p>You could even plot the two:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(psnTOpt,sensitivity.output<span class="op">$</span>temperate.coniferous<span class="op">$</span>psnTOpt)</code></pre>
<p>What do you notice?</p>
<p>Let’s try to read the output from a single run id as you did in the earlier tutorial.</p>
<pre class="sourceCode r"><code class="sourceCode r">runids &lt;-<span class="st"> </span>sa.run.ids<span class="op">$</span>temperate.coniferous<span class="op">$</span>psnTOpt
arun &lt;-<span class="st"> </span>PEcAn.utils<span class="op">::</span><span class="kw">read.output</span>(runids[<span class="dv">1</span>], <span class="kw">paste</span>(settings<span class="op">$</span>outdir, <span class="st">&quot;out&quot;</span>, runids[<span class="dv">1</span>], <span class="dt">sep=</span><span class="st">&quot;/&quot;</span>), <span class="dt">start.year=</span> start.year, <span class="dt">end.year=</span> end.year,<span class="st">&quot;NEE&quot;</span>, <span class="dt">dataframe =</span> <span class="ot">TRUE</span>)

<span class="kw">plot</span>(arun<span class="op">$</span>posix,arun<span class="op">$</span>NEE)</code></pre>
</div>
<div id="b.-now-lets-bring-in-the-actual-observations" class="section level4">
<h4><span class="header-section-number">5.5.5.5</span> B. Now let’s bring in the actual observations</h4>
<p>Recall reading Ameriflux NEE in the modelVSdata tutorial.</p>
<pre class="sourceCode r"><code class="sourceCode r">File_path&lt;-<span class="st">&quot;~/output/dbfiles/AmerifluxLBL_site_0-772/AMF_US-NR1_BASE_HH_9-1.csv&quot;</span>

File_format&lt;-PEcAn.DB<span class="op">::</span><span class="kw">query.format.vars</span>(<span class="dt">bety =</span> bety, <span class="dt">format.id =</span> <span class="dv">5000000002</span>) <span class="co">#This matches the file with a premade &quot;format&quot; or a template that describes how the information in the file is organized</span>
site&lt;-PEcAn.DB<span class="op">::</span><span class="kw">query.site</span>(<span class="dt">site.id =</span> site.id,bety<span class="op">$</span>con)  

obs&lt;-PEcAn.benchmark<span class="op">::</span><span class="kw">load_data</span>(<span class="dt">data.path =</span> File_path, <span class="dt">format=</span> File_format, <span class="dt">time.row =</span> File_format<span class="op">$</span>time.row,  <span class="dt">site =</span> site, <span class="dt">start_year =</span> start.year, <span class="dt">end_year =</span> end.year) 

obs<span class="op">$</span>NEE[obs<span class="op">$</span>UST<span class="op">&lt;</span><span class="fl">0.2</span>]&lt;-<span class="ot">NA</span> <span class="co">#Apply a U* filter</span>

plottable&lt;-<span class="kw">align_data</span>(<span class="dt">model.calc =</span> arun, <span class="dt">obvs.calc =</span> obs, <span class="dt">align_method =</span> <span class="st">&quot;match_timestep&quot;</span>, <span class="dt">var=</span> <span class="st">&quot;NEE&quot;</span>)
<span class="kw">head</span>(plottable)</code></pre>
</div>
<div id="c.-finally-we-can-finally-compare-model-to-data" class="section level4">
<h4><span class="header-section-number">5.5.5.6</span> C. Finally, we can finally compare model to data</h4>
<p>In the modelVSdata, you also compared NEE to the ensemble model run. Here we will do the same except we include each sensitivity run.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(plottable<span class="op">$</span>NEE.m,plottable<span class="op">$</span>NEE.o)
<span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre>
<p>And remember the formula for RMSE:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sqrt</span>(<span class="kw">mean</span>((plottable<span class="op">$</span>NEE.o<span class="op">-</span>plottable<span class="op">$</span>NEE.m)<span class="op">^</span><span class="dv">2</span>,<span class="dt">na.rm =</span> <span class="ot">TRUE</span>))    </code></pre>
<p>All we need to do to go beyond this is to make a loop that reads in each sensitivity run NEE based on runids, calculates RMSE against the observations, and stores it in an array, by combining the steps above in a for loop. Make sure you change the directory names and year to your specific run.</p>
<pre class="sourceCode r"><code class="sourceCode r">rmses &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,<span class="kw">length</span>(runids))
<span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(runids)){
arun &lt;-<span class="st"> </span><span class="kw">read.output</span>(runids[r],<span class="kw">paste</span>(settings<span class="op">$</span>outdir, <span class="st">&quot;out&quot;</span>, runids[r], <span class="dt">sep=</span><span class="st">&quot;/&quot;</span>),<span class="dv">2004</span>,<span class="dv">2004</span>,<span class="st">&quot;NEE&quot;</span>, <span class="dt">dataframe=</span> <span class="ot">TRUE</span>)
plottable&lt;-<span class="kw">align_data</span>(<span class="dt">model.calc =</span> arun, <span class="dt">obvs.calc =</span> obs, <span class="dt">align_method =</span> <span class="st">&quot;match_timestep&quot;</span>, <span class="dt">var=</span> <span class="st">&quot;NEE&quot;</span>)
rmses[r] &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>((plottable<span class="op">$</span>NEE.o<span class="op">-</span>plottable<span class="op">$</span>NEE.m)<span class="op">^</span><span class="dv">2</span>,<span class="dt">na.rm =</span> <span class="ot">TRUE</span>))
}

rmses</code></pre>
<p>Let’s plot that array</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(psnTOpt,rmses)</code></pre>
<p>Can you identify a minimum (if there is one)? If so, is there any reason to believe this is the “best” parameter? Why or why not? Think about all the other parameters.</p>
<p>Now that you have the hang of it, here are a few more things to try:</p>
<ol style="list-style-type: decimal">
<li>Try a different error functions, given actual NEE uncertainty. You learned earlier that uncertainty in half-hourly observed NEE is not Gaussian. This makes RMSE not the correct measure for goodness-of-fit. Go to <em>~/pecan/modules/uncertainty/R</em>, open <em>flux_uncertainty.R</em>, and click on the <em>source</em> button in the program editing pane.</li>
</ol>
<p>Alternatively, you can source the function from the console using:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="st">&quot;pecan/modules/uncertainty/R/flux_uncertainty.R&quot;</span>)</code></pre>
<p>Then you can run:</p>
<pre class="sourceCode r"><code class="sourceCode r">unc &lt;-<span class="st"> </span><span class="kw">flux.uncertainty</span>(plottable<span class="op">$</span>NEE.o,<span class="dt">QC=</span><span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">17520</span>)) 
<span class="kw">plot_flux_uncertainty</span>(unc)</code></pre>
<p>The figure shows you uncertainty (err) as a function of NEE magnitude (mag). How might you use this information to change the RMSE calculation?</p>
<p>Try a few other parameters. Repeat the above steps but with a different parameter. You might want to select one from the sensitivity PDF that has a large sensitivity or from the variance decomposition that is also poorly constrained.</p>

</div>
</div>
</div>
<div id="advanced-user" class="section level2">
<h2><span class="header-section-number">5.6</span> Advanced User Guide</h2>
<ul>
<li><a href="user-section.html#web-curl-submission">Workflow curl submission</a></li>
</ul>

<div id="web-curl-submission" class="section level3">
<h3><span class="header-section-number">5.6.1</span> Submitting Workflow from Command Line</h3>
<p>This is how you can submit a workflow from the command line through the pecan web interface. This will use curl to submit all the requireed parameters to the web interface and trigger a run.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># the host where the model should run</span>
<span class="co"># never use remote sites since you will need to pass your username/password and that WILL be stored</span>
<span class="va">hostname=</span>pecan.vm
<span class="co"># the site id where to run the model (NIWOT in this case)</span>
<span class="va">siteid=</span>772
<span class="co"># start date and end date, / need to be replaced with %2F or use - (NOT TESTED)</span>
<span class="va">start=</span>2004-01-01
<span class="va">end=</span>2004-12-31

<span class="co"># if of model you want to run, rest of section parameters depend on the model selected (SIPNET 136)</span>
<span class="va">modelid=</span>5000000002
<span class="co"># PFT selected (we should just use a number here)</span>
<span class="co"># </span><span class="al">NOTE</span><span class="co">: the square brackets are needed and will need be escaped with a \ if you call this from command line</span>
<span class="ex">pft</span>[]=temperate.coniferous
<span class="co"># initial pool condition (-1 means nothing is selected)</span>
<span class="va">input_poolinitcond=</span>-1
<span class="co"># met data</span>
<span class="va">input_met=</span>99000000006

<span class="co"># variables to collect</span>
<span class="va">variables=</span>NPP,GPP
<span class="co"># ensemble size</span>
<span class="va">runs=</span>10
<span class="co"># use sensitivity analysis</span>
<span class="va">sensitivity=</span>-1,1

<span class="co"># redirect to the edit pecan.xml file</span>
<span class="va">pecan_edit=</span>on
<span class="co"># redirect to edit the model configuration files</span>
<span class="va">model_edit=</span>on
<span class="co"># use browndog</span>
<span class="va">browndog=</span>on</code></pre>
<p>For example the following will run the above workflow. Using -v in curl will show verbose output (needed) and the grep will make sure it only shows the redirect. This will show the actual workflowid:</p>
<pre><code>curl -s -v &#39;http://localhost:6480/pecan/04-runpecan.php?hostname=pecan.vm&amp;siteid=772&amp;start=2004-01-01&amp;end=2004-12-31&amp;modelid=5000000002&amp;pft\[\]=temperate.coniferous&amp;input_poolinitcond=-1&amp;input_met=99000000006&#39; 2&gt;&amp;1 | grep &#39;Location:&#39;
&lt; Location: 05-running.php?workflowid=99000000004</code></pre>
<p>In this case you can use the browser to see progress, or use the following to see the status:</p>
<pre><code>curl -s &#39;http://localhost:6480/pecan/dataset.php?workflowid=99000000004&amp;type=file&amp;name=STATUS&#39;
TRAIT   2017-12-13 08:56:56 2017-12-13 08:56:57 DONE
META    2017-12-13 08:56:57 2017-12-13 08:57:13 DONE
CONFIG  2017-12-13 08:57:13 2017-12-13 08:57:14 DONE
MODEL   2017-12-13 08:57:14 2017-12-13 08:57:15 DONE
OUTPUT  2017-12-13 08:57:15 2017-12-13 08:57:15 DONE
ENSEMBLE    2017-12-13 08:57:15 2017-12-13 08:57:16 DONE
FINISHED    2017-12-13 08:57:16 2017-12-13 08:57:16 DONE</code></pre>
<p>Or to show the output log:</p>
<pre><code>curl -s &#39;http://localhost:6480/pecan/dataset.php?workflowid=99000000004&amp;type=file&amp;name=workflow.Rout&#39;

R version 3.4.3 (2017-11-30) -- &quot;Kite-Eating Tree&quot;
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type &#39;license()&#39; or &#39;licence()&#39; for distribution details.

R is a collaborative project with many contributors.
....</code></pre>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pecan-manual-setup.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="basic-web-wrokflow.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tonygardella/pecan/edit/release/vtonydoc/book_source/02_demos_tutorials_workflows/02_user_demos/01_introductions_user.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
